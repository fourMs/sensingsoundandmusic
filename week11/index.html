<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Week 11: Machine Listening - Sensing Sound and Music</title><meta property="og:title" content="Week 11: Machine Listening - Sensing Sound and Music"/><meta name="generator" content="mystmd"/><meta name="description" content="An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives."/><meta property="og:description" content="An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives."/><meta name="keywords" content="sensing, sound, music, psychology, technology"/><link rel="stylesheet" href="/sensingsoundandmusic/build/_assets/app-5WKS5EPQ.css"/><link rel="stylesheet" href="/sensingsoundandmusic/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/sensingsoundandmusic/favicon.ico"/><link rel="stylesheet" href="/sensingsoundandmusic/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/sensingsoundandmusic/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">âŒ˜</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Sensing Sound and Music" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/sensingsoundandmusic/">Sensing Sound and Music</a><a title="Week 1: Tuning in" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week1">Week 1: Tuning in</a><a title="Week 2: Listening" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week2">Week 2: Listening</a><a title="Week 3: Acoustics" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week3">Week 3: Acoustics</a><a title="Week 4: Psychoacoustics" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week4">Week 4: Psychoacoustics</a><a title="Week 5: Time and Rhythm" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week5">Week 5: Time and Rhythm</a><a title="Week 6: Harmony and melody" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week6">Week 6: Harmony and melody</a><a title="Week 7: Body Motion" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week7">Week 7: Body Motion</a><a title="Week 8: The Brain" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week8">Week 8: The Brain</a><a title="Week 9: Vision" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week9">Week 9: Vision</a><a title="Week 10: Physiology" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week10">Week 10: Physiology</a><a title="Week 11: Machine Listening" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week11">Week 11: Machine Listening</a></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Open_access" target="_blank" rel="noopener noreferrer" title="Open Access" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="mr-1 inline-block opacity-60 hover:opacity-100 hover:text-[#E18435]"><path d="M17.1 12.6h-2V7.5c0-1.7-1.4-3.1-3-3.1-.8 0-1.6.3-2.2.9-.6.5-.9 1.3-.9 2.2v.7H7v-.7c0-1.4.5-2.7 1.5-3.7s2.2-1.5 3.6-1.5 2.6.5 3.6 1.5 1.5 2.3 1.5 3.7v5.1z"></path><path d="M12 21.8c-.8 0-1.6-.2-2.3-.5-.7-.3-1.4-.8-1.9-1.3-.6-.6-1-1.2-1.3-2-.3-.8-.5-1.6-.5-2.4s.2-1.6.5-2.4c.3-.7.7-1.4 1.3-2s1.2-1 1.9-1.3c.7-.3 1.5-.5 2.3-.5.8 0 1.6.2 2.3.5.7.3 1.4.8 1.9 1.3.6.6 1 1.2 1.3 2 .3.8.5 1.6.5 2.4s-.2 1.6-.5 2.4c-.3.7-.7 1.4-1.3 2-.6.6-1.2 1-1.9 1.3-.7.3-1.5.5-2.3.5zm0-10.3c-2.2 0-4 1.8-4 4.1s1.8 4.1 4 4.1 4-1.8 4-4.1-1.8-4.1-4-4.1z"></path><circle cx="12" cy="15.6" r="1.7"></circle></svg></a><a href="https://github.com/fourMs/sensingsoundandmusic" title="GitHub Repository: fourMs/sensingsoundandmusic" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/fourMs/sensingsoundandmusic/edit/main/book/week11.md" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Week 11: Machine Listening</h1><header class="mt-4 not-prose"><div><span class="font-semibold text-sm inline-block text-comma"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rb8top:" data-state="closed">MUS2640</button></span><span class="font-semibold text-sm inline-block"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rd8top:" data-state="closed">University of Oslo</button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><h2 id="machine-listening" class="relative group"><span class="heading-text">Machine Listening</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#machine-listening" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h2><p>Machine listening is a field of study that focuses on enabling machines to interpret and analyze audio signals. It has applications in various domains, including music, speech, and environmental sound analysis.</p><h3 id="information-retrieval" class="relative group"><span class="heading-text">Information Retrieval</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#information-retrieval" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3><p>Information retrieval in machine listening involves extracting meaningful information from audio data. Key areas include:</p><ul><li><p><strong>Classification</strong>: This involves categorizing audio into predefined classes, such as:</p><ul><li><p><a href="https://en.wikipedia.org/wiki/Music_genre" class="italic" target="_blank" rel="noreferrer" data-state="closed">Genre</a></p></li><li><p><a href="https://en.wikipedia.org/wiki/Musical_instrument" class="italic" target="_blank" rel="noreferrer" data-state="closed">Instruments</a></p></li><li><p><a href="https://en.wikipedia.org/wiki/Mood_(psychology)" class="italic" target="_blank" rel="noreferrer" data-state="closed">Mood</a></p></li></ul></li><li><p><strong>Recommendation</strong>: Systems that suggest music or audio content based on user preferences. Learn more about <a href="https://en.wikipedia.org/wiki/Recommender_system" class="italic" target="_blank" rel="noreferrer" data-state="closed">recommender systems</a>.</p></li><li><p><strong>Source Separation</strong>: The process of isolating individual sound sources from a mixture. See <a href="https://en.wikipedia.org/wiki/Audio_signal_processing#Source_separation" class="italic" target="_blank" rel="noreferrer" data-state="closed">source separation</a>.</p></li><li><p><strong>Transcription</strong>: Converting audio into symbolic representations like sheet music. Learn about <a href="https://en.wikipedia.org/wiki/Music_transcription" class="italic" target="_blank" rel="noreferrer" data-state="closed">music transcription</a>.</p></li><li><p><strong>Question-Answering</strong>: Systems that answer questions based on audio content.</p></li><li><p><strong>Segmentation</strong>: Dividing audio into meaningful segments, such as verses or choruses in music.</p></li><li><p><strong>Feature Extraction</strong>: Extracting characteristics like pitch, tempo, or timbre from audio. See <a href="https://en.wikipedia.org/wiki/Feature_extraction" class="italic" target="_blank" rel="noreferrer" data-state="closed">audio feature extraction</a>.</p></li></ul><h3 id="data" class="relative group"><span class="heading-text">Data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#data" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3><p>Machine listening relies on various types of data:</p><ul><li><p><strong>Symbolic Data</strong>: Representations like <a href="https://en.wikipedia.org/wiki/MIDI" class="italic" target="_blank" rel="noreferrer" data-state="closed">MIDI</a> and <a href="https://en.wikipedia.org/wiki/MusicXML" class="italic" target="_blank" rel="noreferrer" data-state="closed">MusicXML</a>.</p></li><li><p><strong>Subsymbolic Data</strong>: Includes raw audio, video, and sensor data.</p></li><li><p><strong>Metadata</strong>: Information about the audio, such as artist or album details. Learn about <a href="https://en.wikipedia.org/wiki/Metadata" class="italic" target="_blank" rel="noreferrer" data-state="closed">metadata</a>.</p></li><li><p><strong>Paradata</strong>: Data about the process of data collection or analysis.</p></li><li><p><strong>User Data</strong>: Information about user interactions and preferences.</p></li></ul><h3 id="artificial-intelligence-ai" class="relative group"><span class="heading-text">Artificial Intelligence (AI)</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#artificial-intelligence-ai" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3><p>AI techniques in machine listening can be categorized as:</p><ul><li><p><strong>Rule-Based Systems</strong>: Systems that rely on predefined rules and <a href="https://en.wikipedia.org/wiki/Statistics" class="italic" target="_blank" rel="noreferrer" data-state="closed">statistics</a>.</p></li><li><p><strong>Learning-Based Systems</strong>: Systems that use machine learning to adapt and improve. Learn about <a href="https://en.wikipedia.org/wiki/Machine_learning" class="italic" target="_blank" rel="noreferrer" data-state="closed">machine learning</a>.</p></li></ul><h3 id="time" class="relative group"><span class="heading-text">Time</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#time" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3><p>Machine listening systems can operate in different time modes:</p><ul><li><p><strong>Realtime</strong>: Systems that process audio as it is received, such as <a href="https://en.wikipedia.org/wiki/Real-time_computing" class="italic" target="_blank" rel="noreferrer" data-state="closed">online systems</a>.</p></li><li><p><strong>Non-Realtime</strong>: Systems that process audio after it has been recorded, such as <a href="https://en.wikipedia.org/wiki/Batch_processing" class="italic" target="_blank" rel="noreferrer" data-state="closed">offline systems</a>.</p></li></ul><aside class="myst-admonition myst-admonition-note my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-blue-500"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-blue-600 bg-blue-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-blue-600"><path stroke-linecap="round" stroke-linejoin="round" d="m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Note</div></div><div class="myst-admonition-body px-4 py-1"><p>SonicVisualiser</p></div></aside><h2 id="citations" class="relative group"><span class="heading-text">Citations</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#citations" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h2><p>the following syntax: <code>{cite}`holdgraf_evidence_2014`</code></p><p>Here is the bibliography</p><span></span><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/sensingsoundandmusic/week10"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Sensing Sound and Music</div>Week 10: Physiology</div></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/sensingsoundandmusic/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-JSE36H2O.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-C7FW3E47.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-ND43KHSX.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/root-IB5726YR.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-NBON2RSI.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/routes/$-LXLHKVOR.js"/><script>window.__remixContext = {"url":"/week11","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.1","options":{"favicon":"/sensingsoundandmusic/build/favicon-2720eef16358a9679c7ec109a6d05906.ico"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"exports":[],"title":"Sensing Sound and Music","description":"An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives.","authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"id":"11cc8b5a-b0a2-4516-8397-a7dbad782f82","toc":[{"file":"intro.md"},{"file":"week1.md"},{"file":"week2.md"},{"file":"week3.ipynb"},{"file":"week4.ipynb"},{"file":"week5.md"},{"file":"week6.ipynb"},{"file":"week7.md"},{"file":"week8.md"},{"file":"week9.md"},{"file":"week10.md"},{"file":"week11.md"}],"bibliography":[],"index":"index","pages":[{"slug":"week1","title":"Week 1: Tuning in","description":"This page introduces the foundational concepts of music psychology and technology, exploring how humans perceive, experience, and create sound and music through both psychological and technological perspectives.","date":"","thumbnail":"/sensingsoundandmusic/build/c20d5f224f701120b83307814eab6564.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week2","title":"Week 2: Listening","description":"This chapter explores the art and science of listening, focusing on how sounds and soundscapes are described, understood, and analyzed across disciplines. It introduces influential theories and thinkers, practical listening exercises, and tools for engaging with the sonic environment.","date":"","thumbnail":"/sensingsoundandmusic/build/impulsive-sustained--c0c48158496bcc681fba65df66fa6f2f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week3","title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","date":"","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week4","title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacousticsâ€”the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","date":"","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week5","title":"Week 5: Time and Rhythm","description":"This chapter explores the foundations of musical time and rhythm, covering concepts such as onset timing, perceptual centers, meter, microrhythm, groove, and entrainment. It examines how rhythm is structured, perceived, and performed, highlighting the roles of technology and analysis tools in understanding the nuances of timing and groove in various musical styles.","date":"","thumbnail":"/sensingsoundandmusic/build/week5_image6-42ef9fdd71a421c1baf682d65217062b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week6","title":"Week 6: Harmony and melody","description":"This notebook explores the concepts of harmony, melody, and musical structure through both theoretical explanations and practical visualizations. It covers fundamental audio representations, symbolic music formats, and provides code examples for analyzing and visualizing musical elements using Python.","date":"","thumbnail":"/sensingsoundandmusic/build/week6_image2-4fa03b8bde3b7bda89ece8a2ac6da510.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week7","title":"Week 7: Body Motion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week8","title":"Week 8: The Brain","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/0698af3bcaf829b93eb28d09596d0541.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week9","title":"Week 9: Vision","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week10","title":"Week 10: Physiology","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week11","title":"Week 11: Machine Listening","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/sensingsoundandmusic"},"routes/$":{"config":{"version":2,"myst":"1.6.1","options":{"favicon":"/sensingsoundandmusic/build/favicon-2720eef16358a9679c7ec109a6d05906.ico"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"exports":[],"title":"Sensing Sound and Music","description":"An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives.","authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"id":"11cc8b5a-b0a2-4516-8397-a7dbad782f82","toc":[{"file":"intro.md"},{"file":"week1.md"},{"file":"week2.md"},{"file":"week3.ipynb"},{"file":"week4.ipynb"},{"file":"week5.md"},{"file":"week6.ipynb"},{"file":"week7.md"},{"file":"week8.md"},{"file":"week9.md"},{"file":"week10.md"},{"file":"week11.md"}],"bibliography":[],"index":"index","pages":[{"slug":"week1","title":"Week 1: Tuning in","description":"This page introduces the foundational concepts of music psychology and technology, exploring how humans perceive, experience, and create sound and music through both psychological and technological perspectives.","date":"","thumbnail":"/sensingsoundandmusic/build/c20d5f224f701120b83307814eab6564.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week2","title":"Week 2: Listening","description":"This chapter explores the art and science of listening, focusing on how sounds and soundscapes are described, understood, and analyzed across disciplines. It introduces influential theories and thinkers, practical listening exercises, and tools for engaging with the sonic environment.","date":"","thumbnail":"/sensingsoundandmusic/build/impulsive-sustained--c0c48158496bcc681fba65df66fa6f2f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week3","title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","date":"","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week4","title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacousticsâ€”the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","date":"","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week5","title":"Week 5: Time and Rhythm","description":"This chapter explores the foundations of musical time and rhythm, covering concepts such as onset timing, perceptual centers, meter, microrhythm, groove, and entrainment. It examines how rhythm is structured, perceived, and performed, highlighting the roles of technology and analysis tools in understanding the nuances of timing and groove in various musical styles.","date":"","thumbnail":"/sensingsoundandmusic/build/week5_image6-42ef9fdd71a421c1baf682d65217062b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week6","title":"Week 6: Harmony and melody","description":"This notebook explores the concepts of harmony, melody, and musical structure through both theoretical explanations and practical visualizations. It covers fundamental audio representations, symbolic music formats, and provides code examples for analyzing and visualizing musical elements using Python.","date":"","thumbnail":"/sensingsoundandmusic/build/week6_image2-4fa03b8bde3b7bda89ece8a2ac6da510.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week7","title":"Week 7: Body Motion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week8","title":"Week 8: The Brain","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/0698af3bcaf829b93eb28d09596d0541.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week9","title":"Week 9: Vision","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week10","title":"Week 10: Physiology","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week11","title":"Week 11: Machine Listening","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":2,"kind":"Article","sha256":"34ef44507ebc731c8e49561e720fc274a7a8d4304c6252608ae0b55197040dc7","slug":"week11","location":"/week11.md","dependencies":[],"frontmatter":{"title":"Week 11: Machine Listening","content_includes_title":false,"authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"source_url":"https://github.com/fourMs/sensingsoundandmusic/blob/main/book/week11.md","edit_url":"https://github.com/fourMs/sensingsoundandmusic/edit/main/book/week11.md","exports":[{"format":"md","filename":"week11.md","url":"/sensingsoundandmusic/build/week11-a2cae0b2ac2e229f6dd018f91fd8a327.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Machine Listening","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wFy4Mb0Q0S"}],"identifier":"machine-listening","label":"Machine Listening","html_id":"machine-listening","implicit":true,"key":"K2Ihu1PPEk"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Machine listening is a field of study that focuses on enabling machines to interpret and analyze audio signals. It has applications in various domains, including music, speech, and environmental sound analysis.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"JuPeNK3VlT"}],"key":"kpj0cv01u8"},{"type":"heading","depth":3,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Information Retrieval","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"UfhPCIiCqy"}],"identifier":"information-retrieval","label":"Information Retrieval","html_id":"information-retrieval","implicit":true,"key":"RXjeFjxVwB"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Information retrieval in machine listening involves extracting meaningful information from audio data. Key areas include:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Xl1qWFmDaB"}],"key":"Arig6zeBQw"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":11,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Classification","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"yi4EbAIb29"}],"key":"C9VYfw3s7p"},{"type":"text","value":": This involves categorizing audio into predefined classes, such as:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"LTFRglZt6I"}],"key":"iZgpbRdVzb"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":12,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Music_genre","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Genre","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"f8MwpY6gnV"}],"urlSource":"https://en.wikipedia.org/wiki/Music_genre","data":{"page":"Music_genre","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"SdiMSQMaY2"}],"key":"wXOIqyjHjX"}],"key":"AcRlwrlj7P"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Musical_instrument","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Instruments","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"IR1tHe9ozs"}],"urlSource":"https://en.wikipedia.org/wiki/Musical_instrument","data":{"page":"Musical_instrument","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"cWyCGSo7Vp"}],"key":"mp8V72ABPf"}],"key":"wuwCTsQd2q"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Mood_(psychology)","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Mood","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"xPqYvBrwQa"}],"urlSource":"https://en.wikipedia.org/wiki/Mood_(psychology)","data":{"page":"Mood_(psychology)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"Sy8KiDjRo4"}],"key":"uunOetAJew"}],"key":"YYHaUKl22F"}],"key":"NW0Rg6u4C4"}],"key":"RodNeceVBU"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Recommendation","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"Lan9BWUyE7"}],"key":"czYFbNmgQS"},{"type":"text","value":": Systems that suggest music or audio content based on user preferences. Learn more about ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"hHEo9qLNqp"},{"type":"link","url":"https://en.wikipedia.org/wiki/Recommender_system","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"recommender systems","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"U9i7jzvY7a"}],"urlSource":"https://en.wikipedia.org/wiki/Recommender_system","data":{"page":"Recommender_system","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"fh72aEmaW2"},{"type":"text","value":".","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"ZkfQvdANHm"}],"key":"LLYyo9opIw"}],"key":"q8yJB19g32"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Source Separation","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"x1bF8TmB3M"}],"key":"NQBtNDOaz7"},{"type":"text","value":": The process of isolating individual sound sources from a mixture. See ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"hvCuYJZR7I"},{"type":"link","url":"https://en.wikipedia.org/wiki/Audio_signal_processing#Source_separation","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"source separation","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"G1N4K1jnQP"}],"urlSource":"https://en.wikipedia.org/wiki/Audio_signal_processing#Source_separation","data":{"page":"Audio_signal_processing#Source_separation","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"sXlR8SPHgH"},{"type":"text","value":".","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"RSUXgXFxRF"}],"key":"rDo44gwcv5"}],"key":"AMOh7N4Ogw"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Transcription","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"CJp4AebmlL"}],"key":"n8TVAW8VEz"},{"type":"text","value":": Converting audio into symbolic representations like sheet music. Learn about ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"HRP0wQufbQ"},{"type":"link","url":"https://en.wikipedia.org/wiki/Music_transcription","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"music transcription","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"p2laIcw9oq"}],"urlSource":"https://en.wikipedia.org/wiki/Music_transcription","data":{"page":"Music_transcription","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"MYkl2GVZ4z"},{"type":"text","value":".","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"jOCvGWVx1h"}],"key":"xSGyBDH2td"}],"key":"gyZrFtXAO8"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Question-Answering","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"nVCi5iy1ne"}],"key":"fyZ0iK37cg"},{"type":"text","value":": Systems that answer questions based on audio content.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"HNOYBEMvWZ"}],"key":"OCRTDHJhiI"}],"key":"BLXw22qfWv"},{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Segmentation","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"y66RIEOqR8"}],"key":"v6YWKFJ2Rf"},{"type":"text","value":": Dividing audio into meaningful segments, such as verses or choruses in music.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"pjjWl9zxLg"}],"key":"AwJSmi3pGO"}],"key":"bOco05PQ8l"},{"type":"listItem","spread":true,"position":{"start":{"line":20,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"Feature Extraction","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"yRcwTSuekO"}],"key":"ekq7Xv6W8u"},{"type":"text","value":": Extracting characteristics like pitch, tempo, or timbre from audio. See ","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"lUKpm8ldP6"},{"type":"link","url":"https://en.wikipedia.org/wiki/Feature_extraction","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"audio feature extraction","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"ew7o21wnof"}],"urlSource":"https://en.wikipedia.org/wiki/Feature_extraction","data":{"page":"Feature_extraction","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"QjiIMn56i9"},{"type":"text","value":".","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"Rfe2Phbnp0"}],"key":"BX0PI4zIbn"}],"key":"KwaIRlaSVD"}],"key":"ZW5UcxvVbJ"},{"type":"heading","depth":3,"position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Data","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"AHjLteHyMH"}],"identifier":"data","label":"Data","html_id":"data","implicit":true,"key":"knb5vmygLh"},{"type":"paragraph","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"Machine listening relies on various types of data:","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"h7TSGxEJ08"}],"key":"GpVOClLtcX"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":26,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"Symbolic Data","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"i6p10iTdub"}],"key":"tZsjmGWwBu"},{"type":"text","value":": Representations like ","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"MszwKbFnCU"},{"type":"link","url":"https://en.wikipedia.org/wiki/MIDI","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"MIDI","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"D0Zm2SbeZy"}],"urlSource":"https://en.wikipedia.org/wiki/MIDI","data":{"page":"MIDI","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"GvAM3aUlUJ"},{"type":"text","value":" and ","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"ZOoNodoGiW"},{"type":"link","url":"https://en.wikipedia.org/wiki/MusicXML","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"MusicXML","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"tzb9qmJV5l"}],"urlSource":"https://en.wikipedia.org/wiki/MusicXML","data":{"page":"MusicXML","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"u82gJyH4Ba"},{"type":"text","value":".","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"W1iOLaV5fe"}],"key":"yTtaPC1YFh"}],"key":"mTV5UdW84J"},{"type":"listItem","spread":true,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Subsymbolic Data","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"ili2O7tXwT"}],"key":"BELFmSX3pP"},{"type":"text","value":": Includes raw audio, video, and sensor data.","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"cY8l1xr7M5"}],"key":"qiPBhqiBtn"}],"key":"Y0TEOjgftI"},{"type":"listItem","spread":true,"position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"Metadata","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"FAPZDzQsHW"}],"key":"WE3DnPB2kq"},{"type":"text","value":": Information about the audio, such as artist or album details. Learn about ","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"JugRCxjn2n"},{"type":"link","url":"https://en.wikipedia.org/wiki/Metadata","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"metadata","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"khnToR2oD4"}],"urlSource":"https://en.wikipedia.org/wiki/Metadata","data":{"page":"Metadata","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"jzHPaaP4rR"},{"type":"text","value":".","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"LVExQVMJwX"}],"key":"q8oGi5PmFx"}],"key":"E0yjdp0otA"},{"type":"listItem","spread":true,"position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Paradata","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"Xh9VsfVNgw"}],"key":"dmkC1HyfJR"},{"type":"text","value":": Data about the process of data collection or analysis.","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"VipzV7IXVM"}],"key":"kyugWwMwTL"}],"key":"hlAV7oYr29"},{"type":"listItem","spread":true,"position":{"start":{"line":30,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"User Data","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"mfrfWjCwuM"}],"key":"KBOBsdoP80"},{"type":"text","value":": Information about user interactions and preferences.","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"Q6iyOd3JZY"}],"key":"x1Yp4qOUw9"}],"key":"jKfUFuHzpP"}],"key":"TDjDN3CUrw"},{"type":"heading","depth":3,"position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"Artificial Intelligence (AI)","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"lniHNeFYqx"}],"identifier":"artificial-intelligence-ai","label":"Artificial Intelligence (AI)","html_id":"artificial-intelligence-ai","implicit":true,"key":"mtf0knS3AB"},{"type":"paragraph","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"AI techniques in machine listening can be categorized as:","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"Opccsz0QRv"}],"key":"dWOY4aeUhu"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":37,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"Rule-Based Systems","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"f4JeuPIMUH"}],"key":"VsFSzXaLid"},{"type":"text","value":": Systems that rely on predefined rules and ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"ALwNmD0h40"},{"type":"link","url":"https://en.wikipedia.org/wiki/Statistics","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"statistics","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"ZASNFF7qy1"}],"urlSource":"https://en.wikipedia.org/wiki/Statistics","data":{"page":"Statistics","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"tTNO36igF9"},{"type":"text","value":".","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"fF9ZRGlxjh"}],"key":"WCnfdJpAIe"}],"key":"HcH2zCUkci"},{"type":"listItem","spread":true,"position":{"start":{"line":38,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Learning-Based Systems","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"pWUZmFykdE"}],"key":"xn9k8814A8"},{"type":"text","value":": Systems that use machine learning to adapt and improve. Learn about ","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"lerNMm5mHX"},{"type":"link","url":"https://en.wikipedia.org/wiki/Machine_learning","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"machine learning","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"kPdvQBryJV"}],"urlSource":"https://en.wikipedia.org/wiki/Machine_learning","data":{"page":"Machine_learning","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"AwfnBBGJyi"},{"type":"text","value":".","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"kbAAhd7klC"}],"key":"BYqbaXIkji"}],"key":"c5JYZRe7M8"}],"key":"Hfp9r28JwB"},{"type":"heading","depth":3,"position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"Time","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"Hz2bDDuYrW"}],"identifier":"time","label":"Time","html_id":"time","implicit":true,"key":"AQI8yIyN7u"},{"type":"paragraph","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"Machine listening systems can operate in different time modes:","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"EPDDDWhPt6"}],"key":"VMSrxNCeLj"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":44,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"Realtime","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"vaefGz47RM"}],"key":"Xft1BtrK64"},{"type":"text","value":": Systems that process audio as it is received, such as ","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"HrmVT8fWi3"},{"type":"link","url":"https://en.wikipedia.org/wiki/Real-time_computing","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"online systems","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"tUXMFtWULB"}],"urlSource":"https://en.wikipedia.org/wiki/Real-time_computing","data":{"page":"Real-time_computing","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"WWw9ppx8NU"},{"type":"text","value":".","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"U4uTOJ3g2a"}],"key":"MOaAgm0WwW"}],"key":"BH3Ua0KJ9M"},{"type":"listItem","spread":true,"position":{"start":{"line":45,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"Non-Realtime","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"W8v2okQb2d"}],"key":"vFVKRddLNW"},{"type":"text","value":": Systems that process audio after it has been recorded, such as ","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"lI47HRSQ6b"},{"type":"link","url":"https://en.wikipedia.org/wiki/Batch_processing","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"offline systems","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"ydC8BpA589"}],"urlSource":"https://en.wikipedia.org/wiki/Batch_processing","data":{"page":"Batch_processing","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"kwUvrXSrxf"},{"type":"text","value":".","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"yidpnpIj5c"}],"key":"G2f2jKyleZ"}],"key":"f8IRuvo0As"}],"key":"MLcGWf9x2Y"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"SM6xkU6MBG"}],"key":"ZOaMwf6qNm"},{"type":"paragraph","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"SonicVisualiser","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"A4ss6XnTJk"}],"key":"ij7eHWb3Xw"}],"key":"QxbmRQp8nI"},{"type":"heading","depth":2,"position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"text","value":"Citations","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"ikpPV2xaBJ"}],"identifier":"citations","label":"Citations","html_id":"citations","implicit":true,"key":"IrvV9irR78"},{"type":"paragraph","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"the following syntax: ","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"ZE4dWMzqF4"},{"type":"inlineCode","value":"{cite}`holdgraf_evidence_2014`","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"ppXpJ6YFII"}],"key":"Nih17jWnbK"},{"type":"paragraph","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"text","value":"Here is the bibliography","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"uUkRR06jHw"}],"key":"XKFRF7iIgK"},{"type":"bibliography","key":"cFQ68bRWib"}],"key":"FYCKh3bL7y"}],"key":"VKvVfFJgog"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Week 10: Physiology","url":"/week10","group":"Sensing Sound and Music"}}},"domain":"http://localhost:3000"},"project":{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"exports":[],"title":"Sensing Sound and Music","description":"An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives.","authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"id":"11cc8b5a-b0a2-4516-8397-a7dbad782f82","toc":[{"file":"intro.md"},{"file":"week1.md"},{"file":"week2.md"},{"file":"week3.ipynb"},{"file":"week4.ipynb"},{"file":"week5.md"},{"file":"week6.ipynb"},{"file":"week7.md"},{"file":"week8.md"},{"file":"week9.md"},{"file":"week10.md"},{"file":"week11.md"}],"bibliography":[],"index":"index","pages":[{"slug":"week1","title":"Week 1: Tuning in","description":"This page introduces the foundational concepts of music psychology and technology, exploring how humans perceive, experience, and create sound and music through both psychological and technological perspectives.","date":"","thumbnail":"/sensingsoundandmusic/build/c20d5f224f701120b83307814eab6564.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week2","title":"Week 2: Listening","description":"This chapter explores the art and science of listening, focusing on how sounds and soundscapes are described, understood, and analyzed across disciplines. It introduces influential theories and thinkers, practical listening exercises, and tools for engaging with the sonic environment.","date":"","thumbnail":"/sensingsoundandmusic/build/impulsive-sustained--c0c48158496bcc681fba65df66fa6f2f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week3","title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","date":"","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week4","title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacousticsâ€”the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","date":"","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week5","title":"Week 5: Time and Rhythm","description":"This chapter explores the foundations of musical time and rhythm, covering concepts such as onset timing, perceptual centers, meter, microrhythm, groove, and entrainment. It examines how rhythm is structured, perceived, and performed, highlighting the roles of technology and analysis tools in understanding the nuances of timing and groove in various musical styles.","date":"","thumbnail":"/sensingsoundandmusic/build/week5_image6-42ef9fdd71a421c1baf682d65217062b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week6","title":"Week 6: Harmony and melody","description":"This notebook explores the concepts of harmony, melody, and musical structure through both theoretical explanations and practical visualizations. It covers fundamental audio representations, symbolic music formats, and provides code examples for analyzing and visualizing musical elements using Python.","date":"","thumbnail":"/sensingsoundandmusic/build/week6_image2-4fa03b8bde3b7bda89ece8a2ac6da510.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week7","title":"Week 7: Body Motion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week8","title":"Week 8: The Brain","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/0698af3bcaf829b93eb28d09596d0541.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week9","title":"Week 9: Vision","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week10","title":"Week 10: Physiology","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week11","title":"Week 11: Machine Listening","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/sensingsoundandmusic/build/manifest-B2B2E6A5.js";
import * as route0 from "/sensingsoundandmusic/build/root-IB5726YR.js";
import * as route1 from "/sensingsoundandmusic/build/routes/$-LXLHKVOR.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/sensingsoundandmusic/build/entry.client-UNPC4GT3.js");</script></body></html>