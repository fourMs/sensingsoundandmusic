<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Week 9: Vision - Sensing Sound and Music</title><meta property="og:title" content="Week 9: Vision - Sensing Sound and Music"/><meta name="generator" content="mystmd"/><meta name="description" content="An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives."/><meta property="og:description" content="An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives."/><meta name="keywords" content="sensing, sound, music, psychology, technology"/><meta name="image" content="/sensingsoundandmusic/build/undefined"/><meta property="og:image" content="/sensingsoundandmusic/build/undefined"/><link rel="stylesheet" href="/sensingsoundandmusic/build/_assets/app-5WKS5EPQ.css"/><link rel="stylesheet" href="/sensingsoundandmusic/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/sensingsoundandmusic/favicon.ico"/><link rel="stylesheet" href="/sensingsoundandmusic/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/sensingsoundandmusic/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Sensing Sound and Music" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/sensingsoundandmusic/">Sensing Sound and Music</a><a title="Week 1: Tuning in" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week1">Week 1: Tuning in</a><a title="Week 2: Listening" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week2">Week 2: Listening</a><a title="Week 3: Acoustics" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week3">Week 3: Acoustics</a><a title="Week 4: Psychoacoustics" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week4">Week 4: Psychoacoustics</a><a title="Week 5: Time and Rhythm" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week5">Week 5: Time and Rhythm</a><a title="Week 6: Harmony and melody" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week6">Week 6: Harmony and melody</a><a title="Week 7: Body Motion" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week7">Week 7: Body Motion</a><a title="Week 8: The Brain" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week8">Week 8: The Brain</a><a title="Week 9: Vision" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week9">Week 9: Vision</a><a title="Week 10: Physiology" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week10">Week 10: Physiology</a><a title="Week 11: Machine Listening" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week11">Week 11: Machine Listening</a></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Open_access" target="_blank" rel="noopener noreferrer" title="Open Access" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="mr-1 inline-block opacity-60 hover:opacity-100 hover:text-[#E18435]"><path d="M17.1 12.6h-2V7.5c0-1.7-1.4-3.1-3-3.1-.8 0-1.6.3-2.2.9-.6.5-.9 1.3-.9 2.2v.7H7v-.7c0-1.4.5-2.7 1.5-3.7s2.2-1.5 3.6-1.5 2.6.5 3.6 1.5 1.5 2.3 1.5 3.7v5.1z"></path><path d="M12 21.8c-.8 0-1.6-.2-2.3-.5-.7-.3-1.4-.8-1.9-1.3-.6-.6-1-1.2-1.3-2-.3-.8-.5-1.6-.5-2.4s.2-1.6.5-2.4c.3-.7.7-1.4 1.3-2s1.2-1 1.9-1.3c.7-.3 1.5-.5 2.3-.5.8 0 1.6.2 2.3.5.7.3 1.4.8 1.9 1.3.6.6 1 1.2 1.3 2 .3.8.5 1.6.5 2.4s-.2 1.6-.5 2.4c-.3.7-.7 1.4-1.3 2-.6.6-1.2 1-1.9 1.3-.7.3-1.5.5-2.3.5zm0-10.3c-2.2 0-4 1.8-4 4.1s1.8 4.1 4 4.1 4-1.8 4-4.1-1.8-4.1-4-4.1z"></path><circle cx="12" cy="15.6" r="1.7"></circle></svg></a><a href="https://github.com/fourMs/sensingsoundandmusic" title="GitHub Repository: fourMs/sensingsoundandmusic" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/fourMs/sensingsoundandmusic/edit/main/book/week9.md" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Week 9: Vision</h1><header class="mt-4 not-prose"><div><span class="font-semibold text-sm inline-block text-comma"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rb8top:" data-state="closed">MUS2640</button></span><span class="font-semibold text-sm inline-block"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rd8top:" data-state="closed">University of Oslo</button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><h2 id="audiovisuality" class="relative group"><span class="heading-text">Audiovisuality</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#audiovisuality" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="physics" class="relative group"><span class="heading-text">Physics</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#physics" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li><p><a href="https://en.wikipedia.org/wiki/Light" class="italic" target="_blank" rel="noreferrer" data-state="closed"><strong>Light</strong></a>: Light is electromagnetic radiation within the visible spectrum, enabling vision and the perception of color, shape, and movement. It is fundamental to how we interpret our surroundings. Light behaves both as a wave and as a particle (photon), and its properties—such as wavelength and intensity—determine how we perceive brightness and color.</p></li><li><p><a href="https://en.wikipedia.org/wiki/Sound" class="italic" target="_blank" rel="noreferrer" data-state="closed"><strong>Sound</strong></a>: Sound consists of mechanical vibrations that travel through a medium (such as air or water) and are perceived by the auditory system. It underpins communication, music, and environmental awareness. Sound is characterized by properties like frequency (pitch), amplitude (loudness), and timbre (quality).</p></li></ul><h3 id="representation" class="relative group"><span class="heading-text">Representation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#representation" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li><p><a href="https://en.wikipedia.org/wiki/Audio" class="italic" target="_blank" rel="noreferrer" data-state="closed"><strong>Audio</strong></a>: Audio encompasses the capture, transmission, and reproduction of sound. It is essential in media, communication, and interactive technologies, allowing for the sharing and analysis of auditory information. Audio signals can be analog or digital, and are often processed for clarity, compression, or creative effect.</p></li><li><p><a href="https://en.wikipedia.org/wiki/Video" class="italic" target="_blank" rel="noreferrer" data-state="closed"><strong>Video</strong></a>: Video involves recording, processing, and displaying sequences of moving images. It is a versatile medium for conveying information, storytelling, education, and entertainment. Video signals can be analog or digital, and are defined by parameters such as frame rate, resolution, and color depth.</p></li></ul><p>These fundamental physical concepts and their representations form the basis for understanding audiovisual systems and technologies, as well as the ways in which humans perceive and interact with their environment.</p><h4 id="auditory-visual" class="relative group"><span class="heading-text">Auditory-visual</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#auditory-visual" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><p><strong>Auditory-visual</strong>: Auditory-visual integration refers to the brain’s ability to combine auditory and visual information to enhance perception and understanding. This phenomenon is essential in activities like speech comprehension and multimedia experiences. <a href="https://en.wikipedia.org/wiki/Audiovisual" class="italic" target="_blank" rel="noreferrer" data-state="closed">Learn more on Wikipedia</a>.</p></li></ul><h4 id="multimodal" class="relative group"><span class="heading-text">Multimodal</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#multimodal" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><p><strong>Multimodal</strong>: Multimodal perception involves the integration of information from multiple sensory modalities, such as sight, sound, and touch, to create a cohesive understanding of the environment. <a href="https://en.wikipedia.org/wiki/Multimodal_perception" class="italic" target="_blank" rel="noreferrer" data-state="closed">Learn more on Wikipedia</a>.</p></li></ul><h4 id="crossmodal" class="relative group"><span class="heading-text">Crossmodal</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#crossmodal" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><p><strong>McGurk effect</strong>: The McGurk effect is a perceptual phenomenon where conflicting auditory and visual stimuli result in a third, distinct perception. It highlights the complex interplay between sensory modalities. <a href="https://en.wikipedia.org/wiki/McGurk_effect" class="italic" target="_blank" rel="noreferrer" data-state="closed">Learn more on Wikipedia</a>.</p></li></ul><h2 id="psychology" class="relative group"><span class="heading-text">Psychology</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#psychology" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="gaze" class="relative group"><span class="heading-text">Gaze</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#gaze" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Gaze refers to the direction in which a person is looking, often used as an indicator of attention and focus. It plays a crucial role in understanding human behavior, communication, and cognitive processes. Gaze tracking is commonly used in psychological studies to analyze visual attention and social interactions. <a href="https://en.wikipedia.org/wiki/Gaze" class="italic" target="_blank" rel="noreferrer" data-state="closed">Learn more on Wikipedia</a>.</p><img id="tfVgWvSCBl" style="margin:0 auto" src="/sensingsoundandmusic/build/undefined" alt="Gaze example" data-canonical-url="https://upload.wikimedia.org/wikipedia/commons/3/3c/Eye_tracking_software.png" class=""/><h3 id="pupillometry" class="relative group"><span class="heading-text">Pupillometry</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#pupillometry" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Pupillometry is the measurement of pupil size and reactivity, often used to study cognitive and emotional processes. Changes in pupil size can indicate arousal, attention, and mental effort. This technique is widely applied in psychology, neuroscience, and human-computer interaction research. <a href="https://en.wikipedia.org/wiki/Pupillometry" class="italic" target="_blank" rel="noreferrer" data-state="closed">Learn more on Wikipedia</a>.</p><img id="c0indmjV6u" style="margin:0 auto" src="/sensingsoundandmusic/build/undefined" alt="Pupillometry example" data-canonical-url="https://upload.wikimedia.org/wikipedia/commons/4/4c/Pupil_dilation.png" class=""/><h2 id="technology" class="relative group"><span class="heading-text">Technology</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#technology" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="eye-trackers" class="relative group"><span class="heading-text">Eye-Trackers</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#eye-trackers" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Eye-trackers are devices used to measure eye positions and movements. They are widely used in research fields such as psychology, neuroscience, marketing, and human-computer interaction. Eye-trackers can be categorized into two main types: mobile and stationary.</p><h4 id="mobile-eye-trackers" class="relative group"><span class="heading-text">Mobile Eye-Trackers</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#mobile-eye-trackers" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Mobile eye-trackers are wearable devices that allow for the tracking of eye movements in real-world environments. These devices are often used in studies that require participants to move freely, such as sports performance analysis, usability testing, and outdoor experiments. <a href="https://en.wikipedia.org/wiki/Eye_tracking" class="italic" target="_blank" rel="noreferrer" data-state="closed">Learn more on Wikipedia</a>.</p><p><img id="mJ3g6PaE95" style="margin:0 auto" src="/sensingsoundandmusic/build/undefined" alt="Mobile Eye-Tracker" data-canonical-url="https://upload.wikimedia.org/wikipedia/commons/6/6e/Eye_tracking_glasses.jpg" class=""/>
<em>Figure 1: Example of mobile eye-tracking glasses. Image credit: Wikimedia Commons.</em></p><h4 id="stationary-eye-trackers" class="relative group"><span class="heading-text">Stationary Eye-Trackers</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#stationary-eye-trackers" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Stationary eye-trackers are fixed devices typically used in controlled laboratory settings. They are often mounted on a desk or integrated into a monitor and are used for tasks such as reading studies, visual search experiments, and website usability testing. <a href="https://en.wikipedia.org/wiki/Eye_tracking" class="italic" target="_blank" rel="noreferrer" data-state="closed">Learn more on Wikipedia</a>.</p><p><img id="Od3Jg7jzdz" style="margin:0 auto" src="/sensingsoundandmusic/build/undefined" alt="Stationary Eye-Tracker" data-canonical-url="https://upload.wikimedia.org/wikipedia/commons/3/3c/Eye_tracking_software.png" class=""/>
<em>Figure 2: Example of stationary eye-tracking software. Image credit: Wikimedia Commons.</em></p><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/sensingsoundandmusic/week8"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Sensing Sound and Music</div>Week 8: The Brain</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/sensingsoundandmusic/week10"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Sensing Sound and Music</div>Week 10: Physiology</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/sensingsoundandmusic/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-JSE36H2O.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-C7FW3E47.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-ND43KHSX.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/root-IB5726YR.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-NBON2RSI.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/routes/$-LXLHKVOR.js"/><script>window.__remixContext = {"url":"/week9","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.1","options":{"favicon":"/sensingsoundandmusic/build/favicon-2720eef16358a9679c7ec109a6d05906.ico"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"exports":[],"title":"Sensing Sound and Music","description":"An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives.","authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"id":"11cc8b5a-b0a2-4516-8397-a7dbad782f82","toc":[{"file":"intro.md"},{"file":"week1.md"},{"file":"week2.md"},{"file":"week3.ipynb"},{"file":"week4.ipynb"},{"file":"week5.md"},{"file":"week6.ipynb"},{"file":"week7.md"},{"file":"week8.md"},{"file":"week9.md"},{"file":"week10.md"},{"file":"week11.md"}],"bibliography":[],"index":"index","pages":[{"slug":"week1","title":"Week 1: Tuning in","description":"This page introduces the foundational concepts of music psychology and technology, exploring how humans perceive, experience, and create sound and music through both psychological and technological perspectives.","date":"","thumbnail":"/sensingsoundandmusic/build/c20d5f224f701120b83307814eab6564.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week2","title":"Week 2: Listening","description":"This chapter explores the art and science of listening, focusing on how sounds and soundscapes are described, understood, and analyzed across disciplines. It introduces influential theories and thinkers, practical listening exercises, and tools for engaging with the sonic environment.","date":"","thumbnail":"/sensingsoundandmusic/build/impulsive-sustained--c0c48158496bcc681fba65df66fa6f2f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week3","title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","date":"","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week4","title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacoustics—the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","date":"","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week5","title":"Week 5: Time and Rhythm","description":"This chapter explores the foundations of musical time and rhythm, covering concepts such as onset timing, perceptual centers, meter, microrhythm, groove, and entrainment. It examines how rhythm is structured, perceived, and performed, highlighting the roles of technology and analysis tools in understanding the nuances of timing and groove in various musical styles.","date":"","thumbnail":"/sensingsoundandmusic/build/week5_image6-42ef9fdd71a421c1baf682d65217062b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week6","title":"Week 6: Harmony and melody","description":"This notebook explores the concepts of harmony, melody, and musical structure through both theoretical explanations and practical visualizations. It covers fundamental audio representations, symbolic music formats, and provides code examples for analyzing and visualizing musical elements using Python.","date":"","thumbnail":"/sensingsoundandmusic/build/week6_image2-4fa03b8bde3b7bda89ece8a2ac6da510.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week7","title":"Week 7: Body Motion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week8","title":"Week 8: The Brain","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/0698af3bcaf829b93eb28d09596d0541.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week9","title":"Week 9: Vision","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week10","title":"Week 10: Physiology","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week11","title":"Week 11: Machine Listening","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/sensingsoundandmusic"},"routes/$":{"config":{"version":2,"myst":"1.6.1","options":{"favicon":"/sensingsoundandmusic/build/favicon-2720eef16358a9679c7ec109a6d05906.ico"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"exports":[],"title":"Sensing Sound and Music","description":"An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives.","authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"id":"11cc8b5a-b0a2-4516-8397-a7dbad782f82","toc":[{"file":"intro.md"},{"file":"week1.md"},{"file":"week2.md"},{"file":"week3.ipynb"},{"file":"week4.ipynb"},{"file":"week5.md"},{"file":"week6.ipynb"},{"file":"week7.md"},{"file":"week8.md"},{"file":"week9.md"},{"file":"week10.md"},{"file":"week11.md"}],"bibliography":[],"index":"index","pages":[{"slug":"week1","title":"Week 1: Tuning in","description":"This page introduces the foundational concepts of music psychology and technology, exploring how humans perceive, experience, and create sound and music through both psychological and technological perspectives.","date":"","thumbnail":"/sensingsoundandmusic/build/c20d5f224f701120b83307814eab6564.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week2","title":"Week 2: Listening","description":"This chapter explores the art and science of listening, focusing on how sounds and soundscapes are described, understood, and analyzed across disciplines. It introduces influential theories and thinkers, practical listening exercises, and tools for engaging with the sonic environment.","date":"","thumbnail":"/sensingsoundandmusic/build/impulsive-sustained--c0c48158496bcc681fba65df66fa6f2f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week3","title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","date":"","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week4","title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacoustics—the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","date":"","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week5","title":"Week 5: Time and Rhythm","description":"This chapter explores the foundations of musical time and rhythm, covering concepts such as onset timing, perceptual centers, meter, microrhythm, groove, and entrainment. It examines how rhythm is structured, perceived, and performed, highlighting the roles of technology and analysis tools in understanding the nuances of timing and groove in various musical styles.","date":"","thumbnail":"/sensingsoundandmusic/build/week5_image6-42ef9fdd71a421c1baf682d65217062b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week6","title":"Week 6: Harmony and melody","description":"This notebook explores the concepts of harmony, melody, and musical structure through both theoretical explanations and practical visualizations. It covers fundamental audio representations, symbolic music formats, and provides code examples for analyzing and visualizing musical elements using Python.","date":"","thumbnail":"/sensingsoundandmusic/build/week6_image2-4fa03b8bde3b7bda89ece8a2ac6da510.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week7","title":"Week 7: Body Motion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week8","title":"Week 8: The Brain","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/0698af3bcaf829b93eb28d09596d0541.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week9","title":"Week 9: Vision","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week10","title":"Week 10: Physiology","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week11","title":"Week 11: Machine Listening","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":2,"kind":"Article","sha256":"e0d7a3cca3c0e2d0d018ca6a31adbab0be67454071a99cfb86d6111e48946470","slug":"week9","location":"/week9.md","dependencies":[],"frontmatter":{"title":"Week 9: Vision","content_includes_title":false,"authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"source_url":"https://github.com/fourMs/sensingsoundandmusic/blob/main/book/week9.md","edit_url":"https://github.com/fourMs/sensingsoundandmusic/edit/main/book/week9.md","thumbnail":"/sensingsoundandmusic/build/undefined","exports":[{"format":"md","filename":"week9.md","url":"/sensingsoundandmusic/build/week9-d6857015f0b09a2041080e18c0a599cc.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Audiovisuality","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"GF3rgeX6lH"}],"identifier":"audiovisuality","label":"Audiovisuality","html_id":"audiovisuality","implicit":true,"key":"IIpwdVRalh"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Physics","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"cfc7LvbubB"}],"identifier":"physics","label":"Physics","html_id":"physics","implicit":true,"key":"mge2FR3Ne6"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Light","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Light","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ptHYxy130t"}],"key":"zcgIp6IZsC"}],"urlSource":"https://en.wikipedia.org/wiki/Light","data":{"page":"Light","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"YzyIwwDz7l"},{"type":"text","value":": Light is electromagnetic radiation within the visible spectrum, enabling vision and the perception of color, shape, and movement. It is fundamental to how we interpret our surroundings. Light behaves both as a wave and as a particle (photon), and its properties—such as wavelength and intensity—determine how we perceive brightness and color.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Fp9r10eQeA"}],"key":"UKLuYqnsuE"}],"key":"mgaLGhyqNs"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Sound","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Sound","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"D9cVWjrXC0"}],"key":"Y2OwMxQlmq"}],"urlSource":"https://en.wikipedia.org/wiki/Sound","data":{"page":"Sound","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"HFfTbBncAQ"},{"type":"text","value":": Sound consists of mechanical vibrations that travel through a medium (such as air or water) and are perceived by the auditory system. It underpins communication, music, and environmental awareness. Sound is characterized by properties like frequency (pitch), amplitude (loudness), and timbre (quality).","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"ZLRqNo7UTP"}],"key":"Um8Kz6AqHH"}],"key":"N9riR0i1Tw"}],"key":"OwomQmPo3P"},{"type":"heading","depth":3,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Representation","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"tLYRj0mnZl"}],"identifier":"representation","label":"Representation","html_id":"representation","implicit":true,"key":"R2XDv1GgIH"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":12,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Audio","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"strong","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Audio","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"QPcDXdHi9E"}],"key":"BvNe5SwQat"}],"urlSource":"https://en.wikipedia.org/wiki/Audio","data":{"page":"Audio","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"epbLxdY9PY"},{"type":"text","value":": Audio encompasses the capture, transmission, and reproduction of sound. It is essential in media, communication, and interactive technologies, allowing for the sharing and analysis of auditory information. Audio signals can be analog or digital, and are often processed for clarity, compression, or creative effect.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"wSA7nzg3Gn"}],"key":"wMbGqG0xcd"}],"key":"QNE3W2g4x8"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Video","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Video","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"rTLJ3wkwF3"}],"key":"sWJPEbdmEx"}],"urlSource":"https://en.wikipedia.org/wiki/Video","data":{"page":"Video","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"cVNG52SzCs"},{"type":"text","value":": Video involves recording, processing, and displaying sequences of moving images. It is a versatile medium for conveying information, storytelling, education, and entertainment. Video signals can be analog or digital, and are defined by parameters such as frame rate, resolution, and color depth.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"B5Ni2gE7IM"}],"key":"VM7yX8tUwi"}],"key":"YaYZHkLPs5"}],"key":"DxSOFYD21s"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"These fundamental physical concepts and their representations form the basis for understanding audiovisual systems and technologies, as well as the ways in which humans perceive and interact with their environment.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"zAuj7dPFG8"}],"key":"t0LgN0ctDW"},{"type":"heading","depth":4,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Auditory-visual","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"H1iiKW89gf"}],"identifier":"auditory-visual","label":"Auditory-visual","html_id":"auditory-visual","implicit":true,"key":"GmudBgFFlj"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":19,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Auditory-visual","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"qu6mIsOe0V"}],"key":"aYljo40yAZ"},{"type":"text","value":": Auditory-visual integration refers to the brain’s ability to combine auditory and visual information to enhance perception and understanding. This phenomenon is essential in activities like speech comprehension and multimedia experiences. ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"KmAH2W7L4o"},{"type":"link","url":"https://en.wikipedia.org/wiki/Audiovisual","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Learn more on Wikipedia","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"hgn3xhGgix"}],"urlSource":"https://en.wikipedia.org/wiki/Audiovisual","data":{"page":"Audiovisual","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"CMHq9eZvMz"},{"type":"text","value":".","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"taDvIyauPN"}],"key":"qUNsrzORhn"}],"key":"sHDMoCgiIM"}],"key":"w5FsbEDOZs"},{"type":"heading","depth":4,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Multimodal","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"NmyDHgwrLH"}],"identifier":"multimodal","label":"Multimodal","html_id":"multimodal","implicit":true,"key":"BUj23fx4Jx"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":22,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Multimodal","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"HTjM2bMxDR"}],"key":"nn1bSJGPN8"},{"type":"text","value":": Multimodal perception involves the integration of information from multiple sensory modalities, such as sight, sound, and touch, to create a cohesive understanding of the environment. ","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"dmQiAnUsFK"},{"type":"link","url":"https://en.wikipedia.org/wiki/Multimodal_perception","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Learn more on Wikipedia","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"RcRZLumqNg"}],"urlSource":"https://en.wikipedia.org/wiki/Multimodal_perception","data":{"page":"Multimodal_perception","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"FqCIsagdxO"},{"type":"text","value":".","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"kjifVAg2vX"}],"key":"dAIKxIPaey"}],"key":"H9E40DtW27"}],"key":"sYDtlijgo8"},{"type":"heading","depth":4,"position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"Crossmodal","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"LYdHulLkup"}],"identifier":"crossmodal","label":"Crossmodal","html_id":"crossmodal","implicit":true,"key":"o1RhS8gCvo"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":25,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":25,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"McGurk effect","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"s07jblnuhM"}],"key":"CEcPS5l0Ta"},{"type":"text","value":": The McGurk effect is a perceptual phenomenon where conflicting auditory and visual stimuli result in a third, distinct perception. It highlights the complex interplay between sensory modalities. ","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"za51QzKU3M"},{"type":"link","url":"https://en.wikipedia.org/wiki/McGurk_effect","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Learn more on Wikipedia","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"y0aVhx0cxx"}],"urlSource":"https://en.wikipedia.org/wiki/McGurk_effect","data":{"page":"McGurk_effect","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"q3KzyksgEC"},{"type":"text","value":".","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"X5bIaLv5Ej"}],"key":"gYgoGpu5jm"}],"key":"FAnl6s9Gep"}],"key":"zMxPgtgI7h"},{"type":"heading","depth":2,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Psychology","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"JVE71AxC55"}],"identifier":"psychology","label":"Psychology","html_id":"psychology","implicit":true,"key":"PJbRAZURem"},{"type":"heading","depth":3,"position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Gaze","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"sNU2PJy2ye"}],"identifier":"gaze","label":"Gaze","html_id":"gaze","implicit":true,"key":"X3C6xMmZNo"},{"type":"paragraph","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"Gaze refers to the direction in which a person is looking, often used as an indicator of attention and focus. It plays a crucial role in understanding human behavior, communication, and cognitive processes. Gaze tracking is commonly used in psychological studies to analyze visual attention and social interactions. ","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"HUwnSXtymd"},{"type":"link","url":"https://en.wikipedia.org/wiki/Gaze","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"Learn more on Wikipedia","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"bRZLGwHHsp"}],"urlSource":"https://en.wikipedia.org/wiki/Gaze","data":{"page":"Gaze","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"UMg0mcY40J"},{"type":"text","value":".","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"GM1HGzbG1O"}],"key":"I3h5UJ3udO"},{"type":"image","url":"/sensingsoundandmusic/build/undefined","alt":"Gaze example","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"tfVgWvSCBl","urlSource":"https://upload.wikimedia.org/wikipedia/commons/3/3c/Eye_tracking_software.png"},{"type":"heading","depth":3,"position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Pupillometry","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"lbHe2g4tBe"}],"identifier":"pupillometry","label":"Pupillometry","html_id":"pupillometry","implicit":true,"key":"xHrEB0s0mS"},{"type":"paragraph","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Pupillometry is the measurement of pupil size and reactivity, often used to study cognitive and emotional processes. Changes in pupil size can indicate arousal, attention, and mental effort. This technique is widely applied in psychology, neuroscience, and human-computer interaction research. ","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"c6YhWWC4Er"},{"type":"link","url":"https://en.wikipedia.org/wiki/Pupillometry","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Learn more on Wikipedia","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"bUsymRGmAT"}],"urlSource":"https://en.wikipedia.org/wiki/Pupillometry","data":{"page":"Pupillometry","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"XzdSXsfLnw"},{"type":"text","value":".","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"d5iTgMXVHi"}],"key":"lwrh6AEHxw"},{"type":"image","url":"/sensingsoundandmusic/build/undefined","alt":"Pupillometry example","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"c0indmjV6u","urlSource":"https://upload.wikimedia.org/wikipedia/commons/4/4c/Pupil_dilation.png"},{"type":"heading","depth":2,"position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Technology","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"CWtloQ37Px"}],"identifier":"technology","label":"Technology","html_id":"technology","implicit":true,"key":"aKrrqI731I"},{"type":"heading","depth":3,"position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"Eye-Trackers","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"E6XX5yLo8K"}],"identifier":"eye-trackers","label":"Eye-Trackers","html_id":"eye-trackers","implicit":true,"key":"EeElzL2ypM"},{"type":"paragraph","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"Eye-trackers are devices used to measure eye positions and movements. They are widely used in research fields such as psychology, neuroscience, marketing, and human-computer interaction. Eye-trackers can be categorized into two main types: mobile and stationary.","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"JXnpwSvfet"}],"key":"lOcT2KNAy9"},{"type":"heading","depth":4,"position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"Mobile Eye-Trackers","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"SAh7Ge1dRg"}],"identifier":"mobile-eye-trackers","label":"Mobile Eye-Trackers","html_id":"mobile-eye-trackers","implicit":true,"key":"a8vyYSW6DX"},{"type":"paragraph","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"Mobile eye-trackers are wearable devices that allow for the tracking of eye movements in real-world environments. These devices are often used in studies that require participants to move freely, such as sports performance analysis, usability testing, and outdoor experiments. ","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"I5h5DYIneS"},{"type":"link","url":"https://en.wikipedia.org/wiki/Eye_tracking","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"Learn more on Wikipedia","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"jbu2MfN7KG"}],"urlSource":"https://en.wikipedia.org/wiki/Eye_tracking","data":{"page":"Eye_tracking","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"R7zfTSmUp8"},{"type":"text","value":".","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"EreTHyxDos"}],"key":"ljdXJxZTQz"},{"type":"paragraph","position":{"start":{"line":48,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/undefined","alt":"Mobile Eye-Tracker","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"mJ3g6PaE95","urlSource":"https://upload.wikimedia.org/wikipedia/commons/6/6e/Eye_tracking_glasses.jpg"},{"type":"text","value":"\n","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"zFBVJeVxWZ"},{"type":"emphasis","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Figure 1: Example of mobile eye-tracking glasses. Image credit: Wikimedia Commons.","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"bbdInKdsLz"}],"key":"cTierw6gR6"}],"key":"JYJn2UUcVb"},{"type":"heading","depth":4,"position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"Stationary Eye-Trackers","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"tTeKbuG7dG"}],"identifier":"stationary-eye-trackers","label":"Stationary Eye-Trackers","html_id":"stationary-eye-trackers","implicit":true,"key":"qI34CsSaXv"},{"type":"paragraph","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"Stationary eye-trackers are fixed devices typically used in controlled laboratory settings. They are often mounted on a desk or integrated into a monitor and are used for tasks such as reading studies, visual search experiments, and website usability testing. ","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"znpdkKeHSN"},{"type":"link","url":"https://en.wikipedia.org/wiki/Eye_tracking","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"Learn more on Wikipedia","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"gW2gH7Gowl"}],"urlSource":"https://en.wikipedia.org/wiki/Eye_tracking","data":{"page":"Eye_tracking","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"BFgIsY2Ko5"},{"type":"text","value":".","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"RbLz96wnjl"}],"key":"H5PZEXd3Nq"},{"type":"paragraph","position":{"start":{"line":54,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/undefined","alt":"Stationary Eye-Tracker","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"Od3Jg7jzdz","urlSource":"https://upload.wikimedia.org/wikipedia/commons/3/3c/Eye_tracking_software.png"},{"type":"text","value":"\n","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"RhgG7alv6g"},{"type":"emphasis","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"text","value":"Figure 2: Example of stationary eye-tracking software. Image credit: Wikimedia Commons.","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"hocT0c956R"}],"key":"AqHplRhVYL"}],"key":"WHpWVOIcco"}],"key":"AE2HniuKnx"}],"key":"y2LgWYmscm"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Week 8: The Brain","url":"/week8","group":"Sensing Sound and Music"},"next":{"title":"Week 10: Physiology","url":"/week10","group":"Sensing Sound and Music"}}},"domain":"http://localhost:3000"},"project":{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"exports":[],"title":"Sensing Sound and Music","description":"An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives.","authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"id":"11cc8b5a-b0a2-4516-8397-a7dbad782f82","toc":[{"file":"intro.md"},{"file":"week1.md"},{"file":"week2.md"},{"file":"week3.ipynb"},{"file":"week4.ipynb"},{"file":"week5.md"},{"file":"week6.ipynb"},{"file":"week7.md"},{"file":"week8.md"},{"file":"week9.md"},{"file":"week10.md"},{"file":"week11.md"}],"bibliography":[],"index":"index","pages":[{"slug":"week1","title":"Week 1: Tuning in","description":"This page introduces the foundational concepts of music psychology and technology, exploring how humans perceive, experience, and create sound and music through both psychological and technological perspectives.","date":"","thumbnail":"/sensingsoundandmusic/build/c20d5f224f701120b83307814eab6564.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week2","title":"Week 2: Listening","description":"This chapter explores the art and science of listening, focusing on how sounds and soundscapes are described, understood, and analyzed across disciplines. It introduces influential theories and thinkers, practical listening exercises, and tools for engaging with the sonic environment.","date":"","thumbnail":"/sensingsoundandmusic/build/impulsive-sustained--c0c48158496bcc681fba65df66fa6f2f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week3","title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","date":"","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week4","title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacoustics—the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","date":"","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week5","title":"Week 5: Time and Rhythm","description":"This chapter explores the foundations of musical time and rhythm, covering concepts such as onset timing, perceptual centers, meter, microrhythm, groove, and entrainment. It examines how rhythm is structured, perceived, and performed, highlighting the roles of technology and analysis tools in understanding the nuances of timing and groove in various musical styles.","date":"","thumbnail":"/sensingsoundandmusic/build/week5_image6-42ef9fdd71a421c1baf682d65217062b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week6","title":"Week 6: Harmony and melody","description":"This notebook explores the concepts of harmony, melody, and musical structure through both theoretical explanations and practical visualizations. It covers fundamental audio representations, symbolic music formats, and provides code examples for analyzing and visualizing musical elements using Python.","date":"","thumbnail":"/sensingsoundandmusic/build/week6_image2-4fa03b8bde3b7bda89ece8a2ac6da510.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week7","title":"Week 7: Body Motion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week8","title":"Week 8: The Brain","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/0698af3bcaf829b93eb28d09596d0541.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week9","title":"Week 9: Vision","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week10","title":"Week 10: Physiology","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week11","title":"Week 11: Machine Listening","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/sensingsoundandmusic/build/manifest-B2B2E6A5.js";
import * as route0 from "/sensingsoundandmusic/build/root-IB5726YR.js";
import * as route1 from "/sensingsoundandmusic/build/routes/$-LXLHKVOR.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/sensingsoundandmusic/build/entry.client-UNPC4GT3.js");</script></body></html>