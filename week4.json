{"version":2,"kind":"Notebook","sha256":"72dd31cf166db5f3a75323526e09fc97e203ef0405309eb6316527da012d8214","slug":"week4","location":"/week4.ipynb","dependencies":[],"frontmatter":{"title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacoustics—the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","subtitle":"Understanding how we hear, perceive, and are fooled by sound","authors":[{"nameParsed":{"literal":"Alexander Refsum Jensenius","given":"Alexander Refsum","family":"Jensenius"},"name":"Alexander Refsum Jensenius","affiliations":["University of Oslo"],"id":"contributors-week4-generated-uid-0"}],"affiliations":[{"id":"University of Oslo","name":"University of Oslo"}],"exports":[{"format":"ipynb","filename":"week4.ipynb","url":"/sensingsoundandmusic/build/week4-f689a5040f52f82af7ce9aaed1be4a61.ipynb"}],"kernelspec":{"name":"python3","display_name":"venv","language":"python"},"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"source_url":"https://github.com/fourMs/sensingsoundandmusic/blob/main/book/week4.ipynb","edit_url":"https://github.com/fourMs/sensingsoundandmusic/edit/main/book/week4.ipynb","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg"},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This week we will explore the field of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zvgsj1rLuD"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Psychoacoustics","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"psychoacoustics","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Q4qsQ9nh1y"}],"urlSource":"https://en.wikipedia.org/wiki/Psychoacoustics","data":{"page":"Psychoacoustics","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"IFUboaYeng"}],"key":"vZzq2nMrKR"},{"type":"text","value":", the study of how humans perceive and interpret sound, bridging the gap between physical sound properties and subjective auditory experiences. Psychoacoustics examines the psychological and physiological responses associated with sound, including how we detect, differentiate, and interpret auditory stimuli. It seeks to answer questions such as: Why do some sounds seem louder than others, even if they have the same physical intensity? How do we distinguish between different musical instruments playing the same note? What makes certain sounds pleasant or unpleasant? This will form the foundation for more detailed investigations of “vertical” and “horizontal” sound perception in the coming weeks.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"D2QIFQXdC9"}],"key":"YPq3wf37iy"},{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Introduction to Psychoacoustics","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"j8h2zauY6I"}],"identifier":"introduction-to-psychoacoustics","label":"Introduction to Psychoacoustics","html_id":"introduction-to-psychoacoustics","implicit":true,"key":"GoTX7AHYoz"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Psychoacoustics is a specialized area within the broader field of ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"KVn6qupydg"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Psychophysics","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"psychophysics","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ep59ZZFH4L"}],"urlSource":"https://en.wikipedia.org/wiki/Psychophysics","data":{"page":"Psychophysics","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"rtbAFrTYAU"}],"key":"Pjio41rRyM"},{"type":"text","value":", which studies the relationships between physical stimuli and the sensations and perceptions they produce. While psychophysics investigates general principles of sensory perception across all senses, psychoacoustics focuses specifically on hearing. Both fields use experimental methods to quantify how changes in physical properties (like frequency, intensity, or duration) correspond to changes in perception (such as pitch, loudness, or timbre), helping to bridge the gap between objective measurements and subjective experience.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VQfXmDKT8z"}],"key":"DoNjRIluab"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Psychoacoustics explores the relationship between the measurable, physical properties of sound (such as frequency, amplitude, and harmonic relationships) and the way these sounds are perceived by the human ear and brain (such as pitch, loudness, and timbre). Insights from psychoacoustics are applied in audio engineering, music production, hearing aid design, and the development of audio codecs (such as MP3), which exploit perceptual limitations to compress audio data efficiently.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TRRwyBHRVI"}],"key":"v3ZqZxEK1n"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"The roots of psychoacoustics can be traced back to the 19th century, with foundational work by scientists such as ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"B2PpknQWH4"},{"type":"link","url":"https://en.wikipedia.org/wiki/Hermann_von_Helmholtz","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Hermann von Helmholtz","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ttWeXqjWqw"}],"urlSource":"https://en.wikipedia.org/wiki/Hermann_von_Helmholtz","data":{"page":"Hermann_von_Helmholtz","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"d0WPkD71Tp"},{"type":"text","value":" (1821–1894), who investigated the sensations of tone and the physical basis of music. Later, ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"AuigsjtxNk"},{"type":"link","url":"https://en.wikipedia.org/wiki/Stanley_Smith_Stevens","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"S. S. Stevens","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"XU9SVd6tRT"}],"urlSource":"https://en.wikipedia.org/wiki/Stanley_Smith_Stevens","data":{"page":"Stanley_Smith_Stevens","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"Ntek9RfFAS"},{"type":"text","value":"  (1906–1973) contributed to the development of psychophysical scaling, introducing methods to quantify the relationship between stimulus and perception (e.g., the Stevens’ Power Law for loudness perception). Over time, psychoacoustics has evolved into a multidisciplinary field, integrating insights from physics, psychology, neuroscience, and engineering.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"eZNzPsK84U"}],"key":"fwDASPnJ9G"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"How does psychoacoustics relate to auditory ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"fWMui24tZ3"},{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"perception","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"SNYsBw39Lz"}],"key":"Q9OdFG4Uxe"},{"type":"text","value":" and ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"TN2g1pcLCx"},{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"cognition","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"IpT65kzpL3"}],"key":"mTtgJna8hs"},{"type":"text","value":"? Psychoacoustics forms the scientific foundation for understanding how we perceive and interpret sound. Auditory perception encompasses the processes by which the ear and brain detect, analyze, and make sense of acoustic signals—transforming vibrations in the air into meaningful experiences such as speech, music, or environmental sounds. Psychoacoustics explains why certain sounds are perceived as louder, higher, or more pleasant, and how we can distinguish between different sources in complex auditory scenes.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"JK1EzqvK0u"}],"key":"ObHRyDt6ZA"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Cognition involves higher-level mental functions such as attention, memory, learning, and decision-making. While psychoacoustics focuses on the sensory and perceptual mechanisms of hearing, cognition shapes how we interpret, remember, and respond to sounds. For example, cognitive processes help us focus on a single voice in a noisy room (the “cocktail party effect”), recognize familiar melodies, or associate sounds with emotions and memories. Together, psychoacoustics and auditory cognition provide a comprehensive understanding of how we experience and interact with the world of sound.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"NES56LW9MG"}],"key":"AIpT1RTUOy"},{"type":"heading","depth":2,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"The Human Auditory System","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"uARZcBmlhv"}],"identifier":"the-human-auditory-system","label":"The Human Auditory System","html_id":"the-human-auditory-system","implicit":true,"key":"LqDfbbUEW1"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"The human ear is a remarkably complex organ that enables us to detect sounds and maintain our sense of balance. It is divided into three main sections: the ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"SPjp33DF4B"},{"type":"emphasis","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"outer ear","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"chMWAOgJOg"}],"key":"WRbZ1mpD4y"},{"type":"text","value":", ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"RTyLOUZFt0"},{"type":"emphasis","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"middle ear","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"Bjy2JkI3cr"}],"key":"bj8LbgDy9y"},{"type":"text","value":", and ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"mH2AKPjvPu"},{"type":"emphasis","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"inner ear","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"cZeVi0uHwp"}],"key":"h4kWkx63ZO"},{"type":"text","value":". Each part plays a distinct and crucial role in the auditory process.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"q7oVCrOCGG"}],"key":"Mk9j61Q7A1"},{"type":"heading","depth":3,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"The outer ear","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"IkOY2CKTfs"}],"identifier":"the-outer-ear","label":"The outer ear","html_id":"the-outer-ear","implicit":true,"key":"tY7BciNtRZ"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"VT2ZNXUfp5"},{"type":"emphasis","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Outer_ear","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"outer ear","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"tSDGRLwgkf"}],"urlSource":"https://en.wikipedia.org/wiki/Outer_ear","data":{"page":"Outer_ear","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"dLHwCe0dmW"}],"key":"XIzao7JIsF"},{"type":"text","value":" consists of the visible part called the ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"uxS9z7vYtm"},{"type":"emphasis","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"pinna","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"OE7p23cZJL"}],"key":"fGGUsI3uQX"},{"type":"text","value":" and the ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"ciKmuGHAUQ"},{"type":"emphasis","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"ear canal","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"MrSB1qlauA"}],"key":"EmFgpJ3u70"},{"type":"text","value":". Its primary function is to collect sound waves from the environment and funnel them toward the ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"uFb3secvnS"},{"type":"emphasis","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"eardrum","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"fi79MCEe5y"}],"key":"dIDFhvri9M"},{"type":"text","value":" (sometimes call the ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"lE60jPOK4Y"},{"type":"emphasis","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"tympanic membrane","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"oHjafQOqtV"}],"key":"QCiUCrs8oq"},{"type":"text","value":"). The unique shape of the pinna helps us localize the direction of sounds. When sound waves reach the eardrum, they cause it to vibrate.","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"MNWaWTp1Hu"}],"key":"SK7jEYsT4a"},{"type":"paragraph","position":{"start":{"line":23,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","alt":"Outer Ear","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"xI87VOQynj","urlSource":"https://upload.wikimedia.org/wikipedia/commons/4/40/Ear-anatomy-text-small-en.svg"},{"type":"break","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"mlHYj9yj2C"},{"type":"emphasis","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"Image Source: ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"cvPrxJ3EBE"},{"type":"link","url":"https://en.wikipedia.org/wiki/Outer_ear","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"Wikipedia - Outer Ear","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"VrQ04AkAh7"}],"urlSource":"https://en.wikipedia.org/wiki/Outer_ear","data":{"page":"Outer_ear","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"rpuGZR7wM6"}],"key":"KJWJf844Lp"}],"key":"kiJYJHqQis"},{"type":"paragraph","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"The eardrum  in the human ear functions much like the membrane in a microphone. Both act as sensitive barriers that vibrate in response to incoming sound waves. When sound waves enter the ear canal, they strike the eardrum, causing it to vibrate. These vibrations are then transmitted through the ossicles to the inner ear, where they are converted into electrical signals for the brain to interpret. In a microphone, sound waves hit a thin, flexible membrane (diaphragm), causing it to vibrate. These vibrations are converted into electrical signals, which can then be amplified, recorded, or transmitted. As such, both the ear drum and the microphone membrane convert air pressure variations (sound waves) into mechanical vibrations. Both also serve as the first step in transforming acoustic energy into a form that can be further processed; biologically in the ear, electronically in the microphone.","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"Z2Beoyr9OX"}],"key":"TEFHyzVNlb"},{"type":"heading","depth":3,"position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"The middle ear","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"aquLFJ5fi0"}],"identifier":"the-middle-ear","label":"The middle ear","html_id":"the-middle-ear","implicit":true,"key":"JKz6U1p6az"},{"type":"paragraph","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"Beyond the eardrum lies the ","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"fpoz6Bn0GO"},{"type":"emphasis","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Middle_ear","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"middle ear","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"CRS23DS4xr"}],"urlSource":"https://en.wikipedia.org/wiki/Middle_ear","data":{"page":"Middle_ear","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"EBHin3Ic6m"}],"key":"nzdKLV4CNM"},{"type":"text","value":", which contains three tiny bones known as the ","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"bF0MdwcGVA"},{"type":"emphasis","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"ossicles","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"nWUP4r51zL"}],"key":"bcKd3rX7Cj"},{"type":"text","value":": the malleus, incus, and stapes. These bones act as a mechanical lever system, amplifying the vibrations from the eardrum and transmitting them to the oval window, a membrane-covered opening to the inner ear. This amplification is essential for efficiently transferring sound energy from air to the fluid-filled inner ear.","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"sVn8Edho98"}],"key":"CWBnRqYAxN"},{"type":"paragraph","position":{"start":{"line":32,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/4780c1900abe3625c515380b4d979e92.png","alt":"Middle Ear","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"jw2Ml1V0Qd","urlSource":"https://upload.wikimedia.org/wikipedia/commons/8/81/Blausen_0330_EarAnatomy_MiddleEar.png"},{"type":"break","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"TsqE73am2h"},{"type":"emphasis","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Image Source: ","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"IrZHrWjaVz"},{"type":"link","url":"https://en.wikipedia.org/wiki/Middle_ear","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Wikipedia - Middle Ear","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"J0Aor9bsdF"}],"urlSource":"https://en.wikipedia.org/wiki/Middle_ear","data":{"page":"Middle_ear","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"EfLrOKirUQ"}],"key":"LRjhZSJQ3k"}],"key":"PuX8ffgx15"},{"type":"paragraph","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"This process is analogous to how a microphone connected to a preamplifier works. The vibrations from a microphone membrane are weak and are typically run through a ","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"ocrlYkllCK"},{"type":"emphasis","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"preamplifier","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"aaH00YqQLp"}],"key":"rQ0TCwIF36"},{"type":"text","value":" to boost the signal to a level suitable for further processing or recording. Similarly, the ossicles amplify the mechanical vibrations from the eardrum, ensuring that the signal is strong enough to be effectively transmitted into the inner ear for further processing by the auditory system.","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"Zm1H0WPU4l"}],"key":"zbQBGhU8Yt"},{"type":"heading","depth":3,"position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"The inner ear","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"puVDajzSWT"}],"identifier":"the-inner-ear","label":"The inner ear","html_id":"the-inner-ear","implicit":true,"key":"mH9DwmifXe"},{"type":"paragraph","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"ztadSkYa5r"},{"type":"emphasis","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Inner_ear","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"inner ear","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"aCz7T3z6y6"}],"urlSource":"https://en.wikipedia.org/wiki/Inner_ear","data":{"page":"Inner_ear","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"BDDfnvpvh9"}],"key":"BuIsgTfGvK"},{"type":"text","value":" is where the mechanical vibrations are transformed into electrical signals that the brain can interpret as sound. The main structure responsible for this is the ","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"Y34YG1xVKg"},{"type":"emphasis","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Cochlea","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"cochlea","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"xs1gdNxa1u"}],"urlSource":"https://en.wikipedia.org/wiki/Cochlea","data":{"page":"Cochlea","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"vDaplbdpoB"}],"key":"gCaGNfuXUU"},{"type":"text","value":", a spiral-shaped, fluid-filled organ lined with thousands of tiny hair cells. As vibrations travel through the cochlear fluid, they cause the hair cells to move, generating nerve impulses that are sent to the brain via the auditory nerve.","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"PzOHyu6KD5"}],"key":"wOiqTV6zaA"},{"type":"paragraph","position":{"start":{"line":41,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/86f9a53d5fe0831c1177f9be08b44abe.png","alt":"Inner Ear","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"diVeV0DpoG","urlSource":"https://upload.wikimedia.org/wikipedia/commons/1/14/Blausen_0329_EarAnatomy_InternalEar.png"},{"type":"break","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"Qyd8NIP1lS"},{"type":"emphasis","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"Image Source: ","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"W70epDyXdb"},{"type":"link","url":"https://en.wikipedia.org/wiki/Inner_ear","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"Wikipedia - Inner Ear","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"rB8owfx2nX"}],"urlSource":"https://en.wikipedia.org/wiki/Inner_ear","data":{"page":"Inner_ear","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"GPWjJmuZj3"}],"key":"fK7qOTNnYw"}],"key":"g5qPzjqjcL"},{"type":"paragraph","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"The cochlea in the inner ear functions similarly to an analog-to-digital converter (ADC) in audio technology. Just as an ADC transforms continuous analog sound waves into discrete digital signals that can be processed by computers, the cochlea converts mechanical vibrations from sound into electrical nerve impulses that the brain can interpret. Inside the cochlea, thousands of hair cells respond to specific frequencies, effectively performing a biological form of frequency analysis and encoding the intensity and timing of sounds. This process is analogous to how an ADC samples and quantizes audio signals, enabling the transmission and interpretation of complex auditory information in a form the brain can understand.","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"MB6kzTgT8Q"}],"key":"zvdYWcRRUc"},{"type":"paragraph","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"The inner ear also contains the ","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"ekUEuvXOJz"},{"type":"link","url":"https://en.wikipedia.org/wiki/Vestibular_system","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"vestibular system","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"KzApuagAwe"}],"urlSource":"https://en.wikipedia.org/wiki/Vestibular_system","data":{"page":"Vestibular_system","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"ZDId04v2XE"},{"type":"text","value":", which is crucial for maintaining balance and spatial orientation. We will get back to this when we get to music-related body motion.","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"TteXB7dQzC"}],"key":"sQoVl9fwm7"},{"type":"heading","depth":3,"position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Human vs machine perception","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"r98Z3f5PYa"}],"identifier":"human-vs-machine-perception","label":"Human vs machine perception","html_id":"human-vs-machine-perception","implicit":true,"key":"n2CbOIKw8g"},{"type":"paragraph","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"children":[{"type":"text","value":"Although the human auditory system and machine-based audio systems (like microphones and ADCs) are fundamentally different in their biological and technological makeup, drawing analogies between them can help us better understand both. Each system consists of a series of components that transform and process sound, ultimately converting physical vibrations in the air into meaningful information—whether as neural signals in the brain or digital data in a computer.","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"nZ2kISINXI"}],"key":"rIcj3XR2g3"},{"type":"mermaid","value":"graph LR\n    A[Sound Waves] --> B[Transduction]\n    B --> C[Frequency analysis]\n    C --> D[Encoding]\n    D --> E[Transmission]\n    E --> F[Interpretation]","position":{"start":{"line":52,"column":1},"end":{"line":59,"column":1}},"key":"KNVen8OGDJ"},{"type":"paragraph","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"The different parts are as follows:","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"AAF5YmEzXH"}],"key":"TTG3oPmeac"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":63,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"Transduction","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"cL7rrieORK"}],"key":"ozkXLLBNe0"},{"type":"text","value":": In humans, the ear drum and ossicles convert air pressure variations into mechanical vibrations, while the cochlea transduces these vibrations into electrical nerve impulses. In machines, a microphone membrane converts sound waves into electrical signals, which are then amplified and digitized.","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"JtdEx22154"}],"key":"beGBsMoon3"}],"key":"RgAWJwYGu0"},{"type":"listItem","spread":true,"position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"Frequency Analysis","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"umDtCKZwrh"}],"key":"XTUqljIZr5"},{"type":"text","value":": The cochlea performs a kind of real-time frequency analysis, with different regions responding to different frequencies (a biological “filter bank”). Similarly, digital systems use mathematical transforms (like the Fourier Transform) to analyze frequency content.","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"OfUWP7tZYu"}],"key":"uTkWlFfFzl"}],"key":"yMV3NNziy7"},{"type":"listItem","spread":true,"position":{"start":{"line":65,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"children":[{"type":"text","value":"Encoding and Transmission","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"OYSrRYO6Fh"}],"key":"Hdx3EUpEn2"},{"type":"text","value":": The auditory nerve encodes and transmits information about sound to the brain, where it is further processed and interpreted. In digital systems, the ADC encodes the analog signal into binary data, which can be stored, transmitted, and processed by computers.","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"FtGGcpmQ1p"}],"key":"V8UcSn798R"}],"key":"Dx9JcWzZkx"}],"key":"pfqMb9L66L"},{"type":"paragraph","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"Despite these similarities, there are important differences:","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"yBhze7xi00"}],"key":"ii7c8idZeG"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":68,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The human auditory system is adaptive, context-sensitive, and influenced by attention, learning, and memory. It can focus on specific sounds in noisy environments (the “cocktail party effect”) and fill in missing information based on prior experience.","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"UwgpO2COds"}],"key":"ASGX6piD4B"}],"key":"hucX6gvO86"},{"type":"listItem","spread":true,"position":{"start":{"line":69,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Machine perception is limited by hardware specifications (such as microphone quality and sampling rate) and the algorithms used for analysis. While modern systems can achieve impressive results, they lack the flexibility, nuance, and subjective interpretation of human hearing.","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"SO3ucMPzHA"}],"key":"rgbLNIkdIe"}],"key":"yAxfzIw7SQ"}],"key":"uiypWLy4QB"},{"type":"paragraph","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"text","value":"Understanding these parallels and differences is essential for fields like audio engineering, hearing aid design, and music information retrieval, where the goal is often to bridge the gap between physical sound and perceptual experience.","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"PYWQgTuigi"}],"key":"gzUU2kpoMu"}],"key":"xq0lgRo0TX"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Loudness","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vtmpFYhcGc"}],"identifier":"loudness","label":"Loudness","html_id":"loudness","implicit":true,"key":"RAKIFc90pc"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"If you recall from last week, ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"X9ZLF89Yhy"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Loudness","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"loudness","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"a3TduOKPCN"}],"urlSource":"https://en.wikipedia.org/wiki/Loudness","data":{"page":"Loudness","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"hRexsK9hZo"}],"key":"lLOwLxxOIe"},{"type":"text","value":" is different from ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"X2Orl7LgEe"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"sound pressure level","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VC54pNbqqU"}],"key":"JVBtVeiEqx"},{"type":"text","value":" (SPL). While ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"XcIcJtU5ZF"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Sound_pressure#Sound_pressure_level","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"sound pressure level (SPL)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"rR2wgMkGUl"}],"urlSource":"https://en.wikipedia.org/wiki/Sound_pressure#Sound_pressure_level","data":{"page":"Sound_pressure#Sound_pressure_level","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"d0AddQxs92"}],"key":"cPW9ZlXSPG"},{"type":"text","value":" is an objective, physical measurement of the intensity of a sound wave (expressed in decibels, dB), loudness is a subjective perception—how “loud” a sound feels to a human listener. Loudness perception is influenced by context, such as background noise and recent exposure to other sounds. This distinction is fundamental in psychoacoustics and underlies many practical considerations in audio engineering, hearing science, and music production.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"RukAcYFy5d"}],"key":"kUx4ymP6rL"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Measuring loudness","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"frzvRmkP0k"}],"identifier":"measuring-loudness","label":"Measuring loudness","html_id":"measuring-loudness","implicit":true,"key":"zOQTWbCOE3"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The most common unit for measuring perceived loudness is the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"rI0wAd5uyu"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Phon","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"phon","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TqWUtNyTKq"}],"urlSource":"https://en.wikipedia.org/wiki/Phon","data":{"page":"Phon","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"NjD5mQESQR"}],"key":"gTJKXxt6Wo"},{"type":"text","value":", which is based on equal-loudness contours (which we will discuss soon). The phon scale is anchored to the loudness of a 1,000 Hz pure tone. For example, a sound that is perceived as equally loud as a 40 dB SPL, 1,000 Hz tone is said to have a loudness of 40 phons, regardless of its frequency or SPL.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"KwqmomBn6h"}],"key":"dH7ye3oAfd"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"There are several standards for estimating loudness in audio signals. ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"JaWK1fFnhq"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/ITU-R_BS.1770","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"ITU-R BS.1770","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"XcBa1MKQir"}],"urlSource":"https://en.wikipedia.org/wiki/ITU-R_BS.1770","data":{"page":"ITU-R_BS.1770","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"k0JgkMLB0x"}],"key":"baWVrzFNSZ"},{"type":"text","value":" is widely used in broadcasting; this standard defines algorithms for measuring loudness and true-peak audio levels, forming the basis for loudness normalization in radio, TV, and streaming.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"yT5z9StIrr"}],"key":"QT9oJdR0pZ"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Modern audio software and digital audio workstations (DAWs) often include loudness meters that display values in LUFS: ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"A5ZUs2WxF5"},{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/LUFS","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Loudness units relative to full scale","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"jbvGIVTg5g"}],"urlSource":"https://en.wikipedia.org/wiki/LUFS","data":{"page":"LUFS","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"FmUM3mvo2v"}],"key":"RGKP2mfqt7"},{"type":"text","value":". These tools help engineers and producers ensure that audio content meets broadcast standards and provides a comfortable listening experience. When mastering music for streaming platforms, engineers typically aim for an integrated loudness of around -14 LUFS, as recommended by services like Spotify and YouTube. In film and TV, loudness normalization ensures that dialogue, music, and effects are balanced and that viewers do not need to constantly adjust the volume.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"P56rkqmgUD"}],"key":"I21jQtAmyh"},{"type":"heading","depth":3,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Threshold of hearing","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"oWHMLgui52"}],"identifier":"threshold-of-hearing","label":"Threshold of hearing","html_id":"threshold-of-hearing","implicit":true,"key":"ILXyfvETvY"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"t1oa16Iv8T"},{"type":"emphasis","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Absolute_threshold_of_hearing","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"threshold of hearing","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"MRxsGuqv82"}],"urlSource":"https://en.wikipedia.org/wiki/Absolute_threshold_of_hearing","data":{"page":"Absolute_threshold_of_hearing","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"RLezhw0CXk"}],"key":"N3zfZjqPm0"},{"type":"text","value":" is the quietest sound that the average human ear can detect in a silent environment. This threshold is typically defined as 0 decibels (dB SPL) at 1,000 Hz for a healthy young adult, but it varies with frequency and individual hearing ability. At very low or very high frequencies, sounds must be much louder to be heard.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"oVYwR0rclf"}],"key":"XG8hebZEUZ"},{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"The threshold of hearing is not a fixed value; it can be affected by age, exposure to loud noises, and even temporary conditions like ear infections or fatigue. As people age, their sensitivity to high frequencies usually decreases, raising the threshold at those frequencies.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"cVnB9lFI8y"}],"key":"RBzJRTLh7E"},{"type":"paragraph","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"The graph below illustrates the average hearing thresholds for different frequencies and age groups, showing how sensitivity changes across the audible spectrum.","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"tC3cfEBScu"}],"key":"uA1YBXOPwo"},{"type":"paragraph","position":{"start":{"line":22,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/33b3ec3b3ae0390f52ff6f4319b2d654.jpeg","alt":"Threshold of Hearing","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"Djq0n5XpNb","urlSource":"https://upload.wikimedia.org/wikipedia/commons/d/da/Average_click-evoked_waveforms_and_Average_hearing_thresholds_for_younger_and_older_adults.jpg"},{"type":"text","value":"\n","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"rxCQVbzFUx"},{"type":"emphasis","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Image Source: ","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"xcY1GnW5W1"},{"type":"link","url":"https://en.wikipedia.org/wiki/Absolute_threshold_of_hearing","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Wikipedia - Hearing Thresholds","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"F1upbqU797"}],"urlSource":"https://en.wikipedia.org/wiki/Absolute_threshold_of_hearing","data":{"page":"Absolute_threshold_of_hearing","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"heSo90v52z"}],"key":"hunLC0HKrG"}],"key":"NbJrjc3tbY"},{"type":"heading","depth":3,"position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Safe listening levels","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"beHSPXKqpU"}],"identifier":"safe-listening-levels","label":"Safe listening levels","html_id":"safe-listening-levels","implicit":true,"key":"aqdI1Cgk7h"},{"type":"paragraph","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Here is a list of some different sound levels:","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"T3A98ZeGAx"}],"key":"Zn1HRFIELg"},{"type":"table","position":{"start":{"line":29,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"tableRow","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"tableCell","header":true,"position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Sound Source","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"GPwmEe4uWG"}],"key":"TbysQ7TZ9H"},{"type":"tableCell","header":true,"position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Approximate Loudness (dB SPL)","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"AccLenOrcn"}],"key":"YcYwNJZWdX"},{"type":"tableCell","header":true,"position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Example / Context","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"fBaCHr0GBM"}],"key":"dvNb15cI1W"}],"key":"ZhC5DXaKCo"},{"type":"tableRow","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Threshold of hearing","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"xE0vuSdxgq"}],"key":"OmYilObCz6"},{"type":"tableCell","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"0","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"rENUJglATq"}],"key":"SPJodiVzBo"},{"type":"tableCell","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Quietest sound a healthy ear can detect","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"ZnNlxXucYA"}],"key":"zBLwCqJLY9"}],"key":"bOxc6xvn8J"},{"type":"tableRow","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Rustling leaves","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"jeO3NnZuik"}],"key":"nPBI7wF2ME"},{"type":"tableCell","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"10","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"a92httiD76"}],"key":"nrEbGTV4n8"},{"type":"tableCell","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Very quiet, barely audible","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"xxTAmMxBHx"}],"key":"ClHAj0MhSI"}],"key":"RTTHHJFOY4"},{"type":"tableRow","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"Whisper","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"Br8Yjtg9YF"}],"key":"eU6xb5dY1b"},{"type":"tableCell","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"20–30","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"Wal1psOJdV"}],"key":"P3aWEgnIRF"},{"type":"tableCell","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"Soft whisper at close distance","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"YStoy1r3Dd"}],"key":"fEtZK7ZIC8"}],"key":"z1hAaK5qNi"},{"type":"tableRow","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Quiet library","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"pO9dZ4LMwP"}],"key":"q4JQJs3WIx"},{"type":"tableCell","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"30–40","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"d5EnYRSSQq"}],"key":"ta268gYbTA"},{"type":"tableCell","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Typical background noise","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"acq4Fnsdyy"}],"key":"VgIy20aEBH"}],"key":"kCRfJqMZ5d"},{"type":"tableRow","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Normal conversation","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"AwCcHnyGMI"}],"key":"tePQqeGA0L"},{"type":"tableCell","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"60","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"gaMkvhvDfR"}],"key":"oosGJ56KqY"},{"type":"tableCell","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"At 1 meter distance","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"KmXVILLxH1"}],"key":"UuMN5KZ8Vk"}],"key":"IoXJXrR8Vp"},{"type":"tableRow","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"Busy street traffic","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"qHkWpmhazU"}],"key":"OEQoTxOtfU"},{"type":"tableCell","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"70–85","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"eZdqRWDIUV"}],"key":"BgY5c5Dsqh"},{"type":"tableCell","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"Inside a car with windows closed","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"l0n142UbzJ"}],"key":"I1Hvimp1vr"}],"key":"fSQ20VQuFh"},{"type":"tableRow","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"Subway train","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"jTLDglMtbw"}],"key":"xJgd7XoKVo"},{"type":"tableCell","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"95–100","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"YXjw4sgE9W"}],"key":"hLD3R4gYik"},{"type":"tableCell","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"Inside the train","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"GDUW2uiFEE"}],"key":"uxzgi7wHMm"}],"key":"p1F6w0Blax"},{"type":"tableRow","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Rock concert","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"V0Rt1RCN17"}],"key":"bkZ6iLJsUC"},{"type":"tableCell","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"110–120","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"EvJtpWJVfT"}],"key":"iQyYE6cJt3"},{"type":"tableCell","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Near speakers","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"nVL221KVQI"}],"key":"vTrta7nXLH"}],"key":"KNfDOkW8wa"},{"type":"tableRow","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Threshold of pain","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"u3RbEHuYpl"}],"key":"y89ahNZUpL"},{"type":"tableCell","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"130","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"LhOaZNS5mK"}],"key":"jwTYeuVX2K"},{"type":"tableCell","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Jet engine at 30 meters","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"sjzPVC4KwV"}],"key":"LlK8UHV1jc"}],"key":"lwmSGWXEtr"},{"type":"tableRow","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"Fireworks / Gunshot","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"TvXOdTKXxe"}],"key":"QEa1zOcKPW"},{"type":"tableCell","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"140–150","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"NOTrBTtwix"}],"key":"tdufwCTvtV"},{"type":"tableCell","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"Close range","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"FVCT2g7Z7j"}],"key":"Oe2xyT5Fr4"}],"key":"ZuWYWe4WGo"}],"key":"XFXFxxxzoY"},{"type":"paragraph","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"As a rule of thumb, prolonged exposure to sounds above 85 dB can cause hearing damage. For example, typical conversation is around 60 dB, city traffic can reach 85 dB, and concerts or clubs often exceed 100 dB. The higher the volume, the shorter the safe exposure time. At 100 dB, hearing damage can occur in as little as 15 minutes.","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"C5Q86uoVD2"}],"key":"YY98Jz2Azb"},{"type":"paragraph","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"The World Health Organization (WHO) recommends keeping personal listening devices below 80 dB for adults (75 dB for children) and limiting exposure to loud environments. Using ear protection in noisy settings and taking listening breaks can help preserve hearing health.","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"KaZ1rNFuxu"}],"key":"zyiPuF72JG"},{"type":"paragraph","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"Sounds above 120–130 dB (such as jet engines at close range or fireworks) can cause immediate pain and permanent hearing loss. Even brief exposure to extremely loud sounds can result in irreversible damage to the hair cells in the inner ear.","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"jsAeQPosRU"}],"key":"fY3txOgMSP"},{"type":"admonition","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Question","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"OOiUHdyYVB"}],"key":"bqCYtVnOpZ"},{"type":"paragraph","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"How do you protect your hearing?","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"YWpIMOMmqu"}],"key":"aiQxuUTg2W"}],"class":"question","key":"XFTAp2dgPg"},{"type":"heading","depth":3,"position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"Equal Loudness Contours","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"dkiSdfBODj"}],"identifier":"equal-loudness-contours","label":"Equal Loudness Contours","html_id":"equal-loudness-contours","implicit":true,"key":"AakfYEouya"},{"type":"paragraph","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"One important thing to consider is that there is not a direct relationship between ","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"GeNhoXtEdt"},{"type":"link","url":"https://en.wikipedia.org/wiki/Sound_pressure#Sound_pressure_level","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"sound pressure level (SPL)","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"Nl7OHlVHAn"}],"urlSource":"https://en.wikipedia.org/wiki/Sound_pressure#Sound_pressure_level","data":{"page":"Sound_pressure#Sound_pressure_level","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"Wdhlz2LA6L"},{"type":"text","value":" and ","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"bDJPJSBdVY"},{"type":"link","url":"https://en.wikipedia.org/wiki/Loudness","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"loudness","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"MyX0Pee5LE"}],"urlSource":"https://en.wikipedia.org/wiki/Loudness","data":{"page":"Loudness","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"PgDtZDcqN8"},{"type":"text","value":". Although they are related, the same SPL can be perceived as having a different loudness depending on the frequency of the sound and the listener’s hearing sensitivity.","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"AoqMDak6Ch"}],"key":"BGkOnAs6GB"},{"type":"paragraph","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"This relationship was first systematically studied by ","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"ykjEITincn"},{"type":"link","url":"https://en.wikipedia.org/wiki/Harvey_Fletcher","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"Harvey Fletcher","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"TYjrB92mda"}],"urlSource":"https://en.wikipedia.org/wiki/Harvey_Fletcher","data":{"page":"Harvey_Fletcher","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"Fd5gJ37umr"},{"type":"text","value":" and ","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"eLEq8Cyd5b"},{"type":"link","url":"https://en.wikipedia.org/wiki/Wilden_A._Munson","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"Wilden A. Munson","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"Zb92d76NND"}],"urlSource":"https://en.wikipedia.org/wiki/Wilden_A._Munson","data":{"page":"Wilden_A._Munson","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"stqJXVPFeg"},{"type":"text","value":" in the 1930s. Their experiments led to the creation of the ","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"YiyzVAbO88"},{"type":"emphasis","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"Fletcher-Munson curves","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"necf45Reht"}],"key":"W9FROFHyKx"},{"type":"text","value":", which is nowadays often also known as ","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"tj2TBczcVb"},{"type":"emphasis","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Equal-loudness_contour","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"equal-loudness contours","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"lf3P0z08YB"}],"urlSource":"https://en.wikipedia.org/wiki/Equal-loudness_contour","data":{"page":"Equal-loudness_contour","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"Iiycp4TndO"}],"key":"lTQkK8YeR6"},{"type":"text","value":". These curves show that the human ear is not equally sensitive to all frequencies: we are most sensitive to frequencies between roughly 2,000 and 5,000 Hz, and less sensitive to very low or very high frequencies. As a result, a low-frequency sound must be played at a higher SPL than a mid-frequency sound to be perceived as equally loud.","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"C75Uauwc9T"}],"key":"tMsEknyRh0"},{"type":"paragraph","position":{"start":{"line":61,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/19e1528606ad954bed92097857b341d8.svg","alt":"Equal-loudness contour","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"yT2MMh4Oki","urlSource":"https://upload.wikimedia.org/wikipedia/commons/4/47/Lindos1.svg"},{"type":"text","value":"\n","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"CjjaNHSmnC"},{"type":"emphasis","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"Image Source: ","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"liAT9o1Aho"},{"type":"link","url":"https://en.wikipedia.org/wiki/Equal-loudness_contour","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"Wikipedia - Equal-loudness contour","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"vEk1KUs5LV"}],"urlSource":"https://en.wikipedia.org/wiki/Equal-loudness_contour","data":{"page":"Equal-loudness_contour","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"pU3iFd7tfD"}],"key":"JMmWtUyfqW"}],"key":"pdJhesM4A4"},{"type":"paragraph","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"There is evidence suggesting that our heightened sensitivity to frequencies between 2,000 and 5,000 Hz has evolutionary roots. This frequency range corresponds closely to the spectral content of human speech, particularly the consonant sounds that are crucial for understanding language. Being able to detect subtle differences in these frequencies would have provided a survival advantage by improving communication, social bonding, and the ability to detect important environmental sounds such as a baby’s cry or warning calls. Over time, natural selection may have favored individuals whose hearing was optimized for these frequencies, shaping the contours of human auditory perception.","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"qr8Gx3WbZv"}],"key":"XH5cwZHvEw"},{"type":"paragraph","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"text","value":"Equal-loudness contours are crucial in audio engineering, music production, and hearing science. They explain why music or speech can sound different at low versus high volumes, and why audio equipment often includes “loudness” compensation to adjust for these perceptual differences. Understanding these contours helps us design better audio systems and create more accurate sound reproductions that align with human hearing.","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"uQrUvgUcsN"}],"key":"UkRhveNzYS"},{"type":"exercise","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Sine tone loudness","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"oOdlYIkeDO"}],"key":"lXhRQPIysh"},{"type":"paragraph","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"text","value":"In ","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"g1fFpxB4Wu"},{"type":"link","url":"https://glicol.org/tour#basicconnection","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"text","value":"Glicol","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"XZr5JUjchC"}],"urlSource":"https://glicol.org/tour#basicconnection","key":"WEJw8dIP3y"},{"type":"text","value":", try to play a sine tone with different frequencies, for example, 100, 500, 1000, 3000, 5000, 10,000 Hz. What do you notice in terms of how loud it sounds like?","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"SfqhsEyR7b"}],"key":"Oh3JVjJ8x9"}],"enumerated":true,"label":"exercise-iNvA7htz4c","identifier":"exercise-inva7htz4c","enumerator":"1","html_id":"exercise-inva7htz4c","key":"Z2AniqwIXY"},{"type":"heading","depth":3,"position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"children":[{"type":"text","value":"Just noticeable differences for loudness","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"key":"GpaJjkSlVv"}],"identifier":"just-noticeable-differences-for-loudness","label":"Just noticeable differences for loudness","html_id":"just-noticeable-differences-for-loudness","implicit":true,"key":"XFOIPollbU"},{"type":"paragraph","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"Pp2ywjnP63"},{"type":"emphasis","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Just-noticeable_difference","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"text","value":"just noticeable difference","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"RkNtwtVzwB"}],"urlSource":"https://en.wikipedia.org/wiki/Just-noticeable_difference","data":{"page":"Just-noticeable_difference","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"OaR6TIF1cA"}],"key":"ZuESan89E3"},{"type":"text","value":" (JND), also called the ","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"rvMxLrtQ4C"},{"type":"emphasis","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"text","value":"difference limen","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"eYavJsAj4i"}],"key":"W1MvMKQHdT"},{"type":"text","value":", is the smallest change in a physical stimulus that a listener can reliably detect. For loudness, the JND refers to the smallest change in sound intensity that can be perceived as a difference in loudness by a human listener.","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"l4WmdkREds"}],"key":"bnmQJbTMiG"},{"type":"paragraph","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"The JND for loudness is often expressed as a percentage of the original sound level. For mid-level sounds, the JND is typically about 1 dB (decibel), meaning that a change of at least 1 dB is needed for most people to notice a difference in loudness. This threshold can vary depending on the frequency, the absolute loudness, and the listening environment.","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"apohkdAJ0C"}],"key":"c0yloVocsL"},{"type":"exercise","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"JND for loudness","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"nyO7xj3NnG"}],"key":"QYBUAHa3Qz"},{"type":"paragraph","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"text","value":"In ","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"key":"lPkjj6qa6L"},{"type":"link","url":"https://glicol.org/tour#basicconnection","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"text","value":"Glicol","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"key":"EANFA7jmY7"}],"urlSource":"https://glicol.org/tour#basicconnection","key":"TPGVnS59SL"},{"type":"text","value":", try to play a sine tone with different amplitues. How little or much do you need to change to hear a difference?","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"key":"bOm1hRkX49"}],"key":"OOlHgDvDWg"}],"enumerated":true,"label":"exercise-yNxF7Jo2vm","identifier":"exercise-ynxf7jo2vm","enumerator":"2","html_id":"exercise-ynxf7jo2vm","key":"KxuD6PZrXG"}],"key":"B4gVGqt0cy"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Pitch","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rnBh8sNvJ6"}],"identifier":"pitch","label":"Pitch","html_id":"pitch","implicit":true,"key":"eWL1fBxcxd"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"When we hear tonal sounds, like musical instruments but also voices, we typically hear a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qZr2w3qbTS"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"pitch","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"rXa9O0MWLV"}],"key":"dJc3edu5fa"},{"type":"text","value":". The pitch is closely related to the physical property of frequency (the rate at which a sound wave vibrates), but it is ultimately a subjective experience shaped by the human auditory system.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"xnh2mptu8H"}],"key":"q0h5ewsMYw"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Pitch range","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"hqmyxkgrcv"}],"identifier":"pitch-range","label":"Pitch range","html_id":"pitch-range","implicit":true,"key":"E3WzRPV7lS"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The typical range of audible sound for humans spans from approximately ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"hNQskeRxQc"},{"type":"link","url":"https://en.wikipedia.org/wiki/Hertz","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"20 Hz","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"NI8QuZYa9B"}],"urlSource":"https://en.wikipedia.org/wiki/Hertz","data":{"page":"Hertz","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"kMoHey147A"},{"type":"text","value":" to ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"HRgPgYDklI"},{"type":"link","url":"https://en.wikipedia.org/wiki/Hearing_range","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"20,000 Hz","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"IcF5kqeEFX"}],"urlSource":"https://en.wikipedia.org/wiki/Hearing_range","data":{"page":"Hearing_range","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"XNtAXEdvQK"},{"type":"text","value":", encompassing the frequencies we perceive as ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"REZIyiXvDp"},{"type":"link","url":"https://en.wikipedia.org/wiki/Pitch_(music)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"pitch","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"cfZF2BuqtW"}],"urlSource":"https://en.wikipedia.org/wiki/Pitch_(music)","data":{"page":"Pitch_(music)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"EVk0dK3FuJ"},{"type":"text","value":". Sounds below 20 Hz are referred to as ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"bsEEGmjjII"},{"type":"link","url":"https://en.wikipedia.org/wiki/Infrasound","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"infrasound","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Fwz0LUaa4Q"}],"urlSource":"https://en.wikipedia.org/wiki/Infrasound","data":{"page":"Infrasound","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"jB0JXSeEs4"},{"type":"text","value":" and are generally imperceptible to the human ear, while those above 20,000 Hz are called ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"OG2e14lKRj"},{"type":"link","url":"https://en.wikipedia.org/wiki/Ultrasound","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"ultrasound","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"tB06LgW8Lw"}],"urlSource":"https://en.wikipedia.org/wiki/Ultrasound","data":{"page":"Ultrasound","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"oCddJqoEy6"},{"type":"text","value":" and also lie beyond our hearing range. Within the audible spectrum, our sensitivity to pitch and frequency varies, with the greatest acuity in the mid-frequency range, which is crucial for understanding speech and music.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"EudotqnmN1"}],"key":"j2291em6Po"},{"type":"image","url":"/sensingsoundandmusic/build/44e0448026a6fd476b34807c09fd5bd0.png","alt":"human hearing","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"RbKtigTJeP","urlSource":"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/H%C3%B6rfl%C3%A4che.svg/960px-H%C3%B6rfl%C3%A4che.svg.png"},{"type":"exercise","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Exploring Pitch with Glicol","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"bu2UmtNDJB"}],"key":"abSI22kk6q"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Use ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"KK8aTq3gzL"},{"type":"link","url":"https://glicol.org/tour#basicconnection","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Glicol","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"o04ftfPsu3"}],"urlSource":"https://glicol.org/tour#basicconnection","key":"JMnRPLrr0A"},{"type":"text","value":" to play sine tones at different frequencies across the human hearing range. Try frequencies at the extremes, below 100 Hz and above 15,000 Hz. What is the range of your hearing?","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"pkQfXbXoCK"}],"key":"cYgw8hAdgG"}],"enumerated":true,"label":"exercise-zeSwZJ1G5G","identifier":"exercise-zeswzj1g5g","enumerator":"3","html_id":"exercise-zeswzj1g5g","key":"yUR5FYB7wp"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"It is well-known that dogs have better hearing than humans, and the following graphs show that humans are in the middle of the pitch range among animals. Different animal species have evolved to detect sounds in frequency ranges that are most relevant to their survival and communication. For example, dogs can hear frequencies up to around 45,000 Hz, allowing them to detect high-pitched noises that are inaudible to humans. Bats and dolphins can perceive even higher frequencies, well into the ultrasonic range, which they use for echolocation. On the other hand, elephants and some whales can hear infrasound—very low frequencies below the human hearing threshold—which helps them communicate over long distances.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"onvM2Et8yP"}],"key":"UF6dHIsLC8"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"The chart below compares the hearing ranges of various animals, illustrating how human hearing fits within the broader spectrum of animal auditory perception. This diversity in hearing abilities reflects the different ecological needs and evolutionary pressures faced by each species. Understanding these differences not only highlights the uniqueness of human hearing but also provides insight into how other animals experience the world of sound.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"iNZdaydm51"}],"key":"HzSI6hkZ9M"},{"type":"image","url":"/sensingsoundandmusic/build/1faf9b8769a5fb9cbdeaa3221bb50ead.svg","alt":"animal hearing","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"tzZaP0zfDl","urlSource":"https://upload.wikimedia.org/wikipedia/commons/5/5d/Animal_hearing_frequency_range.svg"},{"type":"heading","depth":3,"position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Just Noticeable Differences for pitch","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"zrDyAmqX0k"}],"identifier":"just-noticeable-differences-for-pitch","label":"Just Noticeable Differences for pitch","html_id":"just-noticeable-differences-for-pitch","implicit":true,"key":"cwpZaGoXlQ"},{"type":"paragraph","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"We have a just noticeable difference (JND) also for pitch, which relates to the smallest change in frequency that a listener can reliably detect. The human ear is highly sensitive to small frequency changes, especially in the mid-frequency range (about 500–4000 Hz, where speech and music are most prominent). For example, at 1000 Hz, the JND for pitch is typically around 3 Hz for trained listeners, which is about 0.3% of the frequency. This means that if you play two tones at 1000 Hz and 1003 Hz, a trained listener can usually tell them apart. At very low or very high frequencies, the JND becomes larger, meaning it is harder to distinguish small pitch differences.","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"QCfDdE7u2g"}],"key":"u2YMCw2ogK"},{"type":"exercise","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Explore JND for Pitch","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"hSMwVVqQGY"}],"key":"idGhAU5Yrn"},{"type":"paragraph","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Try using ","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"ocSyGNYUZl"},{"type":"link","url":"https://glicol.org/tour#basicconnection","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Glicol","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"e2wsaeErVz"}],"urlSource":"https://glicol.org/tour#basicconnection","key":"bdh7X9WoZS"},{"type":"text","value":" to play two sine tones in succession: start with a reference tone (e.g., 1000 Hz), then play a second tone slightly higher (e.g., 1002 Hz, 1005 Hz, 1010 Hz). At what frequency difference can you reliably hear a change in pitch? Try different frequency ranges and note how your sensitivity changes.","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"Ar0raqWkXt"}],"key":"uQNNNIuZmp"}],"enumerated":true,"label":"exercise-zRiMhDsIVL","identifier":"exercise-zrimhdsivl","enumerator":"4","html_id":"exercise-zrimhdsivl","key":"n8uLwjlGm9"},{"type":"paragraph","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"The JND for pitch vary depending on factors such as the listener’s age, hearing ability, training, the loudness of the tones, and whether the tones are played in isolation or in a complex sound environment.","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"OQcfPViBgR"}],"key":"qombfSAh6R"}],"key":"GyNTKzsJAa"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Timbre","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LnMnfhE5Jl"}],"identifier":"timbre","label":"Timbre","html_id":"timbre","implicit":true,"key":"styc7kXsYY"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Timbre","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Timbre","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"xHBPbPJiGA"}],"urlSource":"https://en.wikipedia.org/wiki/Timbre","data":{"page":"Timbre","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"an7p3I5g9C"}],"key":"cSAVjIsrj4"},{"type":"text","value":" is the quality of a sound that distinguishes different types of sound sources, even when they have the same pitch and loudness. It is what allows us to tell apart a piano and a violin playing the same note at the same volume. Timbre is shaped by the spectral content (the mix of the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MZN2tdi3Td"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"fundamental","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"otIIHUam6U"}],"key":"rkHW95JHhq"},{"type":"text","value":" and the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ahxMlxBKUt"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"overtones","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"D59qWlN2Hl"}],"key":"Kmv80P0uat"},{"type":"text","value":"), the temporal envelope (attack, decay, sustain, release), and other characteristics such as vibrato or noise components. In music and audio, timbre is essential for identifying instruments, voices, and sound textures.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"aKkQMXtXtZ"}],"key":"Hxlpw6dkAn"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Overtones","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"dWTMnNzNcc"}],"identifier":"overtones","label":"Overtones","html_id":"overtones","implicit":true,"key":"EcJSpHPR06"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"When a musical instrument or voice produces a note, it doesn’t just generate a single frequency (the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Z9oe8UDPn3"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"fundamental","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"SEhtHx5LgQ"}],"key":"wJ3WVVp5Fp"},{"type":"text","value":"), but also a series of higher frequencies called ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"wv2Twf3J50"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"overtones","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"eEBTlk2Zvc"}],"key":"sJmpRoHiEz"},{"type":"text","value":" or ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"NSFbcE8qPv"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"harmonics","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ygiysxd9zN"}],"key":"pbWe15Pop0"},{"type":"text","value":". These overtones are integer multiples of the fundamental frequency and contribute to the richness and color of the sound.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"CJ0cWyXX4U"}],"key":"o2SgtfddQc"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":9,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Fundamental","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"EJ0J2BPD5N"}],"key":"gYYM8QbseJ"},{"type":"text","value":": The lowest frequency of a sound, typically perceived as its pitch.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"pbf7n4KIir"}],"key":"D7guOkqnWL"}],"key":"LdxTT7PxqQ"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Overtones/Harmonics","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"JJiphA5Qkv"}],"key":"uAa1gFNvuA"},{"type":"text","value":": Frequencies above the fundamental. The first overtone is the second harmonic (2× the fundamental), the second overtone is the third harmonic (3× the fundamental), and so on.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"uTjhXbZQ2k"}],"key":"ymTwkyGI8y"}],"key":"dZHiTxsxhw"}],"key":"XgJ2xRFFwp"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"A pure sine wave has no overtones and sounds “plain” or “pure,” while most musical sounds are complex and rich due to their overtone content. The specific pattern and strength of overtones determine the timbre of an instrument. For example, a clarinet and a violin playing the same note will have different overtone structures, making them sound distinct.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"ugEdkyWjiL"}],"key":"QaiZSlm7C3"}],"key":"DtDW61USyx"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\n\n# Spectrogram for sound1 (log scale, limited to 0-5000 Hz)\nplt.subplot(2, 1, 1)\nplt.specgram(sound1, Fs=sr, NFFT=128, noverlap=64, cmap='viridis', scale='dB')\nplt.ylim(0, 5000)\nplt.title('Spectrogram (0-5000 Hz): Pure Tone')\nplt.xlabel('Time (s)')\nplt.ylabel('Frequency (Hz)')\n\n# Spectrogram for sound2 (log scale, limited to 0-5000 Hz)\nplt.subplot(2, 1, 2)\nplt.specgram(sound2, Fs=sr, NFFT=128, noverlap=64, cmap='viridis', scale='dB')\nplt.ylim(0, 5000)\nplt.title('Spectrogram (0-5000 Hz): Tone with Overtones')\nplt.xlabel('Time (s)')\nplt.ylabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()\n","visibility":"hide","key":"SOIQD43QcI"},{"type":"output","id":"mU6C3XLS-1dbs-hg01Gay","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"7305d0c4bba1133e13486ace15ede893","path":"/sensingsoundandmusic/build/7305d0c4bba1133e13486ace15ede893.png"},"text/plain":{"content":"<Figure size 1000x600 with 2 Axes>","content_type":"text/plain"}}}],"visibility":"show","key":"i2MgLutTco"}],"visibility":"show","key":"pMAgFeCYha"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Envelope","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mFyHna9Dq6"}],"identifier":"envelope","label":"Envelope","html_id":"envelope","implicit":true,"key":"W0XQUAjo12"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MVPYmiHuui"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Envelope_(waves)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"envelope","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"v2fLXakvK3"}],"urlSource":"https://en.wikipedia.org/wiki/Envelope_(waves)","data":{"page":"Envelope_(waves)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"mHYKfNDqcb"}],"key":"DwVd7o130y"},{"type":"text","value":" of a sound describes how its amplitude changes over time, shaping the sound’s overall character and dynamics. The envelope determines how a sound starts, develops, and ends, and is crucial for distinguishing between different instruments and sound types.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"kfvayXMhOV"}],"key":"RGBhFHn6pZ"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"In audio synthesis, the most common model is the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"BGOkR07j3J"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"ADSR envelope","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"swgnWret6c"}],"urlSource":"https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope","data":{"page":"Synthesizer#ADSR_envelope","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"HXVHKPZ0rw"}],"key":"YaVwl6zSWH"},{"type":"text","value":", which stands for ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"iVxNr80pfF"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Attack","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"qxpPnMIyXo"}],"key":"mCFwZdBvvs"},{"type":"text","value":", ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Y9YlZJZbvt"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Decay","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"JKbr3gUiDY"}],"key":"J51Qsjl7aD"},{"type":"text","value":", ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"HyLieZM82a"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Sustain","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"SPuVt68IVk"}],"key":"YjxvTb0jAW"},{"type":"text","value":", and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"SbLfB28K6e"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Release","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"cHrKsvMWNM"}],"key":"Iin6PPB6VO"},{"type":"text","value":":","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"oq3D3cobM0"}],"key":"u8EuwgPlpI"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Attack","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"d3Qr17O0Jn"}],"key":"AtbMGKuPwy"},{"type":"text","value":": The time it takes for the sound to reach its maximum amplitude after being triggered.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"G7E1dqltys"}],"key":"wjWLoC5djf"}],"key":"Wv0fHjXOQS"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Decay","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"y4fFjc5mi4"}],"key":"DHVkGhb6Mj"},{"type":"text","value":": The time it takes for the amplitude to decrease from the peak level to the sustain level.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"Yffn5xffUn"}],"key":"e6iCEZLQFx"}],"key":"V5KHOQCnbX"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Sustain","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"sPeg0x515Q"}],"key":"O79bgWEdsH"},{"type":"text","value":": The level at which the sound holds while the note is sustained.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"aCLmQprpMi"}],"key":"KjZ6wPuOGL"}],"key":"IJyESQXLGT"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Release","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"f7YPd2kKZk"}],"key":"Iqw0mTc9rP"},{"type":"text","value":": The time it takes for the sound to fade to silence after the note is released.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"o5YdMg0SFf"}],"key":"cgIvv9SOj9"}],"key":"oA35pLRuKM"}],"key":"qwzM3jCzdO"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/db2912eafa08457f706831f1f7fa21c0.svg","alt":"ADSR","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"uHUhOKecc1","urlSource":"https://upload.wikimedia.org/wikipedia/commons/e/ea/ADSR_parameter.svg"},{"type":"text","value":"\n","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"R6iQ9WfoOV"},{"type":"emphasis","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Image source: ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"KUqitaNjL3"},{"type":"link","url":"https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"ADSR envelope on Wikipedia","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"xVYHLPBDJ8"}],"urlSource":"https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope","data":{"page":"Synthesizer#ADSR_envelope","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"yFWwpbGhhh"},{"type":"text","value":".","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"asDuGSDwn3"}],"key":"kkHJDaC280"}],"key":"SzEFrulhYA"},{"type":"heading","depth":3,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Just noticeable differences of timbre","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"jHEC3bIGAG"}],"identifier":"just-noticeable-differences-of-timbre","label":"Just noticeable differences of timbre","html_id":"just-noticeable-differences-of-timbre","implicit":true,"key":"RLNSUT9T2L"},{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"How many partials do you need to recognize the timbre of a sound. Below you can find examples of a Sony Rollins saxophone tone that has been spectrally decomposed and with resynthesis of an increasing number of overtones.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"YTTNtXQzAA"}],"key":"zGV8L5bSPo"}],"key":"u5AcaARMXd"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Audio\n\nfor fname in filenames:\n    y, sr = librosa.load(fname, sr=None)\n    plt.figure(figsize=(8, 3))\n    S = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n    librosa.display.specshow(S, sr=sr, x_axis='time', y_axis='log')\n    plt.title(f\"Spectrogram: {fname.split('/')[-1]}\")\n    plt.colorbar(format='%+2.0f dB')\n    plt.tight_layout()\n    plt.show()\n    display(Audio(y, rate=sr))\n","visibility":"hide","key":"J8uu5qp423"},{"type":"output","id":"ghIq4D-slWL0oh6jjTz4G","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"1ddfd75fe4298752804d5417f63eacf8","path":"/sensingsoundandmusic/build/1ddfd75fe4298752804d5417f63eacf8.png"},"text/plain":{"content":"<Figure size 800x300 with 2 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"fc36079f03894ae695e9c39a771f090c","path":"/sensingsoundandmusic/build/fc36079f03894ae695e9c39a771f090c.html"},"text/plain":{"content":"<IPython.lib.display.Audio object>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"dfd2a8ccd3d06ca9df1613e312465127","path":"/sensingsoundandmusic/build/dfd2a8ccd3d06ca9df1613e312465127.png"},"text/plain":{"content":"<Figure size 800x300 with 2 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"3119db6051b74ae457223569b486e7a9","path":"/sensingsoundandmusic/build/3119db6051b74ae457223569b486e7a9.html"},"text/plain":{"content":"<IPython.lib.display.Audio object>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"7484d9bd6c2a5ca7063e617fce4b6b4a","path":"/sensingsoundandmusic/build/7484d9bd6c2a5ca7063e617fce4b6b4a.png"},"text/plain":{"content":"<Figure size 800x300 with 2 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"176fdca122e7ce71984e83d87243af55","path":"/sensingsoundandmusic/build/176fdca122e7ce71984e83d87243af55.html"},"text/plain":{"content":"<IPython.lib.display.Audio object>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"45ece1d1d5385324d21dafec5fd1e6da","path":"/sensingsoundandmusic/build/45ece1d1d5385324d21dafec5fd1e6da.png"},"text/plain":{"content":"<Figure size 800x300 with 2 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"5cce66f97c3dee83be8fd56e80b5f240","path":"/sensingsoundandmusic/build/5cce66f97c3dee83be8fd56e80b5f240.html"},"text/plain":{"content":"<IPython.lib.display.Audio object>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"cf45c959eca74c99f5ca316d5ba04031","path":"/sensingsoundandmusic/build/cf45c959eca74c99f5ca316d5ba04031.png"},"text/plain":{"content":"<Figure size 800x300 with 2 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"b5c278e0425910a7ddb7b590a978c27a","path":"/sensingsoundandmusic/build/b5c278e0425910a7ddb7b590a978c27a.html"},"text/plain":{"content":"<IPython.lib.display.Audio object>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"93be2b8ca1a67fdf4479ef7623819ec4","path":"/sensingsoundandmusic/build/93be2b8ca1a67fdf4479ef7623819ec4.png"},"text/plain":{"content":"<Figure size 800x300 with 2 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"b6b577d79cbaabba454a94238049754e","path":"/sensingsoundandmusic/build/b6b577d79cbaabba454a94238049754e.html"},"text/plain":{"content":"<IPython.lib.display.Audio object>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"7349edc31eaddfc5ebbfa93163105386","path":"/sensingsoundandmusic/build/7349edc31eaddfc5ebbfa93163105386.png"},"text/plain":{"content":"<Figure size 800x300 with 2 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"906fa1a82d19c12e0b0120896a66753f","path":"/sensingsoundandmusic/build/906fa1a82d19c12e0b0120896a66753f.html"},"text/plain":{"content":"<IPython.lib.display.Audio object>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"7c51fc4ffb24b6f6cb4f1d7840a9410c","path":"/sensingsoundandmusic/build/7c51fc4ffb24b6f6cb4f1d7840a9410c.png"},"text/plain":{"content":"<Figure size 800x300 with 2 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"02e4ea41ab6264aa0dfd4dca7c38433d","path":"/sensingsoundandmusic/build/02e4ea41ab6264aa0dfd4dca7c38433d.html"},"text/plain":{"content":"<IPython.lib.display.Audio object>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"06a67723853c9237d72e63b9e98e456e","path":"/sensingsoundandmusic/build/06a67723853c9237d72e63b9e98e456e.png"},"text/plain":{"content":"<Figure size 800x300 with 2 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"639652d3c9068f3fad7d69be76908ded","path":"/sensingsoundandmusic/build/639652d3c9068f3fad7d69be76908ded.html"},"text/plain":{"content":"<IPython.lib.display.Audio object>","content_type":"text/plain"}}}],"visibility":"show","key":"Tgvu2VoIkj"}],"visibility":"show","key":"riDN6z0MQu"},{"type":"block","kind":"notebook-content","children":[{"type":"exercise","children":[{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"How many overtones do you need to hear the full richness of the saxophone?","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"QJHfP9fgyR"}],"key":"IptfN2RQP6"}],"enumerated":true,"label":"exercise-qAk89fKhdm","identifier":"exercise-qak89fkhdm","enumerator":"5","html_id":"exercise-qak89fkhdm","key":"v1GXLhnjiO"}],"key":"jMlGObvSVI"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Spatial perception","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HmNACysSTJ"}],"identifier":"spatial-perception","label":"Spatial perception","html_id":"spatial-perception","implicit":true,"key":"gjPhceMo40"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Sound_localization","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Spatial hearing","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"guwfe2iRYo"}],"urlSource":"https://en.wikipedia.org/wiki/Sound_localization","data":{"page":"Sound_localization","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"mDNKZIuKKN"}],"key":"hO6mR8VN12"},{"type":"text","value":" refers to our ability to perceive the location and movement of sound sources in our environment. This skill allows us to determine where a sound is coming from—whether it is in front, behind, above, below, or to the side. Spatial hearing is essential for navigating the world, understanding speech in complex environments, and enjoying immersive audio experiences in music and virtual reality.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"G1uYdQ0ZCE"}],"key":"WIPtfFfzIm"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Binaural_hearing","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Binaural hearing","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"fhGM5spnGo"}],"urlSource":"https://en.wikipedia.org/wiki/Binaural_hearing","data":{"page":"Binaural_hearing","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"sbR63mK21U"},{"type":"text","value":" is the process of using both ears to perceive spatial cues and localize sounds. By comparing the differences in timing (ITD) and intensity (ILD) between the two ears, the brain constructs a three-dimensional auditory scene. Binaural hearing is essential for depth perception, sound localization, and separating different sound sources in complex environments.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VajBBOOLgr"}],"key":"Zj7bgqIXGx"},{"type":"heading","depth":3,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Interaural time difference","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"PkxOgjmsEu"}],"identifier":"interaural-time-difference","label":"Interaural time difference","html_id":"interaural-time-difference","implicit":true,"key":"hbNiHpulqF"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Ey5zP7sGvL"},{"type":"link","url":"https://en.wikipedia.org/wiki/Sound_localization#Interaural_time_difference","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"interaural time difference (ITD)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"EOOG4f46Dn"}],"urlSource":"https://en.wikipedia.org/wiki/Sound_localization#Interaural_time_difference","data":{"page":"Sound_localization#Interaural_time_difference","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"pkpONh2jS7"},{"type":"text","value":" is the difference in the arrival time of a sound at each ear. When a sound source is positioned off-center, it reaches one ear slightly before the other. The brain uses this tiny time difference, especially for low-frequency sounds, to help localize the direction of the sound source on the horizontal plane. ITD is a primary cue for determining the azimuth (left-right position) of sounds.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"VQVzpbnJcE"}],"key":"eGIIpJaCXf"},{"type":"image","url":"/sensingsoundandmusic/build/d318e146b8a0996d4632f46eb573fe96.jpeg","alt":"ITD","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"QoWaDZ5GPa","urlSource":"https://upload.wikimedia.org/wikipedia/commons/3/3d/Interaural_Diferencia_de_tiempo_%28ITD%29_entre_izquierdo_%28inferior%29_y_correcto_%28superior%29_orejas.jpg"},{"type":"heading","depth":3,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Interaural level difference","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"v4k4tDK9rJ"}],"identifier":"interaural-level-difference","label":"Interaural level difference","html_id":"interaural-level-difference","implicit":true,"key":"zvVDeXqnCi"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Sound_localization#Interaural_level_difference","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Interaural level difference (ILD)","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"LIY9brwBhb"}],"urlSource":"https://en.wikipedia.org/wiki/Sound_localization#Interaural_level_difference","data":{"page":"Sound_localization#Interaural_level_difference","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"ZaRbu7H0mU"},{"type":"text","value":" refers to the difference in sound pressure level reaching each ear. When a sound comes from one side, the head acts as a barrier, causing the sound to be louder in the ear closer to the source and quieter in the far ear. ILD is most effective for high-frequency sounds, where the head shadow effect is more pronounced. The brain combines ILD with ITD to accurately localize sounds.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"RGQlem8A0g"}],"key":"mnH0hwDC9H"},{"type":"image","url":"/sensingsoundandmusic/build/81f7412a35ef648d6060772303b2d607.jpeg","alt":"ILD","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"yldqQ0Wfu3","urlSource":"https://upload.wikimedia.org/wikipedia/commons/c/c3/ExempleILD.jpg"},{"type":"heading","depth":3,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Head-related transfer function","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"QFbEN9WTX5"}],"identifier":"head-related-transfer-function","label":"Head-related transfer function","html_id":"head-related-transfer-function","implicit":true,"key":"HzUM76FLID"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"pvo60wDPHC"},{"type":"link","url":"https://en.wikipedia.org/wiki/Head-related_transfer_function","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"head-related transfer function (HRTF)","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"ZSX73QeEpu"}],"urlSource":"https://en.wikipedia.org/wiki/Head-related_transfer_function","data":{"page":"Head-related_transfer_function","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"uf8twzWC0s"},{"type":"text","value":" describes how an ear receives a sound from a specific point in space, taking into account the effects of the listener’s head, torso, and outer ear (pinna). HRTFs are unique to each individual and are crucial for perceiving elevation and front-back differences in sound localization. They are widely used in 3D audio and virtual reality to simulate realistic spatial audio experiences.","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"voR3JbKv0C"}],"key":"pwWSl49YYd"},{"type":"image","url":"/sensingsoundandmusic/build/1bd89b43e124f43674f0cb23eb51f8d9.svg","alt":"HRTF","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"j2Cwf3SDyD","urlSource":"https://upload.wikimedia.org/wikipedia/commons/5/50/HRTF.svg"},{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"OIWhc5prBy"},{"type":"link","url":"https://en.wikipedia.org/wiki/Precedence_effect","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"precedence effect","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"zuJUix7GLB"}],"urlSource":"https://en.wikipedia.org/wiki/Precedence_effect","data":{"page":"Precedence_effect","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"a47rffjTfN"},{"type":"text","value":" is a phenomenon where the first-arriving sound dominates our perception of the sound’s location, even if reflections or echoes follow shortly after. This effect helps us focus on the direct sound source in reverberant environments, such as distinguishing a speaker’s voice in a large hall, and prevents confusion from multiple sound reflections.","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"MpMMyo65ab"}],"key":"k4s5psPfXK"},{"type":"heading","depth":3,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Cocktail party effect","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"E1g19f74qH"}],"identifier":"cocktail-party-effect","label":"Cocktail party effect","html_id":"cocktail-party-effect","implicit":true,"key":"k442zbFGAq"},{"type":"paragraph","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"KB9eYddi1k"},{"type":"link","url":"https://en.wikipedia.org/wiki/Cocktail_party_effect","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"cocktail party effect","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"rEig1bGfac"}],"urlSource":"https://en.wikipedia.org/wiki/Cocktail_party_effect","data":{"page":"Cocktail_party_effect","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"KT5GzR4SNO"},{"type":"text","value":" describes our remarkable ability to focus on a single sound source, such as a conversation partner, in a noisy environment filled with competing sounds. This selective attention relies on spatial hearing cues, as well as cognitive processes, to filter out background noise and enhance the target sound. The cocktail party effect is a key aspect of auditory scene analysis and is fundamental to effective communication in social settings.","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"pnAQVW0Gst"}],"key":"Fb2sO9uNaz"}],"key":"AEok0jW5mS"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Auditory illusions","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZbXM6OhtLg"}],"identifier":"auditory-illusions","label":"Auditory illusions","html_id":"auditory-illusions","implicit":true,"key":"NlkCGOUMGD"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Auditory illusions are fascinating because they reveal the complex ways in which our brains interpret sound, often going beyond the raw physical properties of audio signals. By studying these illusions, we gain insight into the mechanisms of human auditory perception, how we organize, prioritize, and sometimes misinterpret acoustic information. This understanding is crucial for fields like music production, audio engineering, hearing aid design, and the development of perceptually efficient audio codecs.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"mnOwHdytqj"}],"key":"lIS7oc4srs"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Hysteresis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"DHa18pAQLA"}],"identifier":"hysteresis","label":"Hysteresis","html_id":"hysteresis","implicit":true,"key":"ksqrg1yThf"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Hysteresis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Hysteresis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"oAhswkXMYK"}],"urlSource":"https://en.wikipedia.org/wiki/Hysteresis","data":{"page":"Hysteresis","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"jL8X8YMqS2"}],"key":"t5wqr7RXcp"},{"type":"text","value":" refers to the phenomenon where the response of a system depends not only on its current state but also on its past states. In psychoacoustics, hysteresis can be observed in loudness perception: the perceived loudness of a sound may depend on the sequence of sounds that came before it. For example, if a listener is exposed to a loud sound and then to a softer sound, the softer sound may seem even quieter than if it were heard in isolation. Conversely, a gradual increase in volume may be perceived differently than a sudden jump, even if the final sound pressure level is the same. This effect highlights how our auditory system adapts to changing sound environments and why context and listening history can influence how loud a sound seems.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"MQOoMz9GaN"}],"key":"xB8cquBq6B"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/93bd867b14dcf6a1b6abc41d7cdf23bc.png","alt":"Hysteresis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Eq3aQrNhSh","urlSource":"https://upload.wikimedia.org/wikipedia/en/e/e2/Hysteresis.png"},{"type":"text","value":"\n","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"elGY0DqBTg"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Image Source: ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"aDWtOd1dDO"},{"type":"link","url":"https://en.wikipedia.org/wiki/Hysteresis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Wikipedia - Hysteresis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"mrOGqoj0P7"}],"urlSource":"https://en.wikipedia.org/wiki/Hysteresis","data":{"page":"Hysteresis","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"iLHj6houEx"}],"key":"JLLzAGnFm5"}],"key":"T8CVUekV8S"},{"type":"heading","depth":3,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Masking Effects","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"jGsejtTxzT"}],"identifier":"masking-effects","label":"Masking Effects","html_id":"masking-effects","implicit":true,"key":"PAkZnAEr2i"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Masking","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"Ms4GDQEk5F"}],"key":"iF9xPT8iE8"},{"type":"text","value":" in psychoacoustics refers to the phenomenon where the presence of one sound (the masker) makes it more difficult to hear another sound (the maskee). This occurs because the auditory system has limited frequency and temporal resolution, so strong or similar sounds can “cover up” weaker or nearby sounds, making them less perceptible or even inaudible.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"f7wvxLSi0y"}],"key":"mUkXTXOvnx"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"There are different types of masking. ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"ivikxl3Dhw"},{"type":"link","url":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Simultaneous_masking","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Simultaneous Masking","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"S7OmCVGeNd"}],"urlSource":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Simultaneous_masking","data":{"page":"Masking_(psychophysics)#Simultaneous_masking","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"dUzuunUgNv"},{"type":"text","value":" refers to when two sounds are played at the same time, a louder sound (the masker) can make a softer sound (the maskee) inaudible, even if both are within the listener’s hearing range. This effect is strongest when the sounds are close in frequency. For example, in music production, a loud bass drum can mask a softer bass guitar note if they occur together and share similar frequencies. This principle is used in ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"pL2WjvAzsN"},{"type":"link","url":"https://en.wikipedia.org/wiki/Audio_compression_(data)","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"audio compression","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"VIQatUYQKd"}],"urlSource":"https://en.wikipedia.org/wiki/Audio_compression_(data)","data":{"page":"Audio_compression_(data)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"GhJTKgq2Mm"},{"type":"text","value":", such as ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"WSUNga3xGX"},{"type":"link","url":"https://en.wikipedia.org/wiki/MP3","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"MP3","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"cG9X8C0zKa"}],"urlSource":"https://en.wikipedia.org/wiki/MP3","data":{"page":"MP3","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"hWvY5TcJmU"},{"type":"text","value":", which remove masked sounds to reduce file size without noticeably affecting perceived audio quality.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"Jma555dTUr"}],"key":"ofJfFs2DDw"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Frequency_masking","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Frequency Masking","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"gZu43rqEjQ"}],"urlSource":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Frequency_masking","data":{"page":"Masking_(psychophysics)#Frequency_masking","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"uqfmITXSlZ"},{"type":"text","value":" is most effective when the masker and maskee are close in frequency, typically within the same ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"L6xc2ybnzl"},{"type":"link","url":"https://en.wikipedia.org/wiki/Critical_band","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"critical band","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"M8qX7ytLl0"}],"urlSource":"https://en.wikipedia.org/wiki/Critical_band","data":{"page":"Critical_band","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"fLQhsxzDbI"},{"type":"text","value":". The human ear divides the frequency spectrum into critical bands, and sounds within the same band are more likely to mask each other. This is why a high-pitched sound is less likely to be masked by a low-pitched sound, and vice versa. Masking is generally stronger for frequencies above the masker (upward spread) than for those below. This means a loud low-frequency sound can mask higher-frequency sounds more effectively than the reverse.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"l9nRe9jP3S"}],"key":"J5ZwMp764s"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Temporal_masking","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Temporal Masking","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"MiKFNXwGcu"}],"urlSource":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Temporal_masking","data":{"page":"Masking_(psychophysics)#Temporal_masking","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"KS4iEAu9mc"},{"type":"text","value":" refers to when a loud sound can mask a softer sound that occurs immediately before (","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"EM4KnyMnXJ"},{"type":"link","url":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Pre-masking","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"pre-masking","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"jCbqkfiW9b"}],"urlSource":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Pre-masking","data":{"page":"Masking_(psychophysics)#Pre-masking","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"hTAbAVZBMC"},{"type":"text","value":") or after (","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"H0RtdP7HTg"},{"type":"link","url":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Post-masking","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"post-masking","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"yvmO3yb8cZ"}],"urlSource":"https://en.wikipedia.org/wiki/Masking_(psychophysics)#Post-masking","data":{"page":"Masking_(psychophysics)#Post-masking","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"F92zjRGXMc"},{"type":"text","value":") it, even if the two sounds do not overlap in time. Pre-masking can last up to about 20 ms before the masker, while post-masking can persist for up to 100 ms after the masker. This demonstrates the temporal resolution limits of human hearing and is also exploited in ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"fjx1UQNR6Y"},{"type":"link","url":"https://en.wikipedia.org/wiki/Perceptual_coding","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"perceptual audio coding","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"lOH57I8BNH"}],"urlSource":"https://en.wikipedia.org/wiki/Perceptual_coding","data":{"page":"Perceptual_coding","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"W3rhJAbQ9v"},{"type":"text","value":".","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"xiSwk7AwQA"}],"key":"AqGKpi4z4I"},{"type":"paragraph","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"The graph below illustrates how a masker tone at a certain frequency and intensity can raise the ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"VeYSAQ5xLh"},{"type":"link","url":"https://en.wikipedia.org/wiki/Absolute_threshold_of_hearing","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"threshold of hearing","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"LRHh2IpnBw"}],"urlSource":"https://en.wikipedia.org/wiki/Absolute_threshold_of_hearing","data":{"page":"Absolute_threshold_of_hearing","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"PKWYTNhhVr"},{"type":"text","value":" for nearby frequencies, making them inaudible unless they are louder than the masking threshold. This is a key concept in ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"pSCRs2ZxUA"},{"type":"link","url":"https://en.wikipedia.org/wiki/Psychoacoustics","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"psychoacoustics","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"HbzNowqTK7"}],"urlSource":"https://en.wikipedia.org/wiki/Psychoacoustics","data":{"page":"Psychoacoustics","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"aB8qcf1yuV"},{"type":"text","value":" and ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"xsyTgcsQAf"},{"type":"link","url":"https://en.wikipedia.org/wiki/Audio_engineering","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"audio engineering","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"zDTkErXv2k"}],"urlSource":"https://en.wikipedia.org/wiki/Audio_engineering","data":{"page":"Audio_engineering","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"jC7g6gXTSp"},{"type":"text","value":".","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"ahsAs47pYk"}],"key":"ZvSiJsyKYw"},{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"image","url":"/sensingsoundandmusic/build/e37cd6434c56aa6b97198965ac4faa6a.png","alt":"Audio Masking Graph","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"FHJFfiqUas","urlSource":"https://upload.wikimedia.org/wikipedia/commons/e/eb/Audio_Mask_Graph.png"},{"type":"text","value":"\n","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"bXEzjaDHrX"},{"type":"emphasis","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Image Source: ","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"fTo9RQgmNb"},{"type":"link","url":"https://en.wikipedia.org/wiki/Masking_(audio)","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Wikipedia - Audio Masking","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"CJfSjMtDT4"}],"urlSource":"https://en.wikipedia.org/wiki/Masking_(audio)","data":{"page":"Masking_(audio)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"hgCadZWRQ0"}],"key":"yiZ6WeQhhs"}],"key":"DAzqr3NsRo"},{"type":"paragraph","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"Some real-world examples of auditory masking includes how the sound of a passing truck can mask a conversation, making it difficult to hear speech until the truck has passed. In music, masking can be used creatively to blend instruments or to hide imperfections in a recording. In ","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"WD8xesnD9a"},{"type":"link","url":"https://en.wikipedia.org/wiki/Hearing_aid","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"hearing aids","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"gs2jXsaOzl"}],"urlSource":"https://en.wikipedia.org/wiki/Hearing_aid","data":{"page":"Hearing_aid","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"ezHludozBL"},{"type":"text","value":", understanding masking helps in designing algorithms that enhance speech while suppressing background noise.","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"qZvbUKoac4"}],"key":"o5ZsuOYixj"},{"type":"heading","depth":3,"position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Shepard and Risset tones","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"puZd0ZMEWv"}],"identifier":"shepard-and-risset-tones","label":"Shepard and Risset tones","html_id":"shepard-and-risset-tones","implicit":true,"key":"oKKh2kKQ9Y"},{"type":"paragraph","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"One of the most famous auditory illusions is named ","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"w52O82Uc1A"},{"type":"emphasis","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Shepard_tone","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Shepard Tones","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"Hvvn6FIzJ7"}],"urlSource":"https://en.wikipedia.org/wiki/Shepard_tone","data":{"page":"Shepard_tone","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"YEi5DouOHs"}],"key":"VIiHe1bkpG"},{"type":"text","value":" after ","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"P3pNGjIohz"},{"type":"link","url":"https://en.wikipedia.org/wiki/Roger_Shepard","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Roger Shepard (1929–2022)","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"Yo1Bgvzjhh"}],"urlSource":"https://en.wikipedia.org/wiki/Roger_Shepard","data":{"page":"Roger_Shepard","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"O8cLvtqp2B"},{"type":"text","value":". This is a series of tones that seem to continually ascend or descend in pitch, yet never get higher or lower. This creates the auditory equivalent of a “sonic barber pole.”","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"rrHKN00Qy7"}],"key":"HXOzwSyp9h"},{"type":"paragraph","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"The Shepard tone is created by layering several sine waves that are spaced one octave apart. As the sequence progresses, all the sine waves move up (or down) in pitch simultaneously. The highest-pitched sine wave fades out as it reaches the top of the range, while a new, low-pitched sine wave fades in at the bottom. The overall amplitude envelope is shaped so that the listener always hears a similar blend of frequencies, with no clear starting or ending point. This continuous overlap and cross-fading trick the brain into perceiving a never-ending rise (or fall) in pitch, even though the actual frequencies are cycling within a fixed range. The illusion exploits the way our auditory system groups harmonically related tones and interprets pitch changes, making it difficult to pinpoint when the scale “resets.”","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"KitCiUJbPr"}],"key":"v5XYAKfb34"},{"type":"paragraph","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Risset_tone","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"Risset tones","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"nWfj4t6bLM"}],"urlSource":"https://en.wikipedia.org/wiki/Risset_tone","data":{"page":"Risset_tone","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"S5Smieaxah"}],"key":"Uoypn47qZa"},{"type":"text","value":", named after French composer and scientist ","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"mQY7M9FJ9S"},{"type":"link","url":"https://en.wikipedia.org/wiki/Jean-Claude_Risset","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"Jean-Claude Risset","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"YfiC2Bl71b"}],"urlSource":"https://en.wikipedia.org/wiki/Jean-Claude_Risset","data":{"page":"Jean-Claude_Risset","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"qyFN2GnWMG"},{"type":"text","value":" (1938–2016), are often confused with Shepard tones because they are similar. However, while the Shepard tones are discrete, Risset showed that it is possible to create a similar illusion also work with continuous sounds. This type of auditory illusion is similar to Shepard tones, where a continuously ascending or descending pitch seems to rise or fall endlessly. This effect is achieved by overlapping sine waves that fade in and out at different frequencies, creating the impression of a never-ending scale. Risset tones demonstrate how our perception of pitch can be manipulated by carefully controlling the spectral content and amplitude envelopes of sounds.","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"DUw9BN1MuA"}],"key":"YMblVVfLth"},{"type":"paragraph","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Both Shepard and Risset tones have been used in sound design and music. Here is one of many examples:","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"vRAnFAWszt"}],"key":"ICt11dVDZL"},{"type":"iframe","src":"https://www.youtube.com/embed/OsBanpBQj0k?si=WvLI0whjufrvLyOX","width":"100%","key":"IEPAyEuyDR"},{"type":"heading","depth":3,"position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"Missing Fundamental","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"kCI2Lq0SCt"}],"identifier":"missing-fundamental","label":"Missing Fundamental","html_id":"missing-fundamental","implicit":true,"key":"BNMsBsQOmw"},{"type":"paragraph","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"Another powerful auditory illusion is called ","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"sSIzdky1rW"},{"type":"emphasis","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"text","value":"missing fundamental","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"ipYS69G8F5"}],"key":"i8Odn8EQL8"},{"type":"text","value":". When a complex tone lacks its fundamental frequency but contains its harmonics, listeners still perceive the pitch corresponding to the missing fundamental. This shows that pitch perception is based on the pattern of overtones, not just the lowest frequency present.","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"OPeFvHYNgW"}],"key":"UlfELu4Z9v"},{"type":"paragraph","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"For example, if you play a sound containing frequencies at 200 Hz, 300 Hz, and 400 Hz (the 2nd, 3rd, and 4th harmonics of 100 Hz), but omit the 100 Hz fundamental, most listeners will still perceive the pitch as if the 100 Hz tone were present. The auditory system analyzes the spacing between the harmonics and infers the fundamental frequency, even when it is physically absent.","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"yyZzLFzwt8"}],"key":"kLm8Vu9y6I"},{"type":"paragraph","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"This phenomenon is important in music and audio technology. For instance, small speakers (like those in smartphones) often cannot reproduce very low frequencies, but listeners can still perceive the intended bass notes due to the presence of higher harmonics. The missing fundamental effect is also used in telephony and audio compression to create the illusion of full-range sound with limited frequency content.","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"bItugVkzK7"}],"key":"rAKwVQDLjZ"},{"type":"paragraph","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"The missing fundamental illusion demonstrates that pitch perception is a constructive process, relying on the brain’s ability to detect regularities and patterns in the frequency spectrum, rather than simply responding to the presence of specific frequencies.","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"gkipI9ol7W"}],"key":"nfssOaxvLn"},{"type":"exercise","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Explore the Missing Fundamental with Glicol","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"WoTSjISCop"}],"key":"BgdHVDZU3l"},{"type":"paragraph","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"text","value":"Use ","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"W6ntrX0s39"},{"type":"link","url":"https://glicol.org/tour#basicconnection","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"text","value":"Glicol","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"LsFtHaWulg"}],"urlSource":"https://glicol.org/tour#basicconnection","key":"ORePKcEX0d"},{"type":"text","value":" to create a sound that contains only the 2nd, 3rd, and 4th harmonics of a fundamental frequency (for example, 200 Hz, 300 Hz, and 400 Hz), but omits the fundamental itself (100 Hz). What pitch do you perceive? Try changing the harmonics and observe how your perception of pitch changes. Can you still “hear” the missing fundamental?","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"AEWeLqETKz"}],"key":"n9bEAfH45F"}],"enumerated":true,"label":"exercise-W8WGyNTBaj","identifier":"exercise-w8wgyntbaj","enumerator":"6","html_id":"exercise-w8wgyntbaj","key":"a8iVNgiZud"},{"type":"heading","depth":3,"position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"Binaural Beats","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"ROXPCAkRW5"}],"identifier":"binaural-beats","label":"Binaural Beats","html_id":"binaural-beats","implicit":true,"key":"NchIeisvOm"},{"type":"paragraph","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"When two slightly different frequencies are played separately to each ear (using headphones), the listener perceives a rhythmic beating at the frequency difference. This illusion arises from the brain’s processing of phase differences between the ears.","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"gWmF8VCTVk"}],"key":"WNLztAugwq"}],"key":"Gc5QTtBqv1"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Questions","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SiA6DWJ4VV"}],"identifier":"questions","label":"Questions","html_id":"questions","implicit":true,"key":"Ok4VziRySa"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"What is the difference between sound pressure level (SPL) and loudness, and why is this distinction important in psychoacoustics?","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"OOwOIYErvy"}],"key":"wrzZjhQjfo"}],"key":"Eg0f2CJfpU"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"How does the human ear convert sound waves into electrical signals, and what are the main roles of the outer, middle, and inner ear in this process?","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Xfw7vObHYE"}],"key":"ZAzOaBd5Sr"}],"key":"t7tdyuC34M"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Explain the concept of masking in psychoacoustics. Give an example of how masking can affect our perception of sound in everyday life or music production.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"fmSZffcEIx"}],"key":"IHWoloh9iU"}],"key":"hkFXRBL33r"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"What are Shepard tones and Risset tones, and how do they demonstrate the brain’s role in pitch perception?","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Ipip0FMXSj"}],"key":"GZc6D3ZBJB"}],"key":"nieKcgn7yA"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"How do interaural time difference (ITD) and interaural level difference (ILD) help us localize sound sources in space?","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Vkw67vKuKW"}],"key":"XMDkyNRodo"}],"key":"IN4M8I3Ysm"}],"key":"XGHo8U7Crt"}],"key":"FlP7JOujdY"}],"key":"u8czDDv3P0"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Week 3: Acoustics","url":"/week3","group":"Sensing Sound and Music"},"next":{"title":"Week 5: Time and Rhythm","url":"/week5","group":"Sensing Sound and Music"}}},"domain":"http://localhost:3000"}