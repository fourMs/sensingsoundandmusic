<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Week 3: Acoustics - Sensing Sound and Music</title><meta property="og:title" content="Week 3: Acoustics - Sensing Sound and Music"/><meta name="generator" content="mystmd"/><meta name="description" content="This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts."/><meta property="og:description" content="This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts."/><meta name="keywords" content="sensing, sound, music, psychology, technology"/><meta name="image" content="/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg"/><meta property="og:image" content="/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg"/><link rel="stylesheet" href="/sensingsoundandmusic/build/_assets/app-5WKS5EPQ.css"/><link rel="stylesheet" href="/sensingsoundandmusic/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/sensingsoundandmusic/favicon.ico"/><link rel="stylesheet" href="/sensingsoundandmusic/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/sensingsoundandmusic/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Sensing Sound and Music" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/sensingsoundandmusic/">Sensing Sound and Music</a><a title="Week 1: Tuning in" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week1">Week 1: Tuning in</a><a title="Week 2: Listening" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week2">Week 2: Listening</a><a title="Week 3: Acoustics" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week3">Week 3: Acoustics</a><a title="Week 4: Psychoacoustics" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week4">Week 4: Psychoacoustics</a><a title="Week 5: Time and Rhythm" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week5">Week 5: Time and Rhythm</a><a title="Week 6: Harmony and melody" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week6">Week 6: Harmony and melody</a><a title="Week 7: Body Motion" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week7">Week 7: Body Motion</a><a title="Week 8: The Brain" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week8">Week 8: The Brain</a><a title="Week 9: Vision" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week9">Week 9: Vision</a><a title="Week 10: Physiology" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week10">Week 10: Physiology</a><a title="Week 11: Machine Listening" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/sensingsoundandmusic/week11">Week 11: Machine Listening</a></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Open_access" target="_blank" rel="noopener noreferrer" title="Open Access" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="mr-1 inline-block opacity-60 hover:opacity-100 hover:text-[#E18435]"><path d="M17.1 12.6h-2V7.5c0-1.7-1.4-3.1-3-3.1-.8 0-1.6.3-2.2.9-.6.5-.9 1.3-.9 2.2v.7H7v-.7c0-1.4.5-2.7 1.5-3.7s2.2-1.5 3.6-1.5 2.6.5 3.6 1.5 1.5 2.3 1.5 3.7v5.1z"></path><path d="M12 21.8c-.8 0-1.6-.2-2.3-.5-.7-.3-1.4-.8-1.9-1.3-.6-.6-1-1.2-1.3-2-.3-.8-.5-1.6-.5-2.4s.2-1.6.5-2.4c.3-.7.7-1.4 1.3-2s1.2-1 1.9-1.3c.7-.3 1.5-.5 2.3-.5.8 0 1.6.2 2.3.5.7.3 1.4.8 1.9 1.3.6.6 1 1.2 1.3 2 .3.8.5 1.6.5 2.4s-.2 1.6-.5 2.4c-.3.7-.7 1.4-1.3 2-.6.6-1.2 1-1.9 1.3-.7.3-1.5.5-2.3.5zm0-10.3c-2.2 0-4 1.8-4 4.1s1.8 4.1 4 4.1 4-1.8 4-4.1-1.8-4.1-4-4.1z"></path><circle cx="12" cy="15.6" r="1.7"></circle></svg></a><a href="https://github.com/fourMs/sensingsoundandmusic" title="GitHub Repository: fourMs/sensingsoundandmusic" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="inline-block mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block"><title>Jupyter Notebook</title><path d="M20.2 1.7c0 .8-.5 1.4-1.3 1.5-.8 0-1.4-.5-1.5-1.3 0-.8.5-1.4 1.3-1.5.8-.1 1.5.5 1.5 1.3zM12 17.9c-3.7 0-7-1.3-8.7-3.3 1.8 4.8 7.1 7.3 11.9 5.5 2.5-.9 4.5-2.9 5.5-5.5-1.7 2-4.9 3.3-8.7 3.3zM12 5.1c3.7 0 7 1.3 8.7 3.3-1.8-4.8-7.1-7.3-11.9-5.5-2.5.9-4.5 2.9-5.5 5.5 1.7-2 5-3.3 8.7-3.3zM6.9 21.8c.1 1-.7 1.8-1.7 1.9-1 .1-1.8-.7-1.9-1.7 0-1 .7-1.8 1.7-1.9 1-.1 1.8.7 1.9 1.7zM3.7 4.6c-.6 0-1-.4-1-1s.4-1 1-1 1 .4 1 1c0 .5-.4 1-1 1z"></path></svg></div><a href="https://github.com/fourMs/sensingsoundandmusic/edit/main/book/week3.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Week 3: Acoustics</h1><p class="mt-2 mb-0 lead text-zinc-600 dark:text-zinc-400">Introducing the physics of sound, room acoustics, and digital audio</p><header class="mt-4 not-prose"><div class="grid grid-cols-1 sm:grid-cols-2 gap-y-1"><div><span class="font-semibold text-sm"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R2t8top:" data-state="closed">Alexander Refsum Jensenius</button></span></div><div class="text-sm"><div>University of Oslo<!-- --> </div></div></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="IeYq6Ghot5" class="relative group/block"><p>This week will explore the world of <em>acoustics</em>, which is a term that everyone knows, yet few people can define properly. We will go over the physics of sound, and look more closely at instrument acoustics and room acoustics before ending with an introduction to digital sound.</p><h2 id="introduction" class="relative group"><span class="heading-text">Introduction</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#introduction" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="defining-acoustics" class="relative group"><span class="heading-text">Defining acoustics</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#defining-acoustics" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>A short definition can be that acoustics is the study of sound and its properties. The term originates from the Greek word <em>ἀκουστικός (akoustikos)</em>, meaning “of or for hearing, ready to hear.” According to the <a target="_blank" rel="noreferrer" href="https://webstore.ansi.org/standards/asa/ansiasas112013" class="">ANSI/ASA S1.1-2013</a> standard, acoustics typically have two meanings:</p><ol start="1"><li><p>The science of sound, encompassing its production, transmission, and effects, both biological and psychological (<a href="https://en.wikipedia.org/wiki/Acoustics" class="italic" target="_blank" rel="noreferrer" data-state="closed">acoustics</a>)</p></li><li><p>The qualities of a room that determine its auditory characteristics (which is the sub-discipline of <a href="https://en.wikipedia.org/wiki/Room_acoustics" class="italic" target="_blank" rel="noreferrer" data-state="closed">room acoustics</a>).</p></li></ol><p>We will begin by considering acoustics broadly and then some of its subdisciplines, room acoustics, instrument acoustics, and electroacoustics. However, the latter three are just some of the many subdisciplines of acoustics, as seen in this overview.</p><img id="T3tKxQO3gu" style="margin:0 auto" src="/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg" alt="Lindsay&#x27;s Wheel of Acoustics" data-canonical-url="https://upload.wikimedia.org/wikipedia/commons/8/82/Lindsay%27s_Wheel_of_Acoustics.svg" class=""/><p><em>Figure: Lindsay’s Wheel of Acoustics, illustrating the interdisciplinary nature of acoustics (<a target="_blank" rel="noreferrer" href="https://commons.wikimedia.org/wiki/File:Lindsay%27s_Wheel_of_Acoustics.svg" class="">source</a>).</em></p><h3 id="why-is-acoustics-important-for-musicology-music-psychology-and-music-technology" class="relative group"><span class="heading-text">Why is acoustics important for musicology, music psychology, and music technology?</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#why-is-acoustics-important-for-musicology-music-psychology-and-music-technology" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Understanding acoustics is essential for musicology, music psychology, and music technology because it provides the scientific foundation for how sound is produced, transmitted, and perceived. In musicology, acoustics helps analyze the physical properties of musical instruments and performance spaces, informing historical and cultural studies of music. In music psychology, acoustics underpins research into how humans perceive pitch, timbre, loudness, and spatial attributes of sound, which are crucial for understanding musical cognition and emotion. In music technology, acoustics guides the design of audio equipment, recording techniques, and digital sound processing, enabling innovations in music production, reproduction, and analysis. Thus, acoustics bridges the gap between the physical world of sound and its artistic, perceptual, and technological dimensions.</p></div><div id="qUzipEjeI2" class="relative group/block"><h3 id="cause-and-effect" class="relative group"><span class="heading-text">Cause and effect</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#cause-and-effect" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>At its core, acoustics is about describing the cause and effect of sound. If we consider this systemically, we can think of the following chain from cause to effect:</p><figure class=""></figure><p>The generating and receiving mechanisms in acoustics are typically achieved through <em>transduction</em>, the process of converting energy from one form to another (e.g., mechanical to electrical, or vice versa). Sound first propagates through a medium (such as air, water, or solids), and is then transduced again at the point of reception, enabling further processing or perception. This chain of transduction and propagation is fundamental to how sound is produced, transmitted, and experienced.</p><p>For example, when a guitarist plucks a string (cause), the string vibrates and generates sound waves (generating mechanism). These sound waves travel through the air (propagation) and reach the human ear, where it is transduced and processed further. We will get back to the ear next week.</p><p>The chain can be more complex. For example, the guitar sound can be picked up by a microphone, which converts the sound waves into electrical signals (reception/transduction). The electrical signals are then sent to a speaker, which converts them back into sound waves (effect/transduction), allowing the audience to hear the music.</p></div><div id="XpQhrM2Ws5" class="relative group/block"><h2 id="nature-of-sound-waves" class="relative group"><span class="heading-text">Nature of sound waves</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#nature-of-sound-waves" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="XOdHLJSsHZ" class="relative group/block"><h3 id="vibrations" class="relative group"><span class="heading-text">Vibrations</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#vibrations" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Vibrations are oscillatory motions of particles within a medium, which generate sound waves. These vibrations can be <em>periodic</em> (regular and repeating, as in musical notes) or <em>aperiodic</em> (irregular, as in noise). The nature of these vibrations determines the characteristics of the resulting sound, such as pitch and timbre. Vibrations are fundamental to the production and transmission of sound in acoustics. Let us begin by investigating some of the properties of sound waves.</p></div><div id="Dk8TjkEfpT" class="relative group/block"><aside class="myst-admonition myst-admonition-note my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-blue-500"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-blue-600 bg-blue-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-blue-600"><path stroke-linecap="round" stroke-linejoin="round" d="m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Note</div></div><div class="myst-admonition-body px-4 py-1"><p>In the following, all the plots will be generated by Python code running inside the Jupyter Notebook that this text is written in. You can at any point in time check the source of the code, and even try yourself locally or in <a target="_blank" rel="noreferrer" href="https://colab.research.google.com/github/alexarje/sensing/blob/main/book/week3.ipynb" class="">Colab</a>. You don’t need to understand the details of the code, but as you progress in your learning, it may help to be able to create such plots yourself.</p></div></aside></div><div id="Nk11tn8jKW" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># To make the rest of the code work, we need to load some Python libraries: 
import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import fft, fftfreq</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="bpcu9SrZdhq_X1ZlOnJYK" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system jupyter-error"><code><span style="color:rgb(187, 0, 0)">---------------------------------------------------------------------------</span><span>
</span><span style="color:rgb(187, 0, 0)">ModuleNotFoundError</span><span>                       Traceback (most recent call last)
</span><span style="color:rgb(0, 187, 187)">Cell</span><span style="color:rgb(0, 187, 187)"> </span><span style="color:rgb(0, 187, 0)">In[2]</span><span style="color:rgb(0, 187, 0)">, line 4</span><span>
</span><span style="color:rgb(0, 187, 0)">      2</span><span> </span><span style="color:rgb(0, 135, 0);font-weight:bold">import</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">numpy</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 135, 0);font-weight:bold">as</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">np</span><span>
</span><span style="color:rgb(0, 187, 0)">      3</span><span> </span><span style="color:rgb(0, 135, 0);font-weight:bold">import</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">matplotlib</span><span style="color:rgb(0, 0, 187);font-weight:bold">.</span><span style="color:rgb(0, 0, 187);font-weight:bold">pyplot</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 135, 0);font-weight:bold">as</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">plt</span><span>
</span><span style="color:rgb(0, 187, 0)">----&gt; </span><span style="color:rgb(0, 187, 0)">4</span><span> </span><span style="color:rgb(0, 135, 0);font-weight:bold">from</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">scipy</span><span style="color:rgb(0, 0, 187);font-weight:bold">.</span><span style="color:rgb(0, 0, 187);font-weight:bold">fft</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 135, 0);font-weight:bold">import</span><span> fft, fftfreq

</span><span style="color:rgb(187, 0, 0)">ModuleNotFoundError</span><span>: No module named &#x27;scipy&#x27;</span></code></pre></div></div></div><div id="eWExmvoODd" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define x
x = np.linspace(0, 2 * np.pi, 1000)

# Generate a periodic wave (sine wave)
periodic_wave = np.sin(2 * np.pi * x)

# Generate an aperiodic wave (random noise)
aperiodic_wave = np.random.normal(0, 0.5, len(x))

# Plot the periodic and aperiodic waves
plt.figure(figsize=(12, 6))

# Plot periodic wave
plt.subplot(2, 1, 1)
plt.plot(x, periodic_wave, label=&#x27;Periodic Wave (Sine)&#x27;, color=&#x27;blue&#x27;)
plt.title(&#x27;Periodic Wave&#x27;)
plt.xlabel(&#x27;x&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()

# Plot aperiodic wave
plt.subplot(2, 1, 2)
plt.plot(x, aperiodic_wave, label=&#x27;Aperiodic Wave (Noise)&#x27;, color=&#x27;red&#x27;)
plt.title(&#x27;Aperiodic Wave&#x27;)
plt.xlabel(&#x27;x&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()

plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="gZJXpP1COrB6ky1XBVj9w" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/2f5426082c7b88b0544bdc6afb51155e.png" alt="&lt;Figure size 1200x600 with 2 Axes&gt;"/></div></div><div id="eFmLUamHfF" class="relative group/block"><h3 id="longitudinal-and-transverse-waves" class="relative group"><span class="heading-text">Longitudinal and Transverse Waves</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#longitudinal-and-transverse-waves" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Mechanical waves travel through a medium (such as air, water, or solids) by causing particles to vibrate. These waves are classified based on the direction of particle motion relative to the direction of wave propagation:</p><ul><li><p><strong>Longitudinal waves</strong>: Particles oscillate parallel to the direction the wave travels. Sound waves in air are a common example.</p></li><li><p><strong>Transverse waves</strong>: Particles oscillate perpendicular to the direction of wave travel. Examples include waves on a string or surface water waves.</p></li></ul><p>Understanding these wave types is fundamental to acoustics, as they determine how energy is transmitted through different materials.</p></div><div id="vNZNOIctcY" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define parameters for the waves
x = np.linspace(0, 2 * np.pi, 100)
amplitude = 0.5
frequency = 1

# Generate waveforms
wave = np.sin(2 * np.pi * frequency * x)

# Create particle positions for longitudinal and transverse waves
longitudinal_x = x + amplitude * np.sin(2 * np.pi * frequency * x)
longitudinal_y = np.zeros_like(x)  # No vertical displacement

transverse_x = x  # No horizontal displacement
transverse_y = amplitude * np.sin(2 * np.pi * frequency * x)

# Create the figure
plt.figure(figsize=(12, 6))

# Plot longitudinal wave
plt.subplot(2, 1, 1)
plt.plot(x, np.zeros_like(x), &#x27;--&#x27;, color=&#x27;gray&#x27;, label=&#x27;Wave Direction&#x27;)
plt.scatter(longitudinal_x, longitudinal_y, color=&#x27;blue&#x27;, label=&#x27;Particles&#x27;)
plt.title(&#x27;Longitudinal Wave (Particles Oscillate Parallel to Wave Direction)&#x27;)
plt.xlabel(&#x27;Wave Direction&#x27;)
plt.ylabel(&#x27;Particle Displacement&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()

# Plot transverse wave
plt.subplot(2, 1, 2)
plt.plot(x, np.zeros_like(x), &#x27;--&#x27;, color=&#x27;gray&#x27;, label=&#x27;Wave Direction&#x27;)
plt.scatter(transverse_x, transverse_y, color=&#x27;red&#x27;, label=&#x27;Particles&#x27;)
plt.title(&#x27;Transverse Wave (Particles Oscillate Perpendicular to Wave Direction)&#x27;)
plt.xlabel(&#x27;Wave Direction&#x27;)
plt.ylabel(&#x27;Particle Displacement&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()

plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="RaOsKGhnki5Lsm9tlnV_X" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/d219b3543df3a209a2231c01bf085f27.png" alt="&lt;Figure size 1200x600 with 2 Axes&gt;"/></div></div><div id="vX7EK5RpUZ" class="relative group/block"><h3 id="frequency" class="relative group"><span class="heading-text">Frequency</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#frequency" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Frequency refers to the number of complete oscillations or cycles a sound wave undergoes per second, measured in Hertz (Hz). It determines the audible <em>pitch</em> of a sound: higher frequencies produce higher-pitched sounds, while lower frequencies result in lower-pitched sounds. Frequency is a fundamental property in acoustics, influencing how we perceive and analyze sound.</p></div><div id="NSKDEYpkoG" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define parameters for the sine waves
time = np.linspace(0, 1, 1000)  # Time in seconds (0 to 1 second)
freq1, freq2, freq3 = 1, 2, 3  # Frequencies of the sine waves in Hz
wave1 = np.sin(2 * np.pi * freq1 * time)  # First sine wave
wave2 = np.sin(2 * np.pi * freq2 * time)  # Second sine wave
wave3 = np.sin(2 * np.pi * freq3 * time)  # Third sine wave

# Plot the sine waves
plt.figure(figsize=(12, 4))
plt.plot(time, wave1, label=f&#x27;A: Frequency={freq1} Hz&#x27;)
plt.plot(time, wave2, label=f&#x27;B: Frequency={freq2} Hz&#x27;)
plt.plot(time, wave3, label=f&#x27;C: Frequency={freq3} Hz&#x27;)
plt.title(&#x27;Sine Waves with Different Frequencies&#x27;)
plt.xlabel(&#x27;Time (s)&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="f76h-5KldgUiC5qrJWyVC" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/43c4af62f61a4feb55348b860efa7d1a.png" alt="&lt;Figure size 1200x400 with 1 Axes&gt;"/></div></div><div id="s8QBwrtMb2" class="relative group/block"><p>The frequency of a wave is closely related to its <em>period</em>, the time it takes for one complete cycle of a wave to occur. The period is measured in seconds (s) and frequency is the number of cycles that occur per second, measured in Hertz (Hz).</p><p>[
f = \frac{1}{T}
]
[
T = \frac{1}{f}
]</p><p>For example, if a wave has a period of 0.01 seconds, its frequency is ( f = 1 / 0.01 = 100 ) Hz. If the frequency is 50 Hz, the period is ( T = 1 / 50 = 0.02 ) seconds.</p></div><div id="Qamw9CR64o" class="relative group/block"><h3 id="amplitude" class="relative group"><span class="heading-text">Amplitude</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#amplitude" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>A sound wave’s amplitude defines how “loud” it is. More precisely, amplitude is the maximum displacement of particles in the medium from their rest position as the wave passes through. In a graphical representation, such as a sine wave, amplitude corresponds to the peak value above and below the center line (zero).</p><p>Higher amplitude means greater energy in the wave, resulting in a louder sound. Lower amplitude produces a quieter sound. Amplitude is typically measured in units such as meters (for displacement), pascals (for pressure), or volts (for electrical signals).</p><p>For example, in the plot below, each sine wave has a specific amplitude. The peaks and troughs of the wave show the maximum and minimum values, illustrating how amplitude determines the loudness of the sound.</p></div><div id="CEzPzMQUzI" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define amplitudes for the sine tones
amplitude1 = 0.5
amplitude2 = 1.0
amplitude3 = 1.5

# Generate the sine tones
sine1 = amplitude1 * np.sin(x)
sine2 = amplitude2 * np.sin(x)
sine3 = amplitude3 * np.sin(x)

# Plot the sine tones
plt.figure(figsize=(12, 4))
plt.plot(x, sine1, label=&#x27;Amplitude = 0.5&#x27;, alpha=0.8)
plt.plot(x, sine2, label=&#x27;Amplitude = 1.0&#x27;, alpha=0.8)
plt.plot(x, sine3, label=&#x27;Amplitude = 1.5&#x27;, alpha=0.8)
plt.title(&#x27;Sine Tones with Different Amplitudes&#x27;)
plt.xlabel(&#x27;x&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="bxMPVMxbxpXpFg-K3koH4" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/95d21b1a311befa4436ef5db09f19e83.png" alt="&lt;Figure size 1200x400 with 1 Axes&gt;"/></div></div><div id="LpQqkoeESs" class="relative group/block"><h3 id="sound-pressure-level-spl" class="relative group"><span class="heading-text">Sound Pressure Level (SPL)</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#sound-pressure-level-spl" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p><a href="https://en.wikipedia.org/wiki/Sound_pressure#Sound_pressure_level" class="italic" target="_blank" rel="noreferrer" data-state="closed">Sound Pressure Level</a> (SPL) is a measure of the pressure variation caused by a sound wave. It is used in various fields, such as acoustics, audio engineering, and environmental noise monitoring, to assess sound levels and ensure compliance with safety standards. Understanding SPL is crucial for analyzing how sound behaves in different environments and its impact on human hearing.</p><p>SPL is expressed in <a href="https://en.wikipedia.org/wiki/Decibel" class="italic" target="_blank" rel="noreferrer" data-state="closed">decibels</a> (dB), which is a <em><a href="https://en.wikipedia.org/wiki/Logarithmic_scale" class="italic" target="_blank" rel="noreferrer" data-state="closed">logarithmic</a></em> unit used to express the ratio of two values. In a logarithmic scale, each step on the scale represents a multiplication rather than a simple addition. For example, an increase of 10 dB corresponds to a tenfold increase in sound intensity, while an increase of 20 dB means a hundredfold increase. This allows us to represent very large ranges of sound pressure in a compact and manageable way, since human hearing also perceives loudness logarithmically rather than linearly.</p><p>The formula for SPL in decibels is:</p><span class="" style="display:block;text-align:center"><strong>SPL</strong> = 20 log<sub>10</sub>(p / p<sub>0</sub>)</span><p>where <em>p</em> is the measured sound pressure and <em>p <sub>0</sub></em> is the reference sound pressure (typically 20 μPa in air).</p></div><div id="iimF5kBIE8" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Plot illustrating regular (linear) vs logarithmic scale

x = np.linspace(1, 1000, 1000)
y = x  # Linear relationship

plt.figure(figsize=(12, 5))

# Linear scale plot
plt.subplot(1, 2, 1)
plt.plot(x, y, color=&#x27;blue&#x27;)
plt.title(&#x27;Linear Scale&#x27;)
plt.xlabel(&#x27;x&#x27;)
plt.ylabel(&#x27;y&#x27;)
plt.grid()

# Logarithmic scale plot
plt.subplot(1, 2, 2)
plt.plot(x, y, color=&#x27;red&#x27;)
plt.yscale(&#x27;log&#x27;)
plt.title(&#x27;Logarithmic Scale (y-axis)&#x27;)
plt.xlabel(&#x27;x&#x27;)
plt.ylabel(&#x27;y (log scale)&#x27;)
plt.grid()

plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="Y9albJUf1APGhbiXyC8bO" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/55564c86d862f9866651a58ed72722e6.png" alt="&lt;Figure size 1200x500 with 2 Axes&gt;"/></div></div><div id="kFYGVBOyen" class="relative group/block"><p>What is important to know is that a 10 dB increase in SPL is generally perceived as about twice as loud by the human ear. This is because human hearing responds logarithmically: a 10 dB rise means the sound pressure increases by a factor of about 3.16, but our perception of loudness roughly doubles.</p><p>The <em>3 dB rule</em> states that if you add a second identical sound source, the SPL increases by about 3 dB, doubling the energy but only slightly increasing perceived loudness. For example, if a single speaker produces 70 dB SPL at a certain point, adding a second identical speaker playing the same signal at the same location will increase the SPL to approximately 73 dB. This is because the sound pressure doubles, resulting in a 3 dB increase, but the perceived loudness is only slightly greater, not doubled. Similarly, two 60 dB sound sources will have a combined SPL of 63 dB.</p><p>In addition, you need to know about the <em>Inverse-Square Law</em>, which states that when the distance from a sound source doubles, the sound pressure drops to one-fourth, resulting in a 6 dB reduction in SPL. This explains why sounds become much quieter as you move further away from the source.</p><img id="oLVMFkteQY" style="margin:0 auto" src="/sensingsoundandmusic/build/47adf533f5737acf99eccc4024a66adb.svg" alt="Inverse Square Law" data-canonical-url="https://upload.wikimedia.org/wikipedia/commons/d/da/Inverse_square_law_mk.svg" class=""/><p><em>Figure: Illustration of the Inverse-Square Law, showing how sound pressure decreases with distance (<a target="_blank" rel="noreferrer" href="https://commons.wikimedia.org/wiki/File:Inverse_square_law_mk.svg" class="">Wikipedia</a>).</em></p></div><div id="liqcy1ipZu" class="relative group/block"><h3 id="phase" class="relative group"><span class="heading-text">Phase</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#phase" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Describes the position of a point within a wave cycle, measured in degrees or radians. Phase differences between waves can lead to constructive or destructive interference.</p></div><div id="JvsbuwmBXD" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define the amplitude and frequency for the sine tones
x = np.linspace(0, 2 * np.pi, 100)
amplitude = 1
frequency = 1  # Frequency in Hz

# Define the phases for the three sine tones
phase1 = 0  # 0 radians
phase2 = np.pi / 4  # 45 degrees in radians
phase3 = np.pi / 2  # 90 degrees in radians

# Convert x to time in seconds
time_in_seconds = x / (2 * np.pi * frequency)

# Generate the sine tones
sine1 = amplitude * np.sin(2 * np.pi * frequency * time_in_seconds + phase1)
sine2 = amplitude * np.sin(2 * np.pi * frequency * time_in_seconds + phase2)
sine3 = amplitude * np.sin(2 * np.pi * frequency * time_in_seconds + phase3)

# Plot the sine tones
plt.figure(figsize=(12, 4))
plt.plot(time_in_seconds, sine1, label=&#x27;Phase = 0 rad&#x27;, alpha=0.8)
plt.plot(time_in_seconds, sine2, label=&#x27;Phase = π/4 rad&#x27;, alpha=0.8)
plt.plot(time_in_seconds, sine3, label=&#x27;Phase = π/2 rad&#x27;, alpha=0.8)
plt.title(&#x27;Sine Tones with Different Phases&#x27;)
plt.xlabel(&#x27;Time (s)&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="40GugnNPcxO1VPhxy1jp9" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/e6bbb0d0d68c268d5b39b9acca25854d.png" alt="&lt;Figure size 1200x400 with 1 Axes&gt;"/></div></div><div id="aPattVtKJD" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define amplitude and frequency for the sine tones
amplitude = 1
frequency = 1  # Frequency in Hz

# Use x from previous cells
# Define two sine tones with opposite phases (0 and pi)
sine1 = amplitude * np.sin(x)
sine2 = amplitude * np.sin(x + np.pi)  # 180 degrees out of phase

# Sum of the two sine tones
sum_wave = sine1 + sine2

# Plot the two sine tones and their sum
plt.figure(figsize=(12, 4))
plt.plot(x, sine1, label=&#x27;Sine Tone 1 (Phase = 0)&#x27;, alpha=0.8)
plt.plot(x, sine2, label=&#x27;Sine Tone 2 (Phase = π)&#x27;, alpha=0.8)
plt.plot(x, sum_wave, label=&#x27;Sum (Cancellation)&#x27;, color=&#x27;black&#x27;, linewidth=2)
plt.title(&#x27;Two Sine Tones Out of Phase (Cancellation)&#x27;)
plt.xlabel(&#x27;x&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="7Up17rkvANQDkL9MsX6ck" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/7c25ba7d860e2aceba7ef30c5752d6f8.png" alt="&lt;Figure size 1200x400 with 1 Axes&gt;"/></div></div><div id="dAyI4jkAUb" class="relative group/block"><aside id="phase-in-production" class="myst-exercise my-5 shadow dark:bg-stone-800 overflow-hidden dark:border-l-4 border-slate-400 dark:border-blue-500/60"><div class="myst-exercise-header m-0 font-medium py-2 flex min-w-0 text-md border-y dark:border-y-0 bg-blue-50/80 dark:bg-slate-900"><div class="myst-exercise-title text-neutral-900 dark:text-white grow self-center overflow-hidden break-words ml-4 group"><a class="no-underline text-inherit hover:text-inherit font-normal select-none hover:underline" href="#phase-in-production" title="Link to this Exercise" aria-label="Link to this Exercise">Exercise<!-- --> <!-- -->1</a></div></div><div class="myst-exercise-body px-4"><p>Have you tried swapping the phase in a music track? Try <a target="_blank" rel="noreferrer" href="https://l2ork.music.vt.edu:3000/?url=VTWaves/Phase-Cancellation-Emscripten.pd" class="">this phase cancellation</a> web experiment.</p></div></aside></div><div id="eTmC92f8gz" class="relative group/block"><h3 id="beating-waves" class="relative group"><span class="heading-text">Beating waves</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#beating-waves" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>When two sound waves of slightly different frequencies are played together, they interfere with each other. This interference causes the amplitude of the combined wave to fluctuate up and down in a regular pattern, called a <em>beat</em>. The <em><a href="https://en.wikipedia.org/wiki/Beat_(acoustics)" class="italic" target="_blank" rel="noreferrer" data-state="closed">beat frequency</a></em> is equal to the difference between the two original frequencies. For example, two tones with frequencies 440 Hz and 441 Hz will cause a beat frequency of 1 Hz. You hear this as the sound getting louder and softer at this beat frequency.</p><p>Mathematically, if you add two sine waves with close frequencies, the result is a wave whose amplitude varies slowly, creating the “beating” effect. This is commonly heard when tuning musical instruments or when two notes are almost, but not quite, in tune.</p></div><div id="U5LZAPprxI" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define parameters for the two sine waves
frequency1 = 5  # Frequency of the first wave in Hz
frequency2 = 5.5  # Frequency of the second wave in Hz
amplitude = 1  # Amplitude of the waves
time = np.linspace(0, 5, 1000)  # Time array from 0 to 5 seconds

# Generate the two sine waves
wave1 = amplitude * np.sin(2 * np.pi * frequency1 * time)
wave2 = amplitude * np.sin(2 * np.pi * frequency2 * time)

# Generate the resulting wave (superposition)
beating_wave = wave1 + wave2

# Plot the individual waves and the resulting wave
plt.figure(figsize=(12, 4))
plt.plot(time, wave1, label=&#x27;Wave 1&#x27;, alpha=0.7)
plt.plot(time, wave2, label=&#x27;Wave 2&#x27;, alpha=0.7)
plt.plot(time, beating_wave, label=&#x27;Beating Wave&#x27;, color=&#x27;black&#x27;, linewidth=2)
plt.title(&#x27;Beating Waves: Interference of Two Sine Waves&#x27;)
plt.xlabel(&#x27;Time (s)&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="ucT4UXXe8Z3ZUACrMJCdV" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/a15e2c0b0d715baaa6d5e9c237e7f78a.png" alt="&lt;Figure size 1200x400 with 1 Axes&gt;"/></div></div><div id="qFlFOCo4qe" class="relative group/block"><aside id="sine-tones" class="myst-exercise my-5 shadow dark:bg-stone-800 overflow-hidden dark:border-l-4 border-slate-400 dark:border-blue-500/60"><div class="myst-exercise-header m-0 font-medium py-2 flex min-w-0 text-md border-y dark:border-y-0 bg-blue-50/80 dark:bg-slate-900"><div class="myst-exercise-title text-neutral-900 dark:text-white grow self-center overflow-hidden break-words ml-4 group"><a class="no-underline text-inherit hover:text-inherit font-normal select-none hover:underline" href="#sine-tones" title="Link to this Exercise" aria-label="Link to this Exercise">Exercise<!-- --> <!-- -->2</a></div></div><div class="myst-exercise-body px-4"><p>Try out making sine tones in <a target="_blank" rel="noreferrer" href="https://glicol.org/tour#basicconnection" class="">Glicol</a>. Change the amplitude and frequency to hear how they are affecting what you hear. Try adding an extra sine tone with a different frequency create a beat frequency.</p></div></aside></div><div id="I3sO1iynnf" class="relative group/block"><h3 id="complex-waves" class="relative group"><span class="heading-text">Complex waves</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#complex-waves" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>A <em>complex wave</em> is a sound wave that consists of multiple frequencies combined together, rather than a single pure tone. Most sounds we hear in everyday life, such as musical notes, speech, or environmental noises, are complex waves.</p></div><div id="wrUYfTiFv3" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define parameters for the sine waves
x = np.linspace(0, 2 * np.pi, 1000)
wave1 = np.sin(x)  # First sine wave
wave2 = 0.5 * np.sin(2 * x)  # Second sine wave with half amplitude and double frequency
wave3 = 0.25 * np.sin(3 * x)  # Third sine wave with quarter amplitude and triple frequency

# Sum of the sine waves (complex wave)
complex_wave = wave1 + wave2 + wave3

# Plot the individual sine waves and the complex wave
plt.figure(figsize=(12, 4))
plt.plot(x, wave1, label=&#x27;Sine Wave 1: sin(x)&#x27;, alpha=0.7)
plt.plot(x, wave2, label=&#x27;Sine Wave 2: 0.5*sin(2x)&#x27;, alpha=0.7)
plt.plot(x, wave3, label=&#x27;Sine Wave 3: 0.25*sin(3x)&#x27;, alpha=0.7)
plt.plot(x, complex_wave, label=&#x27;Complex Wave: sum of sine waves&#x27;, color=&#x27;black&#x27;, linewidth=2)
plt.title(&#x27;Composition of a Complex Wave from Sine Waves&#x27;)
plt.xlabel(&#x27;x&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="OTifBhdBleIfQ2J09nweQ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/d11580658cfaf0bc51acf785aa8cd920.png" alt="&lt;Figure size 1200x400 with 1 Axes&gt;"/></div></div><div id="eC7MK05SJA" class="relative group/block"><h3 id="time-vs-frequency-domain" class="relative group"><span class="heading-text">Time vs Frequency Domain</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#time-vs-frequency-domain" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Sound can be represented visually in two fundamentally different ways:</p><ul><li><p><strong>Time domain</strong>: A “waveform display” shows how the amplitude of a signal (such as a sound wave) changes over time This view helps us understand the shape, duration, and dynamics of the signal.</p></li><li><p><strong>Frequency domain</strong>: A <em>spectrum</em> plot or <em>spectrogram</em> shows how much of the signal lies within each frequency band. The frequency domain representation is typically obtained using the Fourier transform. This view is useful for analyzing pitch, timbre, and spectral content.</p></li></ul><h3 id="the-fourier-transform" class="relative group"><span class="heading-text">The Fourier Transform</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#the-fourier-transform" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Any complex wave can be represented as the sum of simpler sinusoidal waves with different frequencies, amplitudes, and phases, a process called <em>Fourier analysis</em> (<a href="https://en.wikipedia.org/wiki/Fourier_analysis" class="italic" target="_blank" rel="noreferrer" data-state="closed">Wikipedia</a>). This technique was discovered by the French mathematician <a href="https://en.wikipedia.org/wiki/Joseph_Fourier" class="italic" target="_blank" rel="noreferrer" data-state="closed">Joseph Fourier</a> (1768–1830), laying the foundation for modern signal processing and harmonic analysis.</p><p>BelwThis decomposition is fundamental in acoustics, music technology, and audio engineering, as it allows us to analyze, synthesize, and manipulate sounds in both the time and frequency domains.</p></div><div id="Q0jgVcx8xh" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define parameters for the complex wave
frequency1 = 5  # Frequency of the first wave in Hz
frequency2 = 10  # Frequency of the second wave in Hz
frequency3 = 15  # Frequency of the third wave in Hz
amplitude1 = 1
amplitude2 = 0.5
amplitude3 = 0.25

# Generate the complex wave as a sum of three sine waves
wave1 = amplitude1 * np.sin(2 * np.pi * frequency1 * x)
wave2 = amplitude2 * np.sin(2 * np.pi * frequency2 * x)
wave3 = amplitude3 * np.sin(2 * np.pi * frequency3 * x)
complex_wave = wave1 + wave2 + wave3

# Compute the Fourier Transform of the complex wave
N = len(complex_wave)
T = (x[1] - x[0]) / (2 * np.pi)
frequencies = fftfreq(N, T)[:N // 2]
fft_values = fft(complex_wave)[:N // 2]

# Plot time domain, frequency domain, and spectrogram
plt.figure(figsize=(12, 9))

# Time domain plot
plt.subplot(3, 1, 1)
plt.plot(x, complex_wave, label=&#x27;Complex Wave (Time Domain)&#x27;, color=&#x27;blue&#x27;)
plt.title(&#x27;Waveform display (Time Domain)&#x27;)
plt.xlabel(&#x27;Time (s)&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()

# Frequency domain plot
plt.subplot(3, 1, 2)
plt.plot(frequencies, np.abs(fft_values), label=&#x27;Frequency Domain&#x27;, color=&#x27;red&#x27;)
plt.title(&#x27;Spectrum plot (Frequency Domain)&#x27;)
plt.xlabel(&#x27;Frequency (Hz)&#x27;)
plt.ylabel(&#x27;Magnitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()

# Spectrogram plot
plt.subplot(3, 1, 3)
plt.specgram(complex_wave, NFFT=256, Fs=1/(x[1]-x[0]), noverlap=128, cmap=&#x27;magma&#x27;)
plt.title(&#x27;Spectrogram (Frequency Domain)&#x27;)
plt.xlabel(&#x27;Time (s)&#x27;)
plt.ylabel(&#x27;Frequency (Hz)&#x27;)

plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="DB58bU2x-MX4xZqNfCiqh" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/ed08eb663ad30c5d691a417d5a00c18e.png" alt="&lt;Figure size 1200x900 with 3 Axes&gt;"/></div></div><div id="ieay7d62U5" class="relative group/block"><p>Note how the spectrum plot displays frequency on the X axis and magnitude on the Y axis, while the spectrogram shows time on the X axis and frequency on the Y axis. The spectrum provides an overview of the frequency content averaged over the entire signal. The spectrogram reveals how the frequency content changes over time, showing the temporal evolution.</p><p>To better visualize their relationship, you can plot the spectrum rotated 90 degrees, aligning its frequency axis with the spectrogram’s frequency axis. This highlights the difference: the spectrum summarizes the whole signal, while the spectrogram shows its development over time.</p></div><div id="CTHTd13Bzv" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, axes = plt.subplots(1, 2, figsize=(12, 6))

# Left: Spectrum turned 90 degrees
axes[0].plot(np.abs(fft_values), frequencies, color=&#x27;green&#x27;, linewidth=2)
axes[0].set_title(&#x27;Spectrum&#x27;)
axes[0].set_ylabel(&#x27;Frequency (Hz)&#x27;)
axes[0].set_xlabel(&#x27;Magnitude&#x27;)
axes[0].grid()

# Right: Spectrogram
axes[1].specgram(complex_wave, NFFT=256, Fs=1/(x[1]-x[0]), noverlap=128, cmap=&#x27;magma&#x27;)
axes[1].set_title(&#x27;Spectrogram&#x27;)
axes[1].set_xlabel(&#x27;Time (s)&#x27;)
axes[1].set_ylabel(&#x27;Frequency (Hz)&#x27;)

plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="Qxk5cMkZi7g4-x9RQa8Ny" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/f4aae7408bd2668eecb2bc2060c345b5.png" alt="&lt;Figure size 1200x600 with 2 Axes&gt;"/></div></div><div id="h559m5s4DK" class="relative group/block"><aside class="myst-admonition myst-admonition-note my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-blue-500"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-blue-600 bg-blue-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-blue-600"><path stroke-linecap="round" stroke-linejoin="round" d="m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Note</div></div><div class="myst-admonition-body px-4 py-1"><p>You may come across the term <em>sonogram</em> in the literature. It is essentially a spectrogram of sound signals. For sound and music, they are used interchangeably. However, spectrograms are more general, and can be used to decompose also other types of complex time-based signals.</p></div></aside></div><div id="BG9L3iETpX" class="relative group/block"><h3 id="noise" class="relative group"><span class="heading-text">Noise</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#noise" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Noise refers to random or unpredictable fluctuations in sound, often lacking a clear pitch or musical quality. In acoustics and audio engineering, different types of noise are characterized by their frequency content and how energy is distributed across the spectrum. Common types of noise include:</p><ul><li><p><strong>White noise</strong>: Contains all frequencies at equal intensity, resulting in a “hissing” sound similar to static from a radio or TV. It is often used for sound masking and audio testing because of its uniform frequency distribution.</p></li><li><p><strong>Pink noise</strong>: Has equal energy per octave, meaning its power decreases as frequency increases. This gives it a deeper sound, similar to rainfall or wind, and makes it useful for audio calibration and sleep aids.</p></li><li><p><strong>Brownian noise (Red noise)</strong>: Emphasizes even lower frequencies than pink noise, producing a deep rumble or distant thunder-like sound. It is generated by random walk processes and is sometimes called “red noise.”</p></li><li><p><strong>Blue noise</strong>: Contains more energy at higher frequencies, resulting in a brighter, sharper sound. Blue noise is rare in nature but is used in dithering applications in digital audio and image processing.</p></li><li><p><strong>Grey noise</strong>: Adjusted so that all frequencies are perceived as equally loud to the human ear, based on psychoacoustic principles. It is used in research and testing to account for human hearing sensitivity.</p></li></ul><p>The above noise types are “constant” in the sense that they have the same characteristics. One can also talk about different types of “impulse noise”, based on sudden, short bursts of sound, such as clicks, pops, or bangs. Impulse noise is common in environments with machinery, gunshots, or electrical discharges.</p><p>These noise types are used in audio testing, sound masking, electronic music, and various scientific applications. Understanding the characteristics of each type helps in designing systems for noise reduction, audio analysis, and environmental sound studies.</p></div><div id="LdnIt9ZnGs" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define parameters
sampling_rate = 1000  # Hz
duration = 2  # seconds
N = sampling_rate * duration
t = np.linspace(0, duration, N, endpoint=False)

# Generate noises
white_noise = np.random.normal(0, 1, N)

# Pink noise (approximate using Voss-McCartney algorithm)
def pink_noise(N):
    n_rows = 16
    n_cols = N
    array = np.random.randn(n_rows, n_cols)
    array = np.cumsum(array, axis=1)
    array = array / np.arange(1, n_cols + 1)
    return np.sum(array, axis=0)

pink_noise = pink_noise(N)

# Brownian noise (integrated white noise)
brownian_noise = np.cumsum(np.random.normal(0, 1, N))
brownian_noise /= np.max(np.abs(brownian_noise))

# Blue noise (differentiated white noise)
blue_noise = np.diff(white_noise, prepend=0)
blue_noise /= np.max(np.abs(blue_noise))

# Grey noise (white noise shaped by equal loudness curve, here just normalized white noise)
grey_noise = white_noise / np.max(np.abs(white_noise))

# Impulse noise (random sparse spikes)
impulse_noise = np.zeros(N)
impulse_indices = np.random.choice(N, size=int(N * 0.01), replace=False)
impulse_noise[impulse_indices] = np.random.choice([-1, 1], size=len(impulse_indices))

# List of noises
noises = [
    (&quot;White&quot;, white_noise),
    (&quot;Pink&quot;, pink_noise),
    (&quot;Brownian&quot;, brownian_noise),
    (&quot;Blue&quot;, blue_noise),
    (&quot;Grey&quot;, grey_noise),
    (&quot;Impulse&quot;, impulse_noise)
]

# Plot spectrograms
plt.figure(figsize=(12, 12))
for i, (name, noise) in enumerate(noises, 1):
    plt.subplot(6, 1, i)
    plt.specgram(noise, Fs=sampling_rate, NFFT=1024, noverlap=512, cmap=&#x27;magma&#x27;)
    plt.title(f&#x27;{name} Noise Spectrogram&#x27;)
    plt.ylabel(&#x27;Frequency (Hz)&#x27;)
    plt.xticks([])
    plt.yticks([])
plt.xlabel(&#x27;Time (s)&#x27;)
plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="sMYjgDr_XKNsu0Rc0SAJm" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/92af6899e9ae10fed5f36e17863d6498.png" alt="&lt;Figure size 1200x1200 with 6 Axes&gt;"/></div></div><div id="ejHUtZij7M" class="relative group/block"><aside id="make-spectrograms-in-sonic-visualiser" class="myst-exercise my-5 shadow dark:bg-stone-800 overflow-hidden dark:border-l-4 border-slate-400 dark:border-blue-500/60"><div class="myst-exercise-header m-0 font-medium py-2 flex min-w-0 text-md border-y dark:border-y-0 bg-blue-50/80 dark:bg-slate-900"><div class="myst-exercise-title text-neutral-900 dark:text-white grow self-center overflow-hidden break-words ml-4 group"><a class="no-underline text-inherit hover:text-inherit font-normal select-none hover:underline" href="#make-spectrograms-in-sonic-visualiser" title="Link to this Exercise" aria-label="Link to this Exercise">Exercise<!-- --> <!-- -->3</a></div></div><div class="myst-exercise-body px-4"><p>Download and install <a target="_blank" rel="noreferrer" href="https://www.sonicvisualiser.org/" class="">Sonic Visualiser</a>, a free tool for visualizing and analyzing audio files. Open a sound file (such as a recording or sample) and experiment with creating spectrograms:</p><ul><li><p>Load your audio file into Sonic Visualiser.</p></li><li><p>Add a new spectrogram layer (choose “Layer” → “Add Spectrogram”).</p></li><li><p>Adjust the spectrogram settings (window size, color map, etc.) to explore how they affect the visualization.</p></li><li><p>Try zooming in and out to examine different time and frequency regions.</p></li></ul><p>How does the spectrogram help you understand the frequency content and changes over time in your audio? Compare the visual patterns for different sounds (speech, music, noise).</p></div></aside></div><div id="IsPuyhpgDr" class="relative group/block"><h2 id="sound-propagation" class="relative group"><span class="heading-text">Sound propagation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#sound-propagation" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Sound propagation refers to how sound waves travel through different environments and interact with materials.</p><h3 id="medium-of-propagation" class="relative group"><span class="heading-text">Medium of Propagation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#medium-of-propagation" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Sound needs a medium, such as air, water, or solids, to travel. The particles in these media vibrate and transmit energy from one place to another. The speed and efficiency of sound propagation depend on the medium’s properties, especially density and elasticity. Generally, sound travels faster in materials that are more elastic and have closely packed particles.</p><p>Here are some examples of the <a href="https://en.wikipedia.org/wiki/Speed_of_sound" class="italic" target="_blank" rel="noreferrer" data-state="closed">speed of sound</a> in different media:</p><table class=""><tbody><tr class=""><th class="">Medium</th><th class="">Speed (m/s)</th></tr><tr class=""><td class="">Air</td><td class="">343</td></tr><tr class=""><td class="">Helium</td><td class="">965</td></tr><tr class=""><td class="">Water</td><td class="">1481</td></tr><tr class=""><td class="">Glass</td><td class="">4540</td></tr><tr class=""><td class="">Iron</td><td class="">5120</td></tr><tr class=""><td class="">Diamond</td><td class="">12000</td></tr></tbody></table><p>Sound moves fastest in solids (like iron or diamond) because their particles are tightly packed and transmit vibrations efficiently. For example, you can hear a distant train by placing your ear on the rail, as sound travels much faster through metal than air.</p><p>Temperature, humidity, and altitude also affect the speed of sound. Warmer air or higher humidity generally increases the speed, while higher altitude (lower air density) decreases it.</p></div><div id="kmZ5pEWyGg" class="relative group/block"><h3 id="reflection-refraction-diffraction-and-absorption" class="relative group"><span class="heading-text">Reflection, Refraction, Diffraction, and Absorption</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#reflection-refraction-diffraction-and-absorption" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>There are four physics concepts that are important for understanding the behavior of sound in general, but also in both rooms and instruments:</p><ul><li><p><strong>Reflection</strong>: Sound waves bounce off surfaces, creating echoes and affecting acoustics. In a concert hall, hard walls and ceilings reflect sound, producing reverberation and echoes. Inside a guitar, sound waves reflect off the wooden body, reinforcing certain frequencies and contributing to the instrument’s tone.</p></li><li><p><strong>Refraction</strong>: When sound moves between media (e.g., air to water), its speed changes, causing the wave to bend Temperature gradients in a room can cause sound waves to bend, affecting how sound travels from the stage to the audience. In wind instruments, sound waves refract as they move through air of varying temperature or humidity inside the instrument, subtly changing pitch and timbre.</p></li><li><p><strong>Diffraction</strong>: Sound waves bend around obstacles and spread out after passing through openings. Sound diffracts around furniture or pillars, allowing you to hear someone speaking even if they are not in direct line of sight. The sound from a violin’s f-holes diffracts, helping project the instrument’s sound in all directions.</p></li><li><p><strong>Absorption</strong>: Materials absorb sound energy, reducing its intensity. Carpets, curtains, and acoustic panels absorb sound, reducing echoes and making rooms quieter. The type of wood or material used in a drum absorbs some sound energy, affecting the instrument’s resonance and sustain.</p></li></ul><p>These principles shape how we experience sound in different environments, from open fields to concert halls, and influence the design and performance of musical instruments.</p><img id="eV9io1y3gN" style="margin:0 auto" src="/sensingsoundandmusic/build/2903c0d6cc4b18f749332d7134852c4d.jpeg" alt="reflection-refraction-copilot.jpg" data-canonical-url="data:image/jpeg;base64,iVBORw0KGg...lFTkSuQmCC" class=""/></div><div id="rj0cP6TcsD" class="relative group/block"><h2 id="room-acoustics" class="relative group"><span class="heading-text">Room Acoustics</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#room-acoustics" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Room acoustics explores how the physical characteristics of a space influence sound quality. The shape, size, and materials of a room affect how sound waves behave, impacting clarity, warmth, and reverberation.</p><h3 id="room-size-and-shape" class="relative group"><span class="heading-text">Room Size and Shape</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#room-size-and-shape" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The dimensions and geometry of a room determine how sound waves reflect, interact, and form standing waves. Irregular shapes and non-parallel surfaces help minimize unwanted echoes and resonances, while rectangular rooms with parallel walls are prone to standing waves, where certain frequencies are reinforced due to repeated reflections.</p><p><em>Standing waves</em> form when sound waves reflect between parallel surfaces and interfere with themselves, creating regions of constructive and destructive interference. This results in certain frequencies being amplified (peaks) and others being diminished (nulls) at specific locations in the room. Standing waves are most pronounced at low frequencies and can cause uneven bass response, making some notes sound much louder or softer depending on where you stand. Treating room modes with bass traps and careful placement of speakers/listeners helps minimize these effects.</p><p><em>Room modes</em> are the specific frequencies at which standing waves occur, determined by the room’s dimensions (length, width, height). Each mode corresponds to a resonance frequency where sound energy is reinforced. Modes are categorized as axial (between two parallel surfaces), tangential (between four surfaces), and oblique (between six surfaces). Calculating room modes helps identify problematic frequencies and guides acoustic treatment to achieve a balanced sound environment.</p><aside id="room-modes" class="myst-exercise my-5 shadow dark:bg-stone-800 overflow-hidden dark:border-l-4 border-slate-400 dark:border-blue-500/60"><div class="myst-exercise-header m-0 font-medium py-2 flex min-w-0 text-md border-y dark:border-y-0 bg-blue-50/80 dark:bg-slate-900"><div class="myst-exercise-title text-neutral-900 dark:text-white grow self-center overflow-hidden break-words ml-4 group"><a class="no-underline text-inherit hover:text-inherit font-normal select-none hover:underline" href="#room-modes" title="Link to this Exercise" aria-label="Link to this Exercise">Exercise<!-- --> <!-- -->4</a></div></div><div class="myst-exercise-body px-4"><p>Try a <a target="_blank" rel="noreferrer" href="https://amcoustics.com/tools/amroc?l=300&amp;w=500&amp;h=300&amp;r60=0.6" class="">Room Mode Calculator</a> to estimate the acoustic properties of a room.</p></div></aside><p>Some you may have experienced a particular acoustic phenomenon called <em>flutter echo</em>. This is the rapid, repetitive echoes that occur between hard, parallel surfaces (such as bare walls or ceilings). When a sound wave bounces back and forth between these surfaces, it creates a series of closely spaced echoes that can sound like a “ping-pong” effect or a metallic ringing. Flutter echo is especially noticeable in empty rooms or corridors and can degrade speech intelligibility and musical clarity. Acoustic panels or diffusers are often used to break up parallel surfaces and eliminate flutter echo.</p><p>In Oslo, we have an acoustic installation at one of the entrances of the National Theatre train station based on a spectacular flutter echo.</p><img id="LHBtQhcMbh" style="margin:0 auto" src="/sensingsoundandmusic/build/3b6b1a72c9c1f38f04e7445772621d9c.jpeg" alt="Nationaltheatret-jensenius.jpg" data-canonical-url="data:image/jpeg;base64,/9j/4AAQSk...42zz85/9k=" class=""/></div><div id="o1zbvRXJlV" class="relative group/block"><h3 id="materials" class="relative group"><span class="heading-text">Materials</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#materials" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Different construction materials play a crucial role in shaping the acoustic properties of a room:</p><ul><li><p><strong>Hard surfaces (glass, concrete, tile)</strong>: Reflect sound waves efficiently, leading to increased reverberation and potential echoes. These surfaces can make a space sound “live” or “bright,” but may also cause unwanted reflections and clarity issues.</p></li><li><p><strong>Soft materials (carpet, curtains, upholstered furniture, acoustic panels)</strong>: Absorb sound energy, especially at mid and high frequencies, reducing reverberation and minimizing echoes. These materials help create a “dry” or “warm” acoustic environment, improving speech intelligibility and musical detail.</p></li><li><p><strong>Porous materials (foam, mineral wool, fiberglass)</strong>: Highly effective at absorbing sound, particularly at higher frequencies. Used in acoustic panels and bass traps to control reflections and room modes.</p></li><li><p><strong>Dense materials (brick, stone, thick wood)</strong>: Reflect low-frequency sound waves and can help contain sound within a space, but may also contribute to standing waves and bass buildup.</p></li><li><p><strong>Diffusive surfaces (bookshelves, irregular walls, specialized diffusers)</strong>: Scatter sound waves in multiple directions, breaking up strong reflections and preventing flutter echoes. Diffusion improves clarity and creates a more balanced listening environment.</p></li><li><p><strong>Windows and doors</strong>: Can transmit sound between rooms, affecting isolation and privacy. Double glazing and solid-core doors help reduce sound transmission.</p></li></ul><p>The combination of these materials determine the overall acoustic character of a room.</p><h3 id="acoustic-treatment" class="relative group"><span class="heading-text">Acoustic Treatment</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#acoustic-treatment" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The shape, size, and construction of a room are difficult to change after it has</p><p>The above Effective acoustic treatment involves a combination of absorption, diffusion, and strategic placement of materials to optimize sound quality in a room:</p><ul><li><p><strong>Absorptive Panels</strong>: Typically made from foam, fiberglass, or mineral wool, these panels are mounted on walls or ceilings to absorb mid and high frequencies. They help reduce reflections, reverberation, and flutter echoes, making speech and music clearer.</p></li><li><p><strong>Bass Traps</strong>: Specialized absorbers placed in corners or along walls to target low-frequency energy. Bass traps help control room modes and prevent bass buildup, which can cause uneven sound and “boomy” bass.</p></li><li><p><strong>Diffusers</strong>: Unlike absorbers, diffusers scatter sound waves in multiple directions. They are often made from wood or plastic and have irregular surfaces or patterns. Diffusers break up strong reflections and standing waves, preserving a sense of spaciousness and natural ambience.</p></li><li><p><strong>Ceiling Clouds</strong>: Suspended panels above listening or performance areas absorb sound from above, reducing ceiling reflections and improving overall clarity.</p></li><li><p><strong>Furniture Arrangement</strong>: Placing bookshelves, couches, and other furnishings strategically can help break up sound reflections and add both absorption and diffusion. Soft furniture absorbs sound, while irregular surfaces diffuse it.</p></li><li><p><strong>Door and Window Seals</strong>: Adding seals or heavy curtains to doors and windows improves sound isolation, preventing unwanted noise from entering or leaving the room.</p></li><li><p><strong>Acoustic Curtains and Rugs</strong>: Thick curtains and rugs add absorption, especially in spaces with many hard surfaces, helping to tame excessive reverberation.</p></li></ul><p>A balanced approach using both absorption and diffusion creates a room that is neither too “dead” nor too “live,” supporting accurate sound reproduction and comfortable listening.</p><aside id="improving-room-acoustics" class="myst-exercise my-5 shadow dark:bg-stone-800 overflow-hidden dark:border-l-4 border-slate-400 dark:border-blue-500/60"><div class="myst-exercise-header m-0 font-medium py-2 flex min-w-0 text-md border-y dark:border-y-0 bg-blue-50/80 dark:bg-slate-900"><div class="myst-exercise-title text-neutral-900 dark:text-white grow self-center overflow-hidden break-words ml-4 group"><a class="no-underline text-inherit hover:text-inherit font-normal select-none hover:underline" href="#improving-room-acoustics" title="Link to this Exercise" aria-label="Link to this Exercise">Exercise<!-- --> <!-- -->5</a></div></div><div class="myst-exercise-body px-4"><p>Think about the acoustics of the room you are in. What are the key defining properties of the room? How can you improve it?</p></div></aside></div><div id="fxFOGjny2x" class="relative group/block"><h3 id="reverberation" class="relative group"><span class="heading-text">Reverberation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#reverberation" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p><em><a href="https://en.wikipedia.org/wiki/Reverberation" class="italic" target="_blank" rel="noreferrer" data-state="closed">Reverberation</a></em> is one of the most defining acoustic properties of a room. It can be defined as the persistence of sound in a space after the original sound source has stopped, caused by reflections from surfaces such as walls, ceilings, and floors.</p><p>Acousticians often calculate reverberation time based on the concept <em>T60</em>, which is defined as the time it takes for sound to decay by 60 dB after the source stops. The optimal reverberation time depends on the room’s purpose and the type of music or activity. Spaces designed for speech, such as lecture halls, benefit from shorter reverberation times, while concert halls for symphonic music often require longer reverberation for a fuller sound.</p><ul><li><p><strong>Short T60 (0.5–1 s)</strong>: Ideal for speech and clarity, minimizing echoes and enhancing intelligibility.</p></li><li><p><strong>Moderate T60 (1.5–2 s)</strong>: Suitable for chamber music, balancing clarity and warmth.</p></li><li><p><strong>Long T60 (2–3 s)</strong>: Preferred for orchestral and choral music, creating a rich and immersive sound.</p></li></ul><p>Understanding and controlling reverberation is essential for creating spaces with desirable acoustic properties, whether for recording studios, concert halls, or home listening rooms. Proper acoustic design ensures clarity, warmth, and an enjoyable listening experience.</p></div><div id="F1fORdidGm" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Simulate a simple exponential decay to illustrate T60 reverberation time
initial_amplitude = 1.0
t = np.linspace(0, 3, 1000)  # 3 seconds duration

# T60 is the time for amplitude to decay by 60 dB (factor of 1/1000)
T60 = 2.0  # seconds (example value)
decay_curve = initial_amplitude * np.exp(-t * np.log(1000) / T60)

plt.figure(figsize=(12, 4))
plt.plot(t, decay_curve, label=&#x27;Reverberation Decay&#x27;)
plt.axhline(initial_amplitude / 1000, color=&#x27;red&#x27;, linestyle=&#x27;--&#x27;, label=&#x27;-60 dB Level&#x27;)
plt.title(&#x27;Simulated Reverberation Decay (T60)&#x27;)
plt.xlabel(&#x27;Time (s)&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.legend()
plt.grid()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="f5QqUueG2BTyn2KwUlfWQ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/5ce7e94e55507f22f16555ebc448eea3.png" alt="&lt;Figure size 1200x400 with 1 Axes&gt;"/></div></div><div id="k1cP4llxp4" class="relative group/block"><h2 id="instrument-acoustics" class="relative group"><span class="heading-text">Instrument acoustics</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#instrument-acoustics" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Room acoustics is a big field of study and there are numerous jobs for people working with both constructing and modifying rooms in buildings. There are much fewer people focusing on instrument acoustics. While the scale is smaller, most of the same principles apply to instruments, investigating how musical instruments generate, shape, and radiate sound.</p><h3 id="principles-of-instrument-acoustics" class="relative group"><span class="heading-text">Principles of instrument acoustics</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#principles-of-instrument-acoustics" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The main physical principles of instrument acoustics include the <em>vibration source</em> and the instrument’s <em>resonance</em> The initial sound is produced by vibrating elements such as strings (guitar, violin), air columns (flute, trumpet), membranes (drum), or solid bodies (xylophone). Most instruments have resonating bodies (soundboards, tubes, shells) that amplify and color the sound. The shape, size, and material of these bodies determine the instrument’s timbre and loudness.</p><p>The vibration source heavily influences the <em>frequency range</em> of the instrument. Each instrument has a characteristic range of frequencies it can produce, determined by its physical dimensions and construction.</p><img id="YlblbRjt93" style="margin:0 auto" src="/sensingsoundandmusic/build/ed1ed0d73a498645bbe0ac5d074b8ceb.jpeg" alt="Fundamentals of Instrument Acoustics" data-canonical-url="http://www.sebastianmerchel.de/Projects/Tactile%20Touchscreen/Pictures/fundamentels_instruments_big.jpg" class=""/><p><em>Figure: Fundamentals of Instrument Acoustics (<a target="_blank" rel="noreferrer" href="http://www.sebastianmerchel.de/" class="">Credit: Sebastian Merchel</a>).</em></p><p>The resonance in the instrument is important for its <em>timbre</em> based on its partials and overtones. Instruments rarely produce pure tones; instead, they generate complex waves with multiple harmonics. The relative strength of these harmonics defines the instrument’s unique sound.</p><p>An instrument’s <em>radiation pattern</em> is based on the way sound is projected into the surrounding space depends on the instrument’s geometry and playing technique.</p><div class="myst-grid grid my-5 grid-cols-1 md:grid-cols-1 lg:grid-cols-2 xl:grid-cols-3 gap-4"><div class="myst-card my-5 rounded shadow dark:shadow-neutral-800 overflow-hidden border border-gray-100 dark:border-gray-800 flex flex-col"><header class="myst-card-header py-1 pl-3 m-0 border-b border-gray-100 bg-gray-50 dark:bg-slate-900 dark:border-gray-800"><p>String instruments</p></header><div class="myst-card-body flex-grow px-4 py-2"><p>When a string is plucked or bowed, it vibrates at its fundamental frequency and produces harmonics. The body of the instrument (such as a guitar or violin) amplifies these vibrations and shapes the sound. The material and construction of the body affect the instrument’s tone and projection.</p></div></div><div class="myst-card my-5 rounded shadow dark:shadow-neutral-800 overflow-hidden border border-gray-100 dark:border-gray-800 flex flex-col"><header class="myst-card-header py-1 pl-3 m-0 border-b border-gray-100 bg-gray-50 dark:bg-slate-900 dark:border-gray-800"><p>Wind instruments</p></header><div class="myst-card-body flex-grow px-4 py-2"><p>Wind instruments produce sound by vibrating air columns. The length, shape, and material of the tube determine the pitch and timbre. Opening and closing holes changes the effective length of the air column, allowing different notes to be played.</p></div></div><div class="myst-card my-5 rounded shadow dark:shadow-neutral-800 overflow-hidden border border-gray-100 dark:border-gray-800 flex flex-col"><header class="myst-card-header py-1 pl-3 m-0 border-b border-gray-100 bg-gray-50 dark:bg-slate-900 dark:border-gray-800"><p>Percussion instruments</p></header><div class="myst-card-body flex-grow px-4 py-2"><p>Percussion instruments generate sound through striking, shaking, or scraping. The vibration of membranes (drums) or solid bodies (bells, xylophones) creates complex waveforms. The size, tension, and material of the vibrating surface influence the pitch and timbre.</p></div></div></div><h3 id="organology" class="relative group"><span class="heading-text">Organology</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#organology" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>In addition to acousticians, there is an academic field focused on the study of musical instruments: <em><a href="https://en.wikipedia.org/wiki/Organology" class="italic" target="_blank" rel="noreferrer" data-state="closed">organology</a></em>. This was developed by (ethno)musicologists and researchers working in instrument museums in the late 19th and early 20th century, based on the need to organize large collections of instruments.</p><p>The most famous organological system is the <a href="https://en.wikipedia.org/wiki/Hornbostel%E2%80%93Sachs" class="italic" target="_blank" rel="noreferrer" data-state="closed">Hornbostel–Sachs System</a>, which classifies instruments based on how they produce sound. The main categories are:</p><ul><li><p><strong>Idiophones</strong>: Instruments that produce sound primarily by the vibration of their own material, without strings, membranes, or external air columns. Examples include xylophones, cymbals, and bells.</p></li><li><p><strong>Membranophones</strong>: Instruments that produce sound by vibrating a stretched membrane. Drums are the most common example, where the membrane is struck, rubbed, or otherwise excited.</p></li><li><p><strong>Chordophones</strong>: Instruments that produce sound by vibrating strings stretched between fixed points. This group includes violins, guitars, harps, and pianos.</p></li><li><p><strong>Aerophones</strong>: Instruments that produce sound by vibrating columns of air. Examples are flutes, trumpets, saxophones, and pipe organs.</p></li><li><p><strong>Electrophones</strong>: Instruments that produce sound primarily through electrical means. This includes synthesizers, electric guitars (when amplified), and theremins.</p></li></ul><p>Each category can be further subdivided based on how the sound is initiated (struck, plucked, bowed, blown, etc.), the construction of the instrument, and its acoustic properties. Although not entirely similar,  Disney made an interesting animation film called <em>Toot Whistle Plunk and Boom</em> in 1953 that shows differences between instruments:</p><div style="text-align:center" class="leading-[0]"><div class="relative inline-block" style="padding-bottom:60%;width:min(max(100%, 500px), 100%)"><iframe width="100%" height="100%" src="https://www.youtube.com/embed/8iVf0pPHvjc?si=Q7N2xX4m8J1x2ZEL" allowfullscreen="" allow="autoplay" style="width:100%;height:100%;position:absolute;top:0;left:0;border:none"></iframe></div></div></div><div id="yTSxKTPCUD" class="relative group/block"><h2 id="electro-acoustics" class="relative group"><span class="heading-text">Electro-Acoustics</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#electro-acoustics" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Electro-Acoustics&quot; refers to the field of study and technology that deals with the conversion between electrical signals and sound waves. It encompasses the design, analysis, and application of devices that perform this conversion, such as microphones, loudspeakers, headphones, and hearing aids. This field combines principles from acoustics (the science of sound) and electronics to create systems that enable sound recording, reproduction, and transmission.</p></div><div id="Av7ClpkT9G" class="relative group/block"><h3 id="microphones" class="relative group"><span class="heading-text">Microphones</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#microphones" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Microphones are devices that convert sound waves into electrical signals. They are categorized by their design and working principles. The three main types are:</p><ul><li><p><strong><a href="https://en.wikipedia.org/wiki/Microphone#Dynamic" class="italic" target="_blank" rel="noreferrer" data-state="closed">Dynamic microphones</a></strong> use a diaphragm attached to a coil of wire, which is placed within a magnetic field. When sound waves hit the diaphragm, it moves the coil, generating an electrical signal through electromagnetic induction. These microphones are known for their durability and ability to handle high sound pressure levels, making them ideal for live performances and situations where robustness is required.</p></li><li><p><strong><a href="https://en.wikipedia.org/wiki/Microphone#Condenser" class="italic" target="_blank" rel="noreferrer" data-state="closed">Condenser microphones</a></strong> operate using a diaphragm positioned close to a charged backplate, together forming a capacitor. Sound waves cause the diaphragm to move, changing the distance between the diaphragm and backplate, which alters the capacitance and produces an electrical signal. This design makes condenser microphones highly sensitive and capable of capturing subtle details, making them well-suited for studio recordings and applications requiring high fidelity.</p></li><li><p><strong><a href="https://en.wikipedia.org/wiki/Contact_microphone" class="italic" target="_blank" rel="noreferrer" data-state="closed">Contact microphones</a></strong> detect vibrations directly from solid surfaces rather than from the air. They often use piezoelectric materials to convert these vibrations into electrical signals. This type of microphone is commonly used for amplifying acoustic instruments such as violins or guitars, as it can pick up the vibrations from the instrument’s body, providing a unique perspective on the sound.</p></li></ul><p>In her exploreation of microphones as instruments, Cathy van Eck calls microphones for “softhearers” as a parallel to loudspeakers.</p></div><div id="N0biEj2D9T" class="relative group/block"><h3 id="loudspeakers" class="relative group"><span class="heading-text">Loudspeakers</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#loudspeakers" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Loudspeakers (or perhaps only speakers) are devices that convert electrical signals into sound waves. They come in various types based on their application and design:</p><ul><li><p><strong>Standard Speakers</strong> are used in audio systems for general sound reproduction. They employ a diaphragm (cone) driven by an electromagnet to produce sound and are designed to cover a wide range of frequencies, making them suitable for most listening environments.</p></li><li><p><strong>Headphones</strong> are miniature speakers worn on, around, or in the ears. All headphones feature passive noise cancelling by design (since they cover the ears), but there are also different types of active noise cancelling.</p></li><li><p><strong>Actuators</strong> are devices that create vibrations, typically in solid objects. The vibrations are typically not audible by itself, it is the resonances in the objects excited by the actuator that produces the sound. They are used in haptic feedback systems or to turn surfaces, such as tables or windows, into speakers. They are also used in <a href="https://en.wikipedia.org/wiki/Bone_conduction" class="italic" target="_blank" rel="noreferrer" data-state="closed">bone-conducting headsets</a>.</p></li></ul><aside class="myst-admonition myst-admonition-note my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-blue-500"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-blue-600 bg-blue-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-blue-600"><path stroke-linecap="round" stroke-linejoin="round" d="m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Note</div></div><div class="myst-admonition-body px-4 py-1"><p>Did you know that <a href="https://en.wikipedia.org/wiki/Active_noise_control" class="italic" target="_blank" rel="noreferrer" data-state="closed">active noise cancelling</a> is based on inverting the phase of the sound signal?</p><img id="Umg5MnFy7E" style="margin:0 auto" src="/sensingsoundandmusic/build/3bcbe4c974c9ecb83317cb191118e8af.svg" alt="Noise cancelling" data-canonical-url="https://upload.wikimedia.org/wikipedia/commons/7/7d/Active_Noise_Reduction.svg" class=""/></div></aside></div><div id="Tjr5iBzZl3" class="relative group/block"><h3 id="signal-processing" class="relative group"><span class="heading-text">Signal processing</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#signal-processing" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Signal processing is the field concerned with analyzing, modifying, and synthesizing signals such as sound, images, and scientific measurements. In acoustics and audio engineering, signal processing is essential for improving sound quality, extracting information, and adapting audio for specific applications.</p><p>Signal processing can be done in both the analog and digital domain. Key aspects of signal processing in audio include:</p><ul><li><p><strong>Amplification</strong>: Increasing the strength of electrical signals so they can drive loudspeakers or be recorded at usable levels.</p></li><li><p><strong>Filtering</strong>: Removing unwanted frequencies (such as noise or hum) or enhancing desired frequency ranges. Filters can be low-pass, high-pass, band-pass, or notch filters, each serving different purposes.</p></li><li><p><strong>Equalization (EQ)</strong>: Adjusting the balance between frequency components to shape the tonal quality of audio signals.</p></li><li><p><strong>Dynamic Range Compression</strong>: Reducing the difference between the loudest and quietest parts of a signal to make audio more consistent and prevent distortion.</p></li><li><p><strong>Noise Reduction</strong>: Techniques such as gating, spectral subtraction, or adaptive filtering to minimize background noise.</p></li><li><p><strong>Effects Processing</strong>: Adding reverberation, delay, chorus, distortion, or other effects to enhance or creatively alter the sound.</p></li><li><p><strong>Modulation</strong>: Changing aspects of the signal such as amplitude, frequency, or phase for transmission or synthesis.</p></li></ul><p>Signal processing is used in microphones, mixing consoles, audio interfaces, hearing aids, mobile devices, and music production software. It enables clear communication, high-fidelity music reproduction, and creative sound design. In the following, we will briefly look into digital sound.</p></div><div id="p70yGu06I3" class="relative group/block"><h2 id="digital-audio" class="relative group"><span class="heading-text">Digital audio</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#digital-audio" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Digital audio is a huge field, so here we will only be able to scratch the surface.</p><h3 id="sound-vs-audio" class="relative group"><span class="heading-text">Sound vs audio</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#sound-vs-audio" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>It is important to understand the difference between <em>sound</em> and <em>audio</em>. Sound refers to vibrations traveling through materials, while audio is the technology or electrical representation used to capture, store, and reproduce those vibrations. Audio can exist in both analog and digital forms, such as LPs, cassettes, or digital files, and serves as the intermediary between devices like microphones and speakers. The distinction is similar to that between light (a physical phenomenon) and video (its recorded representation).</p><h3 id="digitization" class="relative group"><span class="heading-text">Digitization</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#digitization" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p><em>Digitization</em> is the process of converting physical sound to digital audio signals using an <a href="https://en.wikipedia.org/wiki/Analog-to-digital_converter" class="italic" target="_blank" rel="noreferrer" data-state="closed">Analog-to-Digital Converter</a> (ADC). This involves two main steps: <em>sampling</em> and <em>quantization</em>.</p><p>First, the continuous sound wave is measured at regular intervals (samples per second), known as the <em>sampling rate</em> (SR). Next, each sampled value is rounded to the nearest value that can be represented by a fixed number of bits (the <em>bit depth</em>). Higher bit depths allow for more precise representation of amplitude, resulting in higher audio quality and lower quantization noise. The result is a stream of numbers that can be stored, processed, and transmitted by computers and digital devices.</p><p>Below is a visualization of how a continuous sound wave (such as a sine wave or white noise) is sampled and quantized. The blue curve represents the original continuous wave. The red dots show the sampled points at a specific sampling rate. Quantization further rounds these sampled values to discrete levels, determined by the bit depth.</p></div><div id="SYF4YkbVEl" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define parameters for the sine wave
frequency = 1  # Frequency in Hz
amplitude = 1  # Amplitude of the sine wave
sampling_rates = [5, 10, 20, 50]  # Different sampling rates in Hz

# Generate the continuous sine wave
continuous_wave = amplitude * np.sin(2 * np.pi * frequency * x)

# Create the figure
plt.figure(figsize=(12, 2))

# Plot the continuous sine wave
plt.plot(x, continuous_wave, label=&#x27;Continuous Sine Wave&#x27;, color=&#x27;blue&#x27;, alpha=0.7)

# Plot sampled points for each sampling rate
for i, rate in enumerate(sampling_rates):
    sampled_x = np.linspace(0, 2 * np.pi, rate, endpoint=False)
    sampled_wave = amplitude * np.sin(2 * np.pi * frequency * sampled_x)
    plt.scatter(sampled_x, sampled_wave, label=f&#x27;Sampled Points (Rate = {rate} Hz)&#x27;, zorder=5)

plt.title(&#x27;Effect of Different Sampling Rates on a Sine Tone&#x27;)
plt.xlabel(&#x27;x&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="7FKXlks_BsWyOnsZWSnsP" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/6394021662f952dbbcb87b55067e4c16.png" alt="&lt;Figure size 1200x200 with 1 Axes&gt;"/></div></div><div id="QHGJgnEvTo" class="relative group/block"><h3 id="sampling-rate" class="relative group"><span class="heading-text">Sampling rate</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#sampling-rate" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The sampling rate is the number of samples per second taken from a continuous signal to create a discrete signal. According to the <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem" class="italic" target="_blank" rel="noreferrer" data-state="closed">Nyquist–Shannon sampling theorem</a>, the sampling rate must be at least twice the highest frequency present in the signal to accurately reconstruct it. This minimum rate is known as the <a href="https://en.wikipedia.org/wiki/Nyquist_frequency" class="italic" target="_blank" rel="noreferrer" data-state="closed">Nyquist Frequency</a>. When the CD was introduced, it was decided that it should have a sampling rate of 44,100 Hz, which can capture frequencies up to 22,050 Hz. As we shall see next week, this is sufficient to cover all humanly audible sounds.</p><p>Nowadays, it is often common to have much higher sampling rates, such as 96 kHz and 192 kHz. This is far beyond human hearing, but there are several benefits in audio processing:</p><ul><li><p><strong>Extended Frequency Response</strong>: While humans cannot hear frequencies above ~20 kHz, higher sampling rates allow for accurate recording and reproduction of ultrasonic content, which can affect the audible range through nonlinear processing or analog equipment.</p></li><li><p><strong>Reduced Aliasing</strong>: Aliasing is distortion caused when high-frequency signals are misrepresented as lower frequencies. Higher sampling rates push the aliasing artifacts further above the audible range, making them easier to filter out.</p></li><li><p><strong>Improved Phase Accuracy</strong>: Digital filters and processing algorithms can operate with greater precision at higher sampling rates, resulting in more accurate phase response and less pre-ringing or artifacts.</p></li><li><p><strong>Better Headroom for Processing</strong>: Audio editing, mixing, and effects (such as pitch shifting or time stretching) can be performed with fewer artifacts and greater fidelity at higher sampling rates.</p></li><li><p><strong>Archival and Mastering Quality</strong>: Recording at higher rates preserves more information for future remastering or conversion to other formats, ensuring the highest possible quality.</p></li></ul><p>However, higher sampling rates also result in larger file sizes and increased CPU usage, so they are typically used in professional recording, mixing, and mastering environments rather than for consumer playback.</p></div><div id="PvmbAI7bsv" class="relative group/block"><h3 id="bit-depth" class="relative group"><span class="heading-text">Bit depth</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#bit-depth" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The <a href="https://en.wikipedia.org/wiki/Audio_bit_depth" class="italic" target="_blank" rel="noreferrer" data-state="closed">audio bit depth</a> is the amount of data used to represent each individual sample in a digital audio signal. Bit depth determines the “resolution” or precision of the amplitude values that can be stored. Higher bit depths allow for more accurate representation of the original sound, resulting in lower quantization noise and a greater dynamic range.</p><ul><li><p><strong>Low bit depth (e.g., 8-bit)</strong>: Only a small number of amplitude levels are available, which can introduce audible distortion and noise, especially in quiet passages.</p></li><li><p><strong>Medium bit depth (e.g., 16-bit)</strong>: CD-quality audio uses 16 bits per sample, allowing for 65,536 possible amplitude values.</p></li><li><p><strong>High bit depth (e.g., 24-bit)</strong>: Professional audio recordings nowadays often use 24 bits per sample, providing over 16 million possible values and a wider dynamic range. Many more amplitude levels are available, resulting in smoother, more natural sound and the ability to capture subtle details.</p></li></ul><p>Quite recently, there are 32-bit recorders available, offering an extremely high dynamic range, far beyond what human hearing or traditional analog equipment can capture. With 32-bit float, you can record both very quiet and extremely loud sounds without worrying about clipping (distortion from signals being too loud) or noise floor issues (signals being too quiet). This means you can adjust levels after recording without losing audio quality, making it nearly impossible to ruin a recording due to incorrect gain settings. While most playback systems and final mixes use 24-bit or 16-bit audio, 32-bit float is a powerful tool for capturing and processing audio with maximum flexibility and safety during production.</p><p>The effect of bit depth can be visualized by quantizing a waveform at different bit depths. Lower bit depths produce a “stepped” appearance and more distortion, while higher bit depths closely follow the original waveform.</p></div><div id="DUtruTBaWn" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><details class="myst-dropdown rounded-md my-5 shadow dark:shadow-2xl dark:shadow-neutral-900 overflow-hidden bg-gray-50 dark:bg-stone-800"><summary class="myst-dropdown-header m-0 text-lg font-medium py-1 min-h-[2em] pl-3 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03] bg-gray-100 dark:bg-slate-900"><span class="myst-dropdown-header-title text-neutral-900 dark:text-white"><span class="block float-right text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-dropdown-header-icon inline-block pl-2 mr-2 -translate-y-[1px] details-toggle transition-transform"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></span>Source</span></summary><div class="myst-dropdown-body px-4 py-1 details-body"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define parameters for the sine wave
frequency = 1  # Frequency in Hz
amplitude = 1  # Amplitude of the sine wave
sampling_rate = 50  # Sampling rate in Hz (samples per second)

# Generate the continuous sine wave
continuous_wave = amplitude * np.sin(2 * np.pi * frequency * x)

# Generate the sampled points
sampled_x = np.linspace(0, 2 * np.pi, sampling_rate, endpoint=False)
sampled_wave = amplitude * np.sin(2 * np.pi * frequency * sampled_x)

# Quantize the sampled wave at different bit depths
bit_depths = [2, 4, 8]  # Bit depths to demonstrate
quantized_waves = [np.round(sampled_wave * (2**(b-1) - 1)) / (2**(b-1) - 1) for b in bit_depths]

# Plot the continuous wave, sampled points, and quantized waves
plt.figure(figsize=(12, 2))

# Plot the continuous sine wave
plt.plot(x, continuous_wave, label=&#x27;Continuous Sine Wave&#x27;, color=&#x27;blue&#x27;, alpha=0.7)

# Plot the sampled points
plt.scatter(sampled_x, sampled_wave, color=&#x27;red&#x27;, label=&#x27;Sampled Points&#x27;, zorder=5)

# Plot quantized waves
for i, b in enumerate(bit_depths):
    plt.step(sampled_x, quantized_waves[i], where=&#x27;mid&#x27;, label=f&#x27;Quantized ({b}-bit)&#x27;, alpha=0.8)

plt.title(&#x27;Effect of Bit Depth on Sine Wave Quantization&#x27;)
plt.xlabel(&#x27;x&#x27;)
plt.ylabel(&#x27;Amplitude&#x27;)
plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5, linestyle=&#x27;--&#x27;)
plt.legend()
plt.grid()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div></details><div data-mdast-node-id="xx0AluK_F-FlL9GhN4KsX" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/sensingsoundandmusic/build/bf3a5b9fed5be82718e50630400e5ebf.png" alt="&lt;Figure size 1200x200 with 1 Axes&gt;"/></div></div><div id="BtYzoqSsNj" class="relative group/block"><h3 id="audio-compression-and-file-formats" class="relative group"><span class="heading-text">Audio Compression and File Formats</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#audio-compression-and-file-formats" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The final topic in today’s class is audio file formats and compression, essential for storing, sharing, and streaming digital sound.</p><p>Audio <em>containers</em> are file formats that store digital audio data along with metadata (such as track info, album art, and artist details). Common containers include <a href="https://en.wikipedia.org/wiki/WAV" class="italic" target="_blank" rel="noreferrer" data-state="closed">WAV</a> (Windows) and <a href="https://en.wikipedia.org/wiki/Audio_Interchange_File_Format" class="italic" target="_blank" rel="noreferrer" data-state="closed">AIFF</a> (Apple), which both offer uncompressed, high-quality audio.</p><p>Several container types, e.g. <a href="https://en.wikipedia.org/wiki/Matroska" class="italic" target="_blank" rel="noreferrer" data-state="closed">MKV</a>, can contain raw (uncompressed) and/or compressed audio data alongside video and metadata. Others, like <a href="https://en.wikipedia.org/wiki/MPEG-4_Part_14" class="italic" target="_blank" rel="noreferrer" data-state="closed">MP4</a>, store compressed audio, often in combination with video.</p><p>It is important to note that the container used for storing the file is (often) independent from the audio <em>compression</em> used. Note that audio file compression is not the same as the dynamics compression often used to improve the balance in recordings. Audio file compression is based on reducing the file size of digital audio, making it easier to store and transmit. There are two main types:</p><ul><li><p><strong>Lossless compression</strong>: Preserves all original audio data, allowing perfect reconstruction, such as <a href="https://en.wikipedia.org/wiki/FLAC" class="italic" target="_blank" rel="noreferrer" data-state="closed">FLAC</a> and <a href="https://en.wikipedia.org/wiki/Apple_Lossless" class="italic" target="_blank" rel="noreferrer" data-state="closed">ALAC</a>.</p></li><li><p><strong>Lossy compression</strong>: Removes some audio data, typically those less perceptible to human hearing, to achieve smaller file sizes, such as <a href="https://en.wikipedia.org/wiki/MP3" class="italic" target="_blank" rel="noreferrer" data-state="closed">MP3</a> and <a href="https://en.wikipedia.org/wiki/Advanced_Audio_Coding" class="italic" target="_blank" rel="noreferrer" data-state="closed">AAC</a>. Here is a quick overview of what to use:</p></li></ul><table class=""><tbody><tr class=""><th class="">Format</th><th class="">Compression Type</th><th class="">Typical Use</th><th class="">Quality</th></tr><tr class=""><td class="">WAV, AIFF</td><td class="">None</td><td class="">Recording, editing</td><td class="">Excellent</td></tr><tr class=""><td class="">FLAC</td><td class="">Lossless</td><td class="">Archiving, hi-fi</td><td class="">Excellent</td></tr><tr class=""><td class="">AAC</td><td class="">Lossy</td><td class="">Streaming</td><td class="">Good</td></tr></tbody></table><p>While MP3 files can provide good quality, AAC compression generally produces smaller file size and are therefore preferred. For those concerned about using open formats, such as the <a href="https://en.wikipedia.org/wiki/Ogg" class="italic" target="_blank" rel="noreferrer" data-state="closed">Ogg container</a> and related compression formats.</p><aside id="audio-compression" class="myst-exercise my-5 shadow dark:bg-stone-800 overflow-hidden dark:border-l-4 border-slate-400 dark:border-blue-500/60"><div class="myst-exercise-header m-0 font-medium py-2 flex min-w-0 text-md border-y dark:border-y-0 bg-blue-50/80 dark:bg-slate-900"><div class="myst-exercise-title text-neutral-900 dark:text-white grow self-center overflow-hidden break-words ml-4 group"><a class="no-underline text-inherit hover:text-inherit font-normal select-none hover:underline" href="#audio-compression" title="Link to this Exercise" aria-label="Link to this Exercise">Exercise<!-- --> <!-- -->6</a></div></div><div class="myst-exercise-body px-4"><p>Try to store an uncompressed audio file in a highly compressed format (MP3 or AAC). Listen to how it degrades.</p></div></aside></div><div id="kJuOp2qVBk" class="relative group/block"><h2 id="questions" class="relative group"><span class="heading-text">Questions</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#questions" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ol start="1"><li><p>What is the difference between longitudinal and transverse waves, and how do these wave types relate to the propagation of sound in different media?</p></li><li><p>Explain the concepts of frequency, amplitude, and phase in sound waves. How do changes in each property affect the perception of sound?</p></li><li><p>Describe the role of room acoustics in shaping sound quality. What are standing waves, room modes, and flutter echo, and how can acoustic treatment improve a room’s acoustics?</p></li><li><p>Compare and contrast the main categories of musical instruments in the Hornbostel–Sachs system. How does each category produce sound, and what are some examples?</p></li><li><p>What is the process of digitizing sound, and how do sampling rate and bit depth influence the quality of digital audio?</p></li></ol></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/sensingsoundandmusic/week2"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Sensing Sound and Music</div>Week 2: Listening</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/sensingsoundandmusic/week4"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Sensing Sound and Music</div>Week 4: Psychoacoustics</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/sensingsoundandmusic/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-JSE36H2O.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-C7FW3E47.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-ND43KHSX.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/root-IB5726YR.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/_shared/chunk-NBON2RSI.js"/><link rel="modulepreload" href="/sensingsoundandmusic/build/routes/$-LXLHKVOR.js"/><script>window.__remixContext = {"url":"/week3","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.1","options":{"favicon":"/sensingsoundandmusic/build/favicon-2720eef16358a9679c7ec109a6d05906.ico"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"exports":[],"title":"Sensing Sound and Music","description":"An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives.","authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"id":"11cc8b5a-b0a2-4516-8397-a7dbad782f82","toc":[{"file":"intro.md"},{"file":"week1.md"},{"file":"week2.md"},{"file":"week3.ipynb"},{"file":"week4.ipynb"},{"file":"week5.md"},{"file":"week6.ipynb"},{"file":"week7.md"},{"file":"week8.md"},{"file":"week9.md"},{"file":"week10.md"},{"file":"week11.md"}],"bibliography":[],"index":"index","pages":[{"slug":"week1","title":"Week 1: Tuning in","description":"This page introduces the foundational concepts of music psychology and technology, exploring how humans perceive, experience, and create sound and music through both psychological and technological perspectives.","date":"","thumbnail":"/sensingsoundandmusic/build/c20d5f224f701120b83307814eab6564.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week2","title":"Week 2: Listening","description":"This chapter explores the art and science of listening, focusing on how sounds and soundscapes are described, understood, and analyzed across disciplines. It introduces influential theories and thinkers, practical listening exercises, and tools for engaging with the sonic environment.","date":"","thumbnail":"/sensingsoundandmusic/build/impulsive-sustained--c0c48158496bcc681fba65df66fa6f2f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week3","title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","date":"","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week4","title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacoustics—the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","date":"","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week5","title":"Week 5: Time and Rhythm","description":"This chapter explores the foundations of musical time and rhythm, covering concepts such as onset timing, perceptual centers, meter, microrhythm, groove, and entrainment. It examines how rhythm is structured, perceived, and performed, highlighting the roles of technology and analysis tools in understanding the nuances of timing and groove in various musical styles.","date":"","thumbnail":"/sensingsoundandmusic/build/week5_image6-42ef9fdd71a421c1baf682d65217062b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week6","title":"Week 6: Harmony and melody","description":"This notebook explores the concepts of harmony, melody, and musical structure through both theoretical explanations and practical visualizations. It covers fundamental audio representations, symbolic music formats, and provides code examples for analyzing and visualizing musical elements using Python.","date":"","thumbnail":"/sensingsoundandmusic/build/week6_image2-4fa03b8bde3b7bda89ece8a2ac6da510.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week7","title":"Week 7: Body Motion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week8","title":"Week 8: The Brain","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/0698af3bcaf829b93eb28d09596d0541.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week9","title":"Week 9: Vision","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week10","title":"Week 10: Physiology","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week11","title":"Week 11: Machine Listening","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/sensingsoundandmusic"},"routes/$":{"config":{"version":2,"myst":"1.6.1","options":{"favicon":"/sensingsoundandmusic/build/favicon-2720eef16358a9679c7ec109a6d05906.ico"},"nav":[],"actions":[],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"exports":[],"title":"Sensing Sound and Music","description":"An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives.","authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"id":"11cc8b5a-b0a2-4516-8397-a7dbad782f82","toc":[{"file":"intro.md"},{"file":"week1.md"},{"file":"week2.md"},{"file":"week3.ipynb"},{"file":"week4.ipynb"},{"file":"week5.md"},{"file":"week6.ipynb"},{"file":"week7.md"},{"file":"week8.md"},{"file":"week9.md"},{"file":"week10.md"},{"file":"week11.md"}],"bibliography":[],"index":"index","pages":[{"slug":"week1","title":"Week 1: Tuning in","description":"This page introduces the foundational concepts of music psychology and technology, exploring how humans perceive, experience, and create sound and music through both psychological and technological perspectives.","date":"","thumbnail":"/sensingsoundandmusic/build/c20d5f224f701120b83307814eab6564.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week2","title":"Week 2: Listening","description":"This chapter explores the art and science of listening, focusing on how sounds and soundscapes are described, understood, and analyzed across disciplines. It introduces influential theories and thinkers, practical listening exercises, and tools for engaging with the sonic environment.","date":"","thumbnail":"/sensingsoundandmusic/build/impulsive-sustained--c0c48158496bcc681fba65df66fa6f2f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week3","title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","date":"","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week4","title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacoustics—the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","date":"","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week5","title":"Week 5: Time and Rhythm","description":"This chapter explores the foundations of musical time and rhythm, covering concepts such as onset timing, perceptual centers, meter, microrhythm, groove, and entrainment. It examines how rhythm is structured, perceived, and performed, highlighting the roles of technology and analysis tools in understanding the nuances of timing and groove in various musical styles.","date":"","thumbnail":"/sensingsoundandmusic/build/week5_image6-42ef9fdd71a421c1baf682d65217062b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week6","title":"Week 6: Harmony and melody","description":"This notebook explores the concepts of harmony, melody, and musical structure through both theoretical explanations and practical visualizations. It covers fundamental audio representations, symbolic music formats, and provides code examples for analyzing and visualizing musical elements using Python.","date":"","thumbnail":"/sensingsoundandmusic/build/week6_image2-4fa03b8bde3b7bda89ece8a2ac6da510.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week7","title":"Week 7: Body Motion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week8","title":"Week 8: The Brain","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/0698af3bcaf829b93eb28d09596d0541.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week9","title":"Week 9: Vision","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week10","title":"Week 10: Physiology","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week11","title":"Week 11: Machine Listening","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":2,"kind":"Notebook","sha256":"69b505dd644e00673c7c557be30027928b67dc35861944ceef3b6b22e9369520","slug":"week3","location":"/week3.ipynb","dependencies":[],"frontmatter":{"title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","subtitle":"Introducing the physics of sound, room acoustics, and digital audio","authors":[{"nameParsed":{"literal":"Alexander Refsum Jensenius","given":"Alexander Refsum","family":"Jensenius"},"name":"Alexander Refsum Jensenius","affiliations":["University of Oslo"],"id":"contributors-week3-generated-uid-0"}],"affiliations":[{"id":"University of Oslo","name":"University of Oslo"}],"exports":[{"format":"ipynb","filename":"week3.ipynb","url":"/sensingsoundandmusic/build/week3-8e68cfcdfe47927d60f66276ea6f1d9c.ipynb"}],"content_includes_title":false,"kernelspec":{"name":"python3","display_name":".venv","language":"python"},"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"source_url":"https://github.com/fourMs/sensingsoundandmusic/blob/main/book/week3.ipynb","edit_url":"https://github.com/fourMs/sensingsoundandmusic/edit/main/book/week3.ipynb","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg"},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This week will explore the world of ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Ctglzi3u78"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"acoustics","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"eNYmjSQrAX"}],"key":"k6A7KEd2C9"},{"type":"text","value":", which is a term that everyone knows, yet few people can define properly. We will go over the physics of sound, and look more closely at instrument acoustics and room acoustics before ending with an introduction to digital sound.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"u9VXbQN6Fj"}],"key":"DyKbxTymeM"},{"type":"heading","depth":2,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Introduction","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"v03tC75gtd"}],"identifier":"introduction","label":"Introduction","html_id":"introduction","implicit":true,"key":"Z5mQapil6a"},{"type":"heading","depth":3,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Defining acoustics","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"MPN3seo3wv"}],"identifier":"defining-acoustics","label":"Defining acoustics","html_id":"defining-acoustics","implicit":true,"key":"vD3y4iWiu7"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"A short definition can be that acoustics is the study of sound and its properties. The term originates from the Greek word ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"L4kY9iLULJ"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"ἀκουστικός (akoustikos)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"JtCuMTH1rg"}],"key":"MD5n1bfJM8"},{"type":"text","value":", meaning “of or for hearing, ready to hear.” According to the ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"x4Ui8McPPj"},{"type":"link","url":"https://webstore.ansi.org/standards/asa/ansiasas112013","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"ANSI/ASA S1.1-2013","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ntVCNfMS6V"}],"urlSource":"https://webstore.ansi.org/standards/asa/ansiasas112013","key":"yJOXH7SJ8r"},{"type":"text","value":" standard, acoustics typically have two meanings:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"XaC1QNVuwA"}],"key":"fbT5l2GFic"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":11,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The science of sound, encompassing its production, transmission, and effects, both biological and psychological (","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"TOIH7vD6QX"},{"type":"link","url":"https://en.wikipedia.org/wiki/Acoustics","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"acoustics","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"XcyWhsEl5S"}],"urlSource":"https://en.wikipedia.org/wiki/Acoustics","data":{"page":"Acoustics","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"GMHqK9Ff9C"},{"type":"text","value":")","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"O0NwcvfRy2"}],"key":"BdZgDCPHcw"}],"key":"RjdKKi7CAG"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The qualities of a room that determine its auditory characteristics (which is the sub-discipline of ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"ElVi3G6Kvh"},{"type":"link","url":"https://en.wikipedia.org/wiki/Room_acoustics","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"room acoustics","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"zR4qnUjqjy"}],"urlSource":"https://en.wikipedia.org/wiki/Room_acoustics","data":{"page":"Room_acoustics","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"eK4eUU4ntO"},{"type":"text","value":").","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"Bts9IARxa8"}],"key":"wgKvhfTiI4"}],"key":"EZXW6K8RTQ"}],"key":"SvZIxBnEuF"},{"type":"paragraph","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"We will begin by considering acoustics broadly and then some of its subdisciplines, room acoustics, instrument acoustics, and electroacoustics. However, the latter three are just some of the many subdisciplines of acoustics, as seen in this overview.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"GVbljueExB"}],"key":"FtdU9OVyRE"},{"type":"image","url":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","alt":"Lindsay's Wheel of Acoustics","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"T3tKxQO3gu","urlSource":"https://upload.wikimedia.org/wikipedia/commons/8/82/Lindsay%27s_Wheel_of_Acoustics.svg"},{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Figure: Lindsay’s Wheel of Acoustics, illustrating the interdisciplinary nature of acoustics (","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"bg8ukdhdB4"},{"type":"link","url":"https://commons.wikimedia.org/wiki/File:Lindsay%27s_Wheel_of_Acoustics.svg","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"source","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"dUwMy0l8vD"}],"urlSource":"https://commons.wikimedia.org/wiki/File:Lindsay%27s_Wheel_of_Acoustics.svg","key":"xDkHpm1hQn"},{"type":"text","value":").","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"DQZUZzR0YO"}],"key":"JsTK4201dM"}],"key":"xM4z0A1aGB"},{"type":"heading","depth":3,"position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"Why is acoustics important for musicology, music psychology, and music technology?","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"gZKV41Pjxo"}],"identifier":"why-is-acoustics-important-for-musicology-music-psychology-and-music-technology","label":"Why is acoustics important for musicology, music psychology, and music technology?","html_id":"why-is-acoustics-important-for-musicology-music-psychology-and-music-technology","implicit":true,"key":"aAvnHGfivR"},{"type":"paragraph","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Understanding acoustics is essential for musicology, music psychology, and music technology because it provides the scientific foundation for how sound is produced, transmitted, and perceived. In musicology, acoustics helps analyze the physical properties of musical instruments and performance spaces, informing historical and cultural studies of music. In music psychology, acoustics underpins research into how humans perceive pitch, timbre, loudness, and spatial attributes of sound, which are crucial for understanding musical cognition and emotion. In music technology, acoustics guides the design of audio equipment, recording techniques, and digital sound processing, enabling innovations in music production, reproduction, and analysis. Thus, acoustics bridges the gap between the physical world of sound and its artistic, perceptual, and technological dimensions.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"JuAjxnHdpT"}],"key":"i9FY2Oj4dv"}],"key":"IeYq6Ghot5"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Cause and effect","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qnnAZwr6cK"}],"identifier":"cause-and-effect","label":"Cause and effect","html_id":"cause-and-effect","implicit":true,"key":"SauBTru3ey"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"At its core, acoustics is about describing the cause and effect of sound. If we consider this systemically, we can think of the following chain from cause to effect:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wliAxufroY"}],"key":"yo6OCvs27o"},{"type":"mermaid","value":"graph LR\n    A[Cause] --\u003e B[Generating mechanism]\n    B --\u003e C[Propagation]\n    C --\u003e D[Reception]\n    D --\u003e E[Effect]","position":{"start":{"line":5,"column":1},"end":{"line":11,"column":1}},"key":"fnRMjhx2mY"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"The generating and receiving mechanisms in acoustics are typically achieved through ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"plPftCWuC2"},{"type":"emphasis","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"transduction","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"JY8MLkOJGw"}],"key":"dv1Jr4uG0S"},{"type":"text","value":", the process of converting energy from one form to another (e.g., mechanical to electrical, or vice versa). Sound first propagates through a medium (such as air, water, or solids), and is then transduced again at the point of reception, enabling further processing or perception. This chain of transduction and propagation is fundamental to how sound is produced, transmitted, and experienced.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Sclg62gVx3"}],"key":"cVeEQ5KnM3"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"For example, when a guitarist plucks a string (cause), the string vibrates and generates sound waves (generating mechanism). These sound waves travel through the air (propagation) and reach the human ear, where it is transduced and processed further. We will get back to the ear next week.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"yhwsjdCjHZ"}],"key":"nTbhcFLzMJ"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"The chain can be more complex. For example, the guitar sound can be picked up by a microphone, which converts the sound waves into electrical signals (reception/transduction). The electrical signals are then sent to a speaker, which converts them back into sound waves (effect/transduction), allowing the audience to hear the music.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"rg0VknUk9V"}],"key":"y2JkuS2Mkh"}],"key":"qUzipEjeI2"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Nature of sound waves","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JmEYiZeOUN"}],"identifier":"nature-of-sound-waves","label":"Nature of sound waves","html_id":"nature-of-sound-waves","implicit":true,"key":"qfl2cQdYnm"}],"key":"XpQhrM2Ws5"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Vibrations","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lItxKMVrke"}],"identifier":"vibrations","label":"Vibrations","html_id":"vibrations","implicit":true,"key":"CPWlOekqfR"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Vibrations are oscillatory motions of particles within a medium, which generate sound waves. These vibrations can be ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ECXUHnHEG8"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"periodic","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"k8NSzrHn3F"}],"key":"HAFk9Y4bja"},{"type":"text","value":" (regular and repeating, as in musical notes) or ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"LBaOueaWFx"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"aperiodic","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"l3hHB3bcWY"}],"key":"kUfQGtPYHy"},{"type":"text","value":" (irregular, as in noise). The nature of these vibrations determines the characteristics of the resulting sound, such as pitch and timbre. Vibrations are fundamental to the production and transmission of sound in acoustics. Let us begin by investigating some of the properties of sound waves.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VJAgXq8UDj"}],"key":"SWkor5i7EW"}],"key":"XOdHLJSsHZ"},{"type":"block","kind":"notebook-content","children":[{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"pzzrO9v1UZ"}],"key":"k5wk1cSQnf"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"In the following, all the plots will be generated by Python code running inside the Jupyter Notebook that this text is written in. You can at any point in time check the source of the code, and even try yourself locally or in ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Ccr7xbEOU5"},{"type":"link","url":"https://colab.research.google.com/github/alexarje/sensing/blob/main/book/week3.ipynb","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Colab","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"x9e6aD2HBQ"}],"urlSource":"https://colab.research.google.com/github/alexarje/sensing/blob/main/book/week3.ipynb","key":"E0qk7ANcOx"},{"type":"text","value":". You don’t need to understand the details of the code, but as you progress in your learning, it may help to be able to create such plots yourself.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"rAfWUWy1w6"}],"key":"opWhFhdmd0"}],"key":"rYvSJfumhn"}],"key":"Dk8TjkEfpT"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# To make the rest of the code work, we need to load some Python libraries: \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft, fftfreq","visibility":"hide","key":"abuMx2IHWq"},{"type":"output","id":"bpcu9SrZdhq_X1ZlOnJYK","data":[{"ename":"ModuleNotFoundError","evalue":"No module named 'scipy'","output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----\u003e \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fft, fftfreq\n\n\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy'"}],"visibility":"show","key":"jh1odDJReF"}],"visibility":"show","key":"Nk11tn8jKW"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define x\nx = np.linspace(0, 2 * np.pi, 1000)\n\n# Generate a periodic wave (sine wave)\nperiodic_wave = np.sin(2 * np.pi * x)\n\n# Generate an aperiodic wave (random noise)\naperiodic_wave = np.random.normal(0, 0.5, len(x))\n\n# Plot the periodic and aperiodic waves\nplt.figure(figsize=(12, 6))\n\n# Plot periodic wave\nplt.subplot(2, 1, 1)\nplt.plot(x, periodic_wave, label='Periodic Wave (Sine)', color='blue')\nplt.title('Periodic Wave')\nplt.xlabel('x')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\n\n# Plot aperiodic wave\nplt.subplot(2, 1, 2)\nplt.plot(x, aperiodic_wave, label='Aperiodic Wave (Noise)', color='red')\nplt.title('Aperiodic Wave')\nplt.xlabel('x')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\n\nplt.tight_layout()\nplt.show()","visibility":"hide","key":"sVK962foeE"},{"type":"output","id":"gZJXpP1COrB6ky1XBVj9w","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"2f5426082c7b88b0544bdc6afb51155e","path":"/sensingsoundandmusic/build/2f5426082c7b88b0544bdc6afb51155e.png"},"text/plain":{"content":"\u003cFigure size 1200x600 with 2 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"L7UuAx2jkZ"}],"visibility":"show","key":"eWExmvoODd"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Longitudinal and Transverse Waves","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qhIiXmjYqr"}],"identifier":"longitudinal-and-transverse-waves","label":"Longitudinal and Transverse Waves","html_id":"longitudinal-and-transverse-waves","implicit":true,"key":"IjeRfjafpX"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Mechanical waves travel through a medium (such as air, water, or solids) by causing particles to vibrate. These waves are classified based on the direction of particle motion relative to the direction of wave propagation:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ZHVctk8LG8"}],"key":"PAztNEEfqz"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Longitudinal waves","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"oCc0kJVUAw"}],"key":"xqFzRzneEt"},{"type":"text","value":": Particles oscillate parallel to the direction the wave travels. Sound waves in air are a common example.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"sRRw2U55IX"}],"key":"TTTxkgHp2v"}],"key":"rNmvhlNAKa"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Transverse waves","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"jRkRXb9mIk"}],"key":"KDB5m6lCd9"},{"type":"text","value":": Particles oscillate perpendicular to the direction of wave travel. Examples include waves on a string or surface water waves.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"ETRjnHhMG0"}],"key":"Us1Htjd9b5"}],"key":"EVXuSDOG39"}],"key":"ehR3RFIXz3"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Understanding these wave types is fundamental to acoustics, as they determine how energy is transmitted through different materials.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"P3UAqdD1dq"}],"key":"HqWmsMwmu4"}],"key":"eFmLUamHfF"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define parameters for the waves\nx = np.linspace(0, 2 * np.pi, 100)\namplitude = 0.5\nfrequency = 1\n\n# Generate waveforms\nwave = np.sin(2 * np.pi * frequency * x)\n\n# Create particle positions for longitudinal and transverse waves\nlongitudinal_x = x + amplitude * np.sin(2 * np.pi * frequency * x)\nlongitudinal_y = np.zeros_like(x)  # No vertical displacement\n\ntransverse_x = x  # No horizontal displacement\ntransverse_y = amplitude * np.sin(2 * np.pi * frequency * x)\n\n# Create the figure\nplt.figure(figsize=(12, 6))\n\n# Plot longitudinal wave\nplt.subplot(2, 1, 1)\nplt.plot(x, np.zeros_like(x), '--', color='gray', label='Wave Direction')\nplt.scatter(longitudinal_x, longitudinal_y, color='blue', label='Particles')\nplt.title('Longitudinal Wave (Particles Oscillate Parallel to Wave Direction)')\nplt.xlabel('Wave Direction')\nplt.ylabel('Particle Displacement')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\n\n# Plot transverse wave\nplt.subplot(2, 1, 2)\nplt.plot(x, np.zeros_like(x), '--', color='gray', label='Wave Direction')\nplt.scatter(transverse_x, transverse_y, color='red', label='Particles')\nplt.title('Transverse Wave (Particles Oscillate Perpendicular to Wave Direction)')\nplt.xlabel('Wave Direction')\nplt.ylabel('Particle Displacement')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\n\nplt.tight_layout()\nplt.show()","visibility":"hide","key":"WIHFJBIr56"},{"type":"output","id":"RaOsKGhnki5Lsm9tlnV_X","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"d219b3543df3a209a2231c01bf085f27","path":"/sensingsoundandmusic/build/d219b3543df3a209a2231c01bf085f27.png"},"text/plain":{"content":"\u003cFigure size 1200x600 with 2 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"B5MLh4do2A"}],"visibility":"show","key":"vNZNOIctcY"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Frequency","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QEVUWXKDwI"}],"identifier":"frequency","label":"Frequency","html_id":"frequency","implicit":true,"key":"B1RxdwCZix"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Frequency refers to the number of complete oscillations or cycles a sound wave undergoes per second, measured in Hertz (Hz). It determines the audible ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"UiZLUFjxGu"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"pitch","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jPRHmr1SSL"}],"key":"izpELqzrHt"},{"type":"text","value":" of a sound: higher frequencies produce higher-pitched sounds, while lower frequencies result in lower-pitched sounds. Frequency is a fundamental property in acoustics, influencing how we perceive and analyze sound.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"pIAoPqYDe1"}],"key":"eCP4WyvhvE"}],"key":"vX7EK5RpUZ"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define parameters for the sine waves\ntime = np.linspace(0, 1, 1000)  # Time in seconds (0 to 1 second)\nfreq1, freq2, freq3 = 1, 2, 3  # Frequencies of the sine waves in Hz\nwave1 = np.sin(2 * np.pi * freq1 * time)  # First sine wave\nwave2 = np.sin(2 * np.pi * freq2 * time)  # Second sine wave\nwave3 = np.sin(2 * np.pi * freq3 * time)  # Third sine wave\n\n# Plot the sine waves\nplt.figure(figsize=(12, 4))\nplt.plot(time, wave1, label=f'A: Frequency={freq1} Hz')\nplt.plot(time, wave2, label=f'B: Frequency={freq2} Hz')\nplt.plot(time, wave3, label=f'C: Frequency={freq3} Hz')\nplt.title('Sine Waves with Different Frequencies')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\nplt.show()","visibility":"hide","key":"JyzXezun4i"},{"type":"output","id":"f76h-5KldgUiC5qrJWyVC","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"43c4af62f61a4feb55348b860efa7d1a","path":"/sensingsoundandmusic/build/43c4af62f61a4feb55348b860efa7d1a.png"},"text/plain":{"content":"\u003cFigure size 1200x400 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"vY6cvek0M5"}],"visibility":"show","key":"NSKDEYpkoG"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The frequency of a wave is closely related to its ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CKXdBKg3sE"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"period","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jTt81pd06R"}],"key":"E0w9klSALg"},{"type":"text","value":", the time it takes for one complete cycle of a wave to occur. The period is measured in seconds (s) and frequency is the number of cycles that occur per second, measured in Hertz (Hz).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Fyl2kONmnQ"}],"key":"gp9l6wbCe7"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"[\nf = \\frac{1}{T}\n]\n[\nT = \\frac{1}{f}\n]","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"unrtwuiHQN"}],"key":"TyHSTLPyOT"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"For example, if a wave has a period of 0.01 seconds, its frequency is ( f = 1 / 0.01 = 100 ) Hz. If the frequency is 50 Hz, the period is ( T = 1 / 50 = 0.02 ) seconds.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"ubuBnB319v"}],"key":"Zudo1gFTSL"}],"key":"s8QBwrtMb2"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Amplitude","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lw4te3a2s0"}],"identifier":"amplitude","label":"Amplitude","html_id":"amplitude","implicit":true,"key":"hkdCjbohFd"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"A sound wave’s amplitude defines how “loud” it is. More precisely, amplitude is the maximum displacement of particles in the medium from their rest position as the wave passes through. In a graphical representation, such as a sine wave, amplitude corresponds to the peak value above and below the center line (zero).","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ITda7pR5yC"}],"key":"g3nTMdQWAM"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Higher amplitude means greater energy in the wave, resulting in a louder sound. Lower amplitude produces a quieter sound. Amplitude is typically measured in units such as meters (for displacement), pascals (for pressure), or volts (for electrical signals).","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"F2KqKSxomI"}],"key":"Ydk8YXwWi5"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"For example, in the plot below, each sine wave has a specific amplitude. The peaks and troughs of the wave show the maximum and minimum values, illustrating how amplitude determines the loudness of the sound.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"UkcTKGyjlo"}],"key":"j4DIZNL8WH"}],"key":"Qamw9CR64o"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define amplitudes for the sine tones\namplitude1 = 0.5\namplitude2 = 1.0\namplitude3 = 1.5\n\n# Generate the sine tones\nsine1 = amplitude1 * np.sin(x)\nsine2 = amplitude2 * np.sin(x)\nsine3 = amplitude3 * np.sin(x)\n\n# Plot the sine tones\nplt.figure(figsize=(12, 4))\nplt.plot(x, sine1, label='Amplitude = 0.5', alpha=0.8)\nplt.plot(x, sine2, label='Amplitude = 1.0', alpha=0.8)\nplt.plot(x, sine3, label='Amplitude = 1.5', alpha=0.8)\nplt.title('Sine Tones with Different Amplitudes')\nplt.xlabel('x')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\nplt.show()","visibility":"hide","key":"nT5IMWVeWk"},{"type":"output","id":"bxMPVMxbxpXpFg-K3koH4","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"95d21b1a311befa4436ef5db09f19e83","path":"/sensingsoundandmusic/build/95d21b1a311befa4436ef5db09f19e83.png"},"text/plain":{"content":"\u003cFigure size 1200x400 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"IpMWzKpqeK"}],"visibility":"show","key":"CEzPzMQUzI"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Sound Pressure Level (SPL)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BQODOkYbGh"}],"identifier":"sound-pressure-level-spl","label":"Sound Pressure Level (SPL)","html_id":"sound-pressure-level-spl","implicit":true,"key":"i9d8ayCF8W"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Sound_pressure#Sound_pressure_level","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Sound Pressure Level","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"IZtX3sa7XT"}],"urlSource":"https://en.wikipedia.org/wiki/Sound_pressure#Sound_pressure_level","data":{"page":"Sound_pressure#Sound_pressure_level","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"UTa1tClmwB"},{"type":"text","value":" (SPL) is a measure of the pressure variation caused by a sound wave. It is used in various fields, such as acoustics, audio engineering, and environmental noise monitoring, to assess sound levels and ensure compliance with safety standards. Understanding SPL is crucial for analyzing how sound behaves in different environments and its impact on human hearing.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vr8eGxYKmm"}],"key":"CYPD6ONuwA"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"SPL is expressed in ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"buOLSRwCqO"},{"type":"link","url":"https://en.wikipedia.org/wiki/Decibel","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"decibels","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"V0dSSNWpxq"}],"urlSource":"https://en.wikipedia.org/wiki/Decibel","data":{"page":"Decibel","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"WjHiGlfbTF"},{"type":"text","value":" (dB), which is a ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"af9H613vFV"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Logarithmic_scale","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"logarithmic","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nULdqM73Vf"}],"urlSource":"https://en.wikipedia.org/wiki/Logarithmic_scale","data":{"page":"Logarithmic_scale","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"EghZTCrtry"}],"key":"RXOfiUr1x1"},{"type":"text","value":" unit used to express the ratio of two values. In a logarithmic scale, each step on the scale represents a multiplication rather than a simple addition. For example, an increase of 10 dB corresponds to a tenfold increase in sound intensity, while an increase of 20 dB means a hundredfold increase. This allows us to represent very large ranges of sound pressure in a compact and manageable way, since human hearing also perceives loudness logarithmically rather than linearly.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"hNje7WdMkb"}],"key":"yqNAlGM3rH"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The formula for SPL in decibels is:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"U7v6JZXtJA"}],"key":"YOd8eCWhs0"},{"type":"span","style":{"display":"block","textAlign":"center"},"children":[{"type":"strong","children":[{"type":"text","value":"SPL","key":"ISooYwBjJd"}],"key":"XAyByM9UrI"},{"type":"text","value":" = 20 log","key":"D15a8IWjIz"},{"type":"subscript","children":[{"type":"text","value":"10","key":"fmwcnCBBlV"}],"key":"zUOtHtUcur"},{"type":"text","value":"(p / p","key":"CcVk1qo5vW"},{"type":"subscript","children":[{"type":"text","value":"0","key":"ocNAQkIF2W"}],"key":"HrzlZd7JCj"},{"type":"text","value":")","key":"IMqjD1tDog"}],"key":"y0f7VDCx44"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"where ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"kDo3IXmsuC"},{"type":"emphasis","children":[{"type":"text","value":"p","key":"yiYWeztt7o"}],"key":"mpfcc8U4R9"},{"type":"text","value":" is the measured sound pressure and ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"utbvPJVkXq"},{"type":"emphasis","children":[{"type":"text","value":"p ","key":"ZKUFIAHYSw"},{"type":"subscript","children":[{"type":"text","value":"0","key":"HBFMSvM1rP"}],"key":"wiajz5tqIk"}],"key":"P6ISFjrzT5"},{"type":"text","value":" is the reference sound pressure (typically 20 μPa in air).","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"LNdMEEkygD"}],"key":"VCrSf92AH5"}],"key":"LpQqkoeESs"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Plot illustrating regular (linear) vs logarithmic scale\n\nx = np.linspace(1, 1000, 1000)\ny = x  # Linear relationship\n\nplt.figure(figsize=(12, 5))\n\n# Linear scale plot\nplt.subplot(1, 2, 1)\nplt.plot(x, y, color='blue')\nplt.title('Linear Scale')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid()\n\n# Logarithmic scale plot\nplt.subplot(1, 2, 2)\nplt.plot(x, y, color='red')\nplt.yscale('log')\nplt.title('Logarithmic Scale (y-axis)')\nplt.xlabel('x')\nplt.ylabel('y (log scale)')\nplt.grid()\n\nplt.tight_layout()\nplt.show()","visibility":"hide","key":"uFRzk7ikYi"},{"type":"output","id":"Y9albJUf1APGhbiXyC8bO","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"55564c86d862f9866651a58ed72722e6","path":"/sensingsoundandmusic/build/55564c86d862f9866651a58ed72722e6.png"},"text/plain":{"content":"\u003cFigure size 1200x500 with 2 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"dMgPF0Ui6e"}],"visibility":"show","key":"iimF5kBIE8"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"What is important to know is that a 10 dB increase in SPL is generally perceived as about twice as loud by the human ear. This is because human hearing responds logarithmically: a 10 dB rise means the sound pressure increases by a factor of about 3.16, but our perception of loudness roughly doubles.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"O0zK6vDR2h"}],"key":"Q8T3Oxfztv"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"oO2IdKufax"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"3 dB rule","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"cfjDf5kCxm"}],"key":"SVkWzP7T8O"},{"type":"text","value":" states that if you add a second identical sound source, the SPL increases by about 3 dB, doubling the energy but only slightly increasing perceived loudness. For example, if a single speaker produces 70 dB SPL at a certain point, adding a second identical speaker playing the same signal at the same location will increase the SPL to approximately 73 dB. This is because the sound pressure doubles, resulting in a 3 dB increase, but the perceived loudness is only slightly greater, not doubled. Similarly, two 60 dB sound sources will have a combined SPL of 63 dB.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"z8Nw0leqV3"}],"key":"WdfpT7Dmpc"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"In addition, you need to know about the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"fY3VC1ZY0E"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Inverse-Square Law","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"PKYTzGZZkp"}],"key":"UlUIhrgJl9"},{"type":"text","value":", which states that when the distance from a sound source doubles, the sound pressure drops to one-fourth, resulting in a 6 dB reduction in SPL. This explains why sounds become much quieter as you move further away from the source.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"rvOb6Nf9q5"}],"key":"PULYRSdncp"},{"type":"image","url":"/sensingsoundandmusic/build/47adf533f5737acf99eccc4024a66adb.svg","alt":"Inverse Square Law","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"oLVMFkteQY","urlSource":"https://upload.wikimedia.org/wikipedia/commons/d/da/Inverse_square_law_mk.svg"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Figure: Illustration of the Inverse-Square Law, showing how sound pressure decreases with distance (","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"FqQDVfMzDN"},{"type":"link","url":"https://commons.wikimedia.org/wiki/File:Inverse_square_law_mk.svg","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Wikipedia","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ZXb6nPzxDs"}],"urlSource":"https://commons.wikimedia.org/wiki/File:Inverse_square_law_mk.svg","key":"GXongQqmLf"},{"type":"text","value":").","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"nIihdpYF8N"}],"key":"OzZKeOnkXe"}],"key":"GHhmj6B8X7"}],"key":"kFYGVBOyen"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Phase","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oA3ggNWSAI"}],"identifier":"phase","label":"Phase","html_id":"phase","implicit":true,"key":"Cbwt3keODz"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Describes the position of a point within a wave cycle, measured in degrees or radians. Phase differences between waves can lead to constructive or destructive interference.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"CVlneIRbAz"}],"key":"M1SlmQ1rM2"}],"key":"liqcy1ipZu"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define the amplitude and frequency for the sine tones\nx = np.linspace(0, 2 * np.pi, 100)\namplitude = 1\nfrequency = 1  # Frequency in Hz\n\n# Define the phases for the three sine tones\nphase1 = 0  # 0 radians\nphase2 = np.pi / 4  # 45 degrees in radians\nphase3 = np.pi / 2  # 90 degrees in radians\n\n# Convert x to time in seconds\ntime_in_seconds = x / (2 * np.pi * frequency)\n\n# Generate the sine tones\nsine1 = amplitude * np.sin(2 * np.pi * frequency * time_in_seconds + phase1)\nsine2 = amplitude * np.sin(2 * np.pi * frequency * time_in_seconds + phase2)\nsine3 = amplitude * np.sin(2 * np.pi * frequency * time_in_seconds + phase3)\n\n# Plot the sine tones\nplt.figure(figsize=(12, 4))\nplt.plot(time_in_seconds, sine1, label='Phase = 0 rad', alpha=0.8)\nplt.plot(time_in_seconds, sine2, label='Phase = π/4 rad', alpha=0.8)\nplt.plot(time_in_seconds, sine3, label='Phase = π/2 rad', alpha=0.8)\nplt.title('Sine Tones with Different Phases')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\nplt.show()","visibility":"hide","key":"xyJeA2jGPQ"},{"type":"output","id":"40GugnNPcxO1VPhxy1jp9","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"e6bbb0d0d68c268d5b39b9acca25854d","path":"/sensingsoundandmusic/build/e6bbb0d0d68c268d5b39b9acca25854d.png"},"text/plain":{"content":"\u003cFigure size 1200x400 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"uCiPR1B8Lp"}],"visibility":"show","key":"JvsbuwmBXD"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define amplitude and frequency for the sine tones\namplitude = 1\nfrequency = 1  # Frequency in Hz\n\n# Use x from previous cells\n# Define two sine tones with opposite phases (0 and pi)\nsine1 = amplitude * np.sin(x)\nsine2 = amplitude * np.sin(x + np.pi)  # 180 degrees out of phase\n\n# Sum of the two sine tones\nsum_wave = sine1 + sine2\n\n# Plot the two sine tones and their sum\nplt.figure(figsize=(12, 4))\nplt.plot(x, sine1, label='Sine Tone 1 (Phase = 0)', alpha=0.8)\nplt.plot(x, sine2, label='Sine Tone 2 (Phase = π)', alpha=0.8)\nplt.plot(x, sum_wave, label='Sum (Cancellation)', color='black', linewidth=2)\nplt.title('Two Sine Tones Out of Phase (Cancellation)')\nplt.xlabel('x')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\nplt.show()","visibility":"hide","key":"ywLstfvyL2"},{"type":"output","id":"7Up17rkvANQDkL9MsX6ck","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"7c25ba7d860e2aceba7ef30c5752d6f8","path":"/sensingsoundandmusic/build/7c25ba7d860e2aceba7ef30c5752d6f8.png"},"text/plain":{"content":"\u003cFigure size 1200x400 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"tDgd0CzcLR"}],"visibility":"show","key":"aPattVtKJD"},{"type":"block","kind":"notebook-content","children":[{"type":"exercise","children":[{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Have you tried swapping the phase in a music track? Try ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"XIY75gIiq2"},{"type":"link","url":"https://l2ork.music.vt.edu:3000/?url=VTWaves/Phase-Cancellation-Emscripten.pd","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"this phase cancellation","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"NFnn50RCmJ"}],"urlSource":"https://l2ork.music.vt.edu:3000/?url=VTWaves/Phase-Cancellation-Emscripten.pd","key":"Nj6LDssvvk"},{"type":"text","value":" web experiment.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"t5WnJBkFe4"}],"key":"oUyqws0bN2"}],"label":"Phase in production","identifier":"phase in production","enumerated":true,"enumerator":"1","html_id":"phase-in-production","key":"fiXZV5sRjN"}],"key":"dAyI4jkAUb"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Beating waves","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XfrvQ9VyQQ"}],"identifier":"beating-waves","label":"Beating waves","html_id":"beating-waves","implicit":true,"key":"JFe1Vv6Lho"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"When two sound waves of slightly different frequencies are played together, they interfere with each other. This interference causes the amplitude of the combined wave to fluctuate up and down in a regular pattern, called a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BLICw7wq8F"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"beat","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"B3ocdtAYfo"}],"key":"qnoQ96sIZE"},{"type":"text","value":". The ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"eHI8dbfQcY"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Beat_(acoustics)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"beat frequency","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VMF5w9Faj3"}],"urlSource":"https://en.wikipedia.org/wiki/Beat_(acoustics)","data":{"page":"Beat_(acoustics)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"fFTP5lFPGx"}],"key":"bfJMQbdOAP"},{"type":"text","value":" is equal to the difference between the two original frequencies. For example, two tones with frequencies 440 Hz and 441 Hz will cause a beat frequency of 1 Hz. You hear this as the sound getting louder and softer at this beat frequency.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ikQnxde4BX"}],"key":"JkZ1SwJurA"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Mathematically, if you add two sine waves with close frequencies, the result is a wave whose amplitude varies slowly, creating the “beating” effect. This is commonly heard when tuning musical instruments or when two notes are almost, but not quite, in tune.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"E1v62CntNW"}],"key":"GopXLcmoG1"}],"key":"eTmC92f8gz"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define parameters for the two sine waves\nfrequency1 = 5  # Frequency of the first wave in Hz\nfrequency2 = 5.5  # Frequency of the second wave in Hz\namplitude = 1  # Amplitude of the waves\ntime = np.linspace(0, 5, 1000)  # Time array from 0 to 5 seconds\n\n# Generate the two sine waves\nwave1 = amplitude * np.sin(2 * np.pi * frequency1 * time)\nwave2 = amplitude * np.sin(2 * np.pi * frequency2 * time)\n\n# Generate the resulting wave (superposition)\nbeating_wave = wave1 + wave2\n\n# Plot the individual waves and the resulting wave\nplt.figure(figsize=(12, 4))\nplt.plot(time, wave1, label='Wave 1', alpha=0.7)\nplt.plot(time, wave2, label='Wave 2', alpha=0.7)\nplt.plot(time, beating_wave, label='Beating Wave', color='black', linewidth=2)\nplt.title('Beating Waves: Interference of Two Sine Waves')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\nplt.show()","visibility":"hide","key":"gQY3v4cJ7T"},{"type":"output","id":"ucT4UXXe8Z3ZUACrMJCdV","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"a15e2c0b0d715baaa6d5e9c237e7f78a","path":"/sensingsoundandmusic/build/a15e2c0b0d715baaa6d5e9c237e7f78a.png"},"text/plain":{"content":"\u003cFigure size 1200x400 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"Ykfk4fU79a"}],"visibility":"show","key":"U5LZAPprxI"},{"type":"block","kind":"notebook-content","children":[{"type":"exercise","children":[{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Try out making sine tones in ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Czim6mNS6w"},{"type":"link","url":"https://glicol.org/tour#basicconnection","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Glicol","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"P0zpgwlVXG"}],"urlSource":"https://glicol.org/tour#basicconnection","key":"aDwDoQahGI"},{"type":"text","value":". Change the amplitude and frequency to hear how they are affecting what you hear. Try adding an extra sine tone with a different frequency create a beat frequency.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"pH79YO8pAE"}],"key":"EfmuGir7SA"}],"label":"Sine tones","identifier":"sine tones","enumerated":true,"enumerator":"2","html_id":"sine-tones","key":"G9fJLFT53i"}],"key":"qFlFOCo4qe"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Complex waves","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Z2l1QtoDIJ"}],"identifier":"complex-waves","label":"Complex waves","html_id":"complex-waves","implicit":true,"key":"rNCwc1VF81"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"A ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Ua2bopntcB"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"complex wave","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PpebOFbYQ8"}],"key":"dCFqFVaVZe"},{"type":"text","value":" is a sound wave that consists of multiple frequencies combined together, rather than a single pure tone. Most sounds we hear in everyday life, such as musical notes, speech, or environmental noises, are complex waves.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"yzFdJn7gf3"}],"key":"vKa1mAqQx2"}],"key":"I3sO1iynnf"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define parameters for the sine waves\nx = np.linspace(0, 2 * np.pi, 1000)\nwave1 = np.sin(x)  # First sine wave\nwave2 = 0.5 * np.sin(2 * x)  # Second sine wave with half amplitude and double frequency\nwave3 = 0.25 * np.sin(3 * x)  # Third sine wave with quarter amplitude and triple frequency\n\n# Sum of the sine waves (complex wave)\ncomplex_wave = wave1 + wave2 + wave3\n\n# Plot the individual sine waves and the complex wave\nplt.figure(figsize=(12, 4))\nplt.plot(x, wave1, label='Sine Wave 1: sin(x)', alpha=0.7)\nplt.plot(x, wave2, label='Sine Wave 2: 0.5*sin(2x)', alpha=0.7)\nplt.plot(x, wave3, label='Sine Wave 3: 0.25*sin(3x)', alpha=0.7)\nplt.plot(x, complex_wave, label='Complex Wave: sum of sine waves', color='black', linewidth=2)\nplt.title('Composition of a Complex Wave from Sine Waves')\nplt.xlabel('x')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\nplt.show()","visibility":"hide","key":"OBG1jcK6GI"},{"type":"output","id":"OTifBhdBleIfQ2J09nweQ","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"d11580658cfaf0bc51acf785aa8cd920","path":"/sensingsoundandmusic/build/d11580658cfaf0bc51acf785aa8cd920.png"},"text/plain":{"content":"\u003cFigure size 1200x400 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"Uy8Ec9pw7M"}],"visibility":"show","key":"wrUYfTiFv3"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Time vs Frequency Domain","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Yzs9IRYFlK"}],"identifier":"time-vs-frequency-domain","label":"Time vs Frequency Domain","html_id":"time-vs-frequency-domain","implicit":true,"key":"Cx159WJw1O"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Sound can be represented visually in two fundamentally different ways:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HQ7N8qrtRG"}],"key":"MNsMjRkMOp"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Time domain","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"WLUasAilkF"}],"key":"cNfF3qHh3P"},{"type":"text","value":": A “waveform display” shows how the amplitude of a signal (such as a sound wave) changes over time This view helps us understand the shape, duration, and dynamics of the signal.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"xBmE8ABwKp"}],"key":"srFaMWitx6"}],"key":"J9cKoLjTEe"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Frequency domain","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"XUZ4xod0bP"}],"key":"M1XGJfKII8"},{"type":"text","value":": A ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"w92SZr6LUe"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"spectrum","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Qr3LwzvebR"}],"key":"azLaiGIZgd"},{"type":"text","value":" plot or ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"JYjbEgh0r2"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"spectrogram","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ExkUeRn1yh"}],"key":"PODy0DbYpa"},{"type":"text","value":" shows how much of the signal lies within each frequency band. The frequency domain representation is typically obtained using the Fourier transform. This view is useful for analyzing pitch, timbre, and spectral content.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"FsbaoYdxSA"}],"key":"IrXAMfC8az"}],"key":"IbAs7gkA6W"}],"key":"NSw3jFF7Cq"},{"type":"heading","depth":3,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"The Fourier Transform","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"v9qVLjy4PH"}],"identifier":"the-fourier-transform","label":"The Fourier Transform","html_id":"the-fourier-transform","implicit":true,"key":"PT9OZkCRPT"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Any complex wave can be represented as the sum of simpler sinusoidal waves with different frequencies, amplitudes, and phases, a process called ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"LiaAf8tKwe"},{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Fourier analysis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"aLP1gTYpL1"}],"key":"VyGS6eAySk"},{"type":"text","value":" (","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"KohWha1zps"},{"type":"link","url":"https://en.wikipedia.org/wiki/Fourier_analysis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Wikipedia","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Y8KP53gKQR"}],"urlSource":"https://en.wikipedia.org/wiki/Fourier_analysis","data":{"page":"Fourier_analysis","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"MqLelEmPhU"},{"type":"text","value":"). This technique was discovered by the French mathematician ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"JBvLb3Hwor"},{"type":"link","url":"https://en.wikipedia.org/wiki/Joseph_Fourier","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Joseph Fourier","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"CNirZZNVuy"}],"urlSource":"https://en.wikipedia.org/wiki/Joseph_Fourier","data":{"page":"Joseph_Fourier","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"xn1OhaNi9p"},{"type":"text","value":" (1768–1830), laying the foundation for modern signal processing and harmonic analysis.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"i6iJIk0oFr"}],"key":"pApZhNKq0J"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"BelwThis decomposition is fundamental in acoustics, music technology, and audio engineering, as it allows us to analyze, synthesize, and manipulate sounds in both the time and frequency domains.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"jW0nFXIP3t"}],"key":"pQKFuZuam2"}],"key":"eC7MK05SJA"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define parameters for the complex wave\nfrequency1 = 5  # Frequency of the first wave in Hz\nfrequency2 = 10  # Frequency of the second wave in Hz\nfrequency3 = 15  # Frequency of the third wave in Hz\namplitude1 = 1\namplitude2 = 0.5\namplitude3 = 0.25\n\n# Generate the complex wave as a sum of three sine waves\nwave1 = amplitude1 * np.sin(2 * np.pi * frequency1 * x)\nwave2 = amplitude2 * np.sin(2 * np.pi * frequency2 * x)\nwave3 = amplitude3 * np.sin(2 * np.pi * frequency3 * x)\ncomplex_wave = wave1 + wave2 + wave3\n\n# Compute the Fourier Transform of the complex wave\nN = len(complex_wave)\nT = (x[1] - x[0]) / (2 * np.pi)\nfrequencies = fftfreq(N, T)[:N // 2]\nfft_values = fft(complex_wave)[:N // 2]\n\n# Plot time domain, frequency domain, and spectrogram\nplt.figure(figsize=(12, 9))\n\n# Time domain plot\nplt.subplot(3, 1, 1)\nplt.plot(x, complex_wave, label='Complex Wave (Time Domain)', color='blue')\nplt.title('Waveform display (Time Domain)')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\n\n# Frequency domain plot\nplt.subplot(3, 1, 2)\nplt.plot(frequencies, np.abs(fft_values), label='Frequency Domain', color='red')\nplt.title('Spectrum plot (Frequency Domain)')\nplt.xlabel('Frequency (Hz)')\nplt.ylabel('Magnitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\n\n# Spectrogram plot\nplt.subplot(3, 1, 3)\nplt.specgram(complex_wave, NFFT=256, Fs=1/(x[1]-x[0]), noverlap=128, cmap='magma')\nplt.title('Spectrogram (Frequency Domain)')\nplt.xlabel('Time (s)')\nplt.ylabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()","visibility":"hide","key":"roRxm6OKw1"},{"type":"output","id":"DB58bU2x-MX4xZqNfCiqh","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"ed08eb663ad30c5d691a417d5a00c18e","path":"/sensingsoundandmusic/build/ed08eb663ad30c5d691a417d5a00c18e.png"},"text/plain":{"content":"\u003cFigure size 1200x900 with 3 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"JkIpRNk4yB"}],"visibility":"show","key":"Q0jgVcx8xh"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Note how the spectrum plot displays frequency on the X axis and magnitude on the Y axis, while the spectrogram shows time on the X axis and frequency on the Y axis. The spectrum provides an overview of the frequency content averaged over the entire signal. The spectrogram reveals how the frequency content changes over time, showing the temporal evolution.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"djbUqWZwnc"}],"key":"LlZ6jFGeX5"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To better visualize their relationship, you can plot the spectrum rotated 90 degrees, aligning its frequency axis with the spectrogram’s frequency axis. This highlights the difference: the spectrum summarizes the whole signal, while the spectrogram shows its development over time.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ECgwd7m3tk"}],"key":"jRVn74fdoY"}],"key":"ieay7d62U5"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n# Left: Spectrum turned 90 degrees\naxes[0].plot(np.abs(fft_values), frequencies, color='green', linewidth=2)\naxes[0].set_title('Spectrum')\naxes[0].set_ylabel('Frequency (Hz)')\naxes[0].set_xlabel('Magnitude')\naxes[0].grid()\n\n# Right: Spectrogram\naxes[1].specgram(complex_wave, NFFT=256, Fs=1/(x[1]-x[0]), noverlap=128, cmap='magma')\naxes[1].set_title('Spectrogram')\naxes[1].set_xlabel('Time (s)')\naxes[1].set_ylabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()","visibility":"hide","key":"dRKp97KVwf"},{"type":"output","id":"Qxk5cMkZi7g4-x9RQa8Ny","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"f4aae7408bd2668eecb2bc2060c345b5","path":"/sensingsoundandmusic/build/f4aae7408bd2668eecb2bc2060c345b5.png"},"text/plain":{"content":"\u003cFigure size 1200x600 with 2 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"RmKxvBFauo"}],"visibility":"show","key":"CTHTd13Bzv"},{"type":"block","kind":"notebook-content","children":[{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"Irw5bidpHp"}],"key":"zH0bcxMpgw"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"You may come across the term ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ufITUOxTjm"},{"type":"emphasis","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"sonogram","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"BfslCZmhe2"}],"key":"nZzMLWSDz3"},{"type":"text","value":" in the literature. It is essentially a spectrogram of sound signals. For sound and music, they are used interchangeably. However, spectrograms are more general, and can be used to decompose also other types of complex time-based signals.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"KQQruWPMQa"}],"key":"wZQ5U7mMZ2"}],"key":"ytkz5Hfz2X"}],"key":"h559m5s4DK"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Noise","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Sjc2ZHY8qi"}],"identifier":"noise","label":"Noise","html_id":"noise","implicit":true,"key":"yaWvy4T7sD"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Noise refers to random or unpredictable fluctuations in sound, often lacking a clear pitch or musical quality. In acoustics and audio engineering, different types of noise are characterized by their frequency content and how energy is distributed across the spectrum. Common types of noise include:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Z7xzWjmnfv"}],"key":"WIwZ8328mI"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"White noise","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"bRlSv8J1Dk"}],"key":"XfhyopvTjJ"},{"type":"text","value":": Contains all frequencies at equal intensity, resulting in a “hissing” sound similar to static from a radio or TV. It is often used for sound masking and audio testing because of its uniform frequency distribution.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Uz5pBeJvWs"}],"key":"P0Pxesw4lF"}],"key":"MyzAOlscYY"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Pink noise","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"pdTZtlyhmH"}],"key":"LABH4dX58j"},{"type":"text","value":": Has equal energy per octave, meaning its power decreases as frequency increases. This gives it a deeper sound, similar to rainfall or wind, and makes it useful for audio calibration and sleep aids.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Mn0uXJuICE"}],"key":"UkTiC2GBHd"}],"key":"fnqmWL9Hlb"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Brownian noise (Red noise)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"B8XIXrOG2T"}],"key":"MJ5pN5sMjh"},{"type":"text","value":": Emphasizes even lower frequencies than pink noise, producing a deep rumble or distant thunder-like sound. It is generated by random walk processes and is sometimes called “red noise.”","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"v9z1o0iJYZ"}],"key":"Jf3U3jGjvo"}],"key":"pSc2d63Qbi"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Blue noise","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"Qcuj34PBug"}],"key":"zcFLHeo3z1"},{"type":"text","value":": Contains more energy at higher frequencies, resulting in a brighter, sharper sound. Blue noise is rare in nature but is used in dithering applications in digital audio and image processing.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"OqxbzL8ixh"}],"key":"XVNS7fJPbl"}],"key":"cAEeIcNyY2"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Grey noise","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"cfFSDdty75"}],"key":"xKVKiXEgnC"},{"type":"text","value":": Adjusted so that all frequencies are perceived as equally loud to the human ear, based on psychoacoustic principles. It is used in research and testing to account for human hearing sensitivity.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Pzy6oUzfWT"}],"key":"KFQ0ITxtlz"}],"key":"FamTNOeHgw"}],"key":"spbePDx6Ps"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"The above noise types are “constant” in the sense that they have the same characteristics. One can also talk about different types of “impulse noise”, based on sudden, short bursts of sound, such as clicks, pops, or bangs. Impulse noise is common in environments with machinery, gunshots, or electrical discharges.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"R434D5iFrg"}],"key":"dhDUQumTVY"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"These noise types are used in audio testing, sound masking, electronic music, and various scientific applications. Understanding the characteristics of each type helps in designing systems for noise reduction, audio analysis, and environmental sound studies.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"CkgxDbBR7F"}],"key":"wI9AnYJ5hL"}],"key":"BG9L3iETpX"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define parameters\nsampling_rate = 1000  # Hz\nduration = 2  # seconds\nN = sampling_rate * duration\nt = np.linspace(0, duration, N, endpoint=False)\n\n# Generate noises\nwhite_noise = np.random.normal(0, 1, N)\n\n# Pink noise (approximate using Voss-McCartney algorithm)\ndef pink_noise(N):\n    n_rows = 16\n    n_cols = N\n    array = np.random.randn(n_rows, n_cols)\n    array = np.cumsum(array, axis=1)\n    array = array / np.arange(1, n_cols + 1)\n    return np.sum(array, axis=0)\n\npink_noise = pink_noise(N)\n\n# Brownian noise (integrated white noise)\nbrownian_noise = np.cumsum(np.random.normal(0, 1, N))\nbrownian_noise /= np.max(np.abs(brownian_noise))\n\n# Blue noise (differentiated white noise)\nblue_noise = np.diff(white_noise, prepend=0)\nblue_noise /= np.max(np.abs(blue_noise))\n\n# Grey noise (white noise shaped by equal loudness curve, here just normalized white noise)\ngrey_noise = white_noise / np.max(np.abs(white_noise))\n\n# Impulse noise (random sparse spikes)\nimpulse_noise = np.zeros(N)\nimpulse_indices = np.random.choice(N, size=int(N * 0.01), replace=False)\nimpulse_noise[impulse_indices] = np.random.choice([-1, 1], size=len(impulse_indices))\n\n# List of noises\nnoises = [\n    (\"White\", white_noise),\n    (\"Pink\", pink_noise),\n    (\"Brownian\", brownian_noise),\n    (\"Blue\", blue_noise),\n    (\"Grey\", grey_noise),\n    (\"Impulse\", impulse_noise)\n]\n\n# Plot spectrograms\nplt.figure(figsize=(12, 12))\nfor i, (name, noise) in enumerate(noises, 1):\n    plt.subplot(6, 1, i)\n    plt.specgram(noise, Fs=sampling_rate, NFFT=1024, noverlap=512, cmap='magma')\n    plt.title(f'{name} Noise Spectrogram')\n    plt.ylabel('Frequency (Hz)')\n    plt.xticks([])\n    plt.yticks([])\nplt.xlabel('Time (s)')\nplt.tight_layout()\nplt.show()","visibility":"hide","key":"HlF6JbIVMk"},{"type":"output","id":"sMYjgDr_XKNsu0Rc0SAJm","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"92af6899e9ae10fed5f36e17863d6498","path":"/sensingsoundandmusic/build/92af6899e9ae10fed5f36e17863d6498.png"},"text/plain":{"content":"\u003cFigure size 1200x1200 with 6 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"KXu4wl3bjD"}],"visibility":"show","key":"LdnIt9ZnGs"},{"type":"block","kind":"notebook-content","children":[{"type":"exercise","children":[{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Download and install ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"iQFr22QQ8H"},{"type":"link","url":"https://www.sonicvisualiser.org/","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Sonic Visualiser","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"CfA6tThjwK"}],"urlSource":"https://www.sonicvisualiser.org/","key":"BysAn2DWgt"},{"type":"text","value":", a free tool for visualizing and analyzing audio files. Open a sound file (such as a recording or sample) and experiment with creating spectrograms:","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"KJVF3YleRX"}],"key":"yPFwfUCr46"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":6,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Load your audio file into Sonic Visualiser.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"YQDLOoMPvQ"}],"key":"oxvteZDbLG"}],"key":"KoOzUUlFJD"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Add a new spectrogram layer (choose “Layer” → “Add Spectrogram”).","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"uxTaX3Doe7"}],"key":"eqBDKVHtJ7"}],"key":"Dffj4kHKGq"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Adjust the spectrogram settings (window size, color map, etc.) to explore how they affect the visualization.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"vRfoVnpQOO"}],"key":"IbR7CVpB2Y"}],"key":"fR2T33MV4F"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Try zooming in and out to examine different time and frequency regions.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"froEcqv7qS"}],"key":"xTI7J2mJhc"}],"key":"GmIaXlFw2N"}],"key":"YjVgKc03Y5"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"How does the spectrogram help you understand the frequency content and changes over time in your audio? Compare the visual patterns for different sounds (speech, music, noise).","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"g1n0iimDaw"}],"key":"xBwv5sE6Tp"}],"label":"Make spectrograms in Sonic Visualiser","identifier":"make spectrograms in sonic visualiser","enumerated":true,"enumerator":"3","html_id":"make-spectrograms-in-sonic-visualiser","key":"WqQqQVjcue"}],"key":"ejHUtZij7M"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Sound propagation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zL2FIovXZP"}],"identifier":"sound-propagation","label":"Sound propagation","html_id":"sound-propagation","implicit":true,"key":"AeI6uFEHdp"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Sound propagation refers to how sound waves travel through different environments and interact with materials.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"RZ87rNKczf"}],"key":"GD1sVunuIv"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Medium of Propagation","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"vxEbP2L6kr"}],"identifier":"medium-of-propagation","label":"Medium of Propagation","html_id":"medium-of-propagation","implicit":true,"key":"XIDxQGK55X"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Sound needs a medium, such as air, water, or solids, to travel. The particles in these media vibrate and transmit energy from one place to another. The speed and efficiency of sound propagation depend on the medium’s properties, especially density and elasticity. Generally, sound travels faster in materials that are more elastic and have closely packed particles.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"dCjWHwKRo3"}],"key":"p8cXXLFeaM"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Here are some examples of the ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"jTnJwwKLmN"},{"type":"link","url":"https://en.wikipedia.org/wiki/Speed_of_sound","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"speed of sound","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"hrgm3pMXkl"}],"urlSource":"https://en.wikipedia.org/wiki/Speed_of_sound","data":{"page":"Speed_of_sound","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"n7IwsHXYtk"},{"type":"text","value":" in different media:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"DaFvwHKWJb"}],"key":"LDwNDYBgTO"},{"type":"table","position":{"start":{"line":11,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"tableRow","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"tableCell","header":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Medium","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"BxEIQ949Dn"}],"key":"MXCFO95doV"},{"type":"tableCell","header":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Speed (m/s)","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"eXJcDxAXu0"}],"key":"jm2dlj5PBG"}],"key":"xbUobFrJVn"},{"type":"tableRow","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Air","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"vOWSUsR5oA"}],"key":"a1GqCdwiYk"},{"type":"tableCell","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"343","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Oa7JMVbAPd"}],"key":"mJUdQmq6Lm"}],"key":"OCdvr4w0hU"},{"type":"tableRow","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Helium","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"vKeuB8QuN8"}],"key":"ko8OBg83tP"},{"type":"tableCell","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"965","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"Q4UGgWdm9r"}],"key":"OafU0tFZXw"}],"key":"D4gK8FaJES"},{"type":"tableRow","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Water","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"UUWakKTJFN"}],"key":"FBdWIpK5zp"},{"type":"tableCell","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"1481","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"f94BRyYF5d"}],"key":"sS6sTGG21q"}],"key":"iUiFzYJn6T"},{"type":"tableRow","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Glass","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"ONhHfcMr8Z"}],"key":"xfq40tyUdA"},{"type":"tableCell","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"4540","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"vGJbwkRbWJ"}],"key":"JJkxsJ3KNV"}],"key":"yzaHGEf9gi"},{"type":"tableRow","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Iron","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"KgpZlfhiuJ"}],"key":"cECZgF0DDi"},{"type":"tableCell","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"5120","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"EBz6WdN78C"}],"key":"TD91drDEoo"}],"key":"TVj8aof6gJ"},{"type":"tableRow","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Diamond","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"TiFgepa8oI"}],"key":"Nd24Pdvy6X"},{"type":"tableCell","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"12000","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"dDRKKkYsKC"}],"key":"aU4zihXRWK"}],"key":"RNpvmojqL2"}],"key":"ummmEFaOFt"},{"type":"paragraph","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"Sound moves fastest in solids (like iron or diamond) because their particles are tightly packed and transmit vibrations efficiently. For example, you can hear a distant train by placing your ear on the rail, as sound travels much faster through metal than air.","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"n6tqCZi7wc"}],"key":"hQvUYpeqr1"},{"type":"paragraph","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Temperature, humidity, and altitude also affect the speed of sound. Warmer air or higher humidity generally increases the speed, while higher altitude (lower air density) decreases it.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"YhiYGt5Pvm"}],"key":"KRk7b6iA4N"}],"key":"IsPuyhpgDr"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Reflection, Refraction, Diffraction, and Absorption","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r3I09oemca"}],"identifier":"reflection-refraction-diffraction-and-absorption","label":"Reflection, Refraction, Diffraction, and Absorption","html_id":"reflection-refraction-diffraction-and-absorption","implicit":true,"key":"WqtvnzyJAb"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"There are four physics concepts that are important for understanding the behavior of sound in general, but also in both rooms and instruments:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tFWyJ8XUmS"}],"key":"sPqjCPRWj8"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Reflection","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"icbxbNKb2p"}],"key":"PtpPEnfbn4"},{"type":"text","value":": Sound waves bounce off surfaces, creating echoes and affecting acoustics. In a concert hall, hard walls and ceilings reflect sound, producing reverberation and echoes. Inside a guitar, sound waves reflect off the wooden body, reinforcing certain frequencies and contributing to the instrument’s tone.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IMe4eaUgN1"}],"key":"nVdj3S9oq6"}],"key":"fGeaVpyQM8"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Refraction","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"tacgwwpnRn"}],"key":"OXSWcGnUdX"},{"type":"text","value":": When sound moves between media (e.g., air to water), its speed changes, causing the wave to bend Temperature gradients in a room can cause sound waves to bend, affecting how sound travels from the stage to the audience. In wind instruments, sound waves refract as they move through air of varying temperature or humidity inside the instrument, subtly changing pitch and timbre.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ThihLINzay"}],"key":"LhHrLwsSQC"}],"key":"pS2WperVCw"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Diffraction","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"puJ9MndpjT"}],"key":"TpaUJa9730"},{"type":"text","value":": Sound waves bend around obstacles and spread out after passing through openings. Sound diffracts around furniture or pillars, allowing you to hear someone speaking even if they are not in direct line of sight. The sound from a violin’s f-holes diffracts, helping project the instrument’s sound in all directions.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"cY3M4ERRBT"}],"key":"I3tv6QzRXA"}],"key":"o2wINXi4df"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Absorption","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Lo90d6Po54"}],"key":"PhLBiMJXPC"},{"type":"text","value":": Materials absorb sound energy, reducing its intensity. Carpets, curtains, and acoustic panels absorb sound, reducing echoes and making rooms quieter. The type of wood or material used in a drum absorbs some sound energy, affecting the instrument’s resonance and sustain.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"D1G9G1FyRD"}],"key":"sDAFJXBVJl"}],"key":"bQ6MqQRXh6"}],"key":"Y7M1V5Wkwf"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"These principles shape how we experience sound in different environments, from open fields to concert halls, and influence the design and performance of musical instruments.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"lYSjIacIFM"}],"key":"Yig5gFE3Tr"},{"type":"image","url":"/sensingsoundandmusic/build/2903c0d6cc4b18f749332d7134852c4d.jpeg","alt":"reflection-refraction-copilot.jpg","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"eV9io1y3gN","urlSource":"data:image/jpeg;base64,iVBORw0KGg...lFTkSuQmCC"}],"key":"kmZ5pEWyGg"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Room Acoustics","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GMN2kx3o7p"}],"identifier":"room-acoustics","label":"Room Acoustics","html_id":"room-acoustics","implicit":true,"key":"h9YPCfwqEH"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Room acoustics explores how the physical characteristics of a space influence sound quality. The shape, size, and materials of a room affect how sound waves behave, impacting clarity, warmth, and reverberation.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"b5bxeAFj4I"}],"key":"mr4IxoGCtG"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Room Size and Shape","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"faXjTwYaNX"}],"identifier":"room-size-and-shape","label":"Room Size and Shape","html_id":"room-size-and-shape","implicit":true,"key":"AFiQI1Mqkw"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The dimensions and geometry of a room determine how sound waves reflect, interact, and form standing waves. Irregular shapes and non-parallel surfaces help minimize unwanted echoes and resonances, while rectangular rooms with parallel walls are prone to standing waves, where certain frequencies are reinforced due to repeated reflections.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"GuuitUFzHo"}],"key":"d1qNd4dG5h"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Standing waves","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"xIWCDCH0xd"}],"key":"w5wEgpx0k7"},{"type":"text","value":" form when sound waves reflect between parallel surfaces and interfere with themselves, creating regions of constructive and destructive interference. This results in certain frequencies being amplified (peaks) and others being diminished (nulls) at specific locations in the room. Standing waves are most pronounced at low frequencies and can cause uneven bass response, making some notes sound much louder or softer depending on where you stand. Treating room modes with bass traps and careful placement of speakers/listeners helps minimize these effects.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"nI6XOQuLLu"}],"key":"cih98zd4Af"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Room modes","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"rPkXNaY3fG"}],"key":"PA7dnFTOll"},{"type":"text","value":" are the specific frequencies at which standing waves occur, determined by the room’s dimensions (length, width, height). Each mode corresponds to a resonance frequency where sound energy is reinforced. Modes are categorized as axial (between two parallel surfaces), tangential (between four surfaces), and oblique (between six surfaces). Calculating room modes helps identify problematic frequencies and guides acoustic treatment to achieve a balanced sound environment.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"iFIJqczSZu"}],"key":"HmGvzHQjsW"},{"type":"exercise","children":[{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Try a ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"dmbBKLKtpu"},{"type":"link","url":"https://amcoustics.com/tools/amroc?l=300\u0026w=500\u0026h=300\u0026r60=0.6","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Room Mode Calculator","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"ugpXNPvwhu"}],"urlSource":"https://amcoustics.com/tools/amroc?l=300\u0026w=500\u0026h=300\u0026r60=0.6","key":"dZajp3G2e8"},{"type":"text","value":" to estimate the acoustic properties of a room.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"xiFnco5Tyg"}],"key":"xJPe2XQNEb"}],"label":"Room Modes","identifier":"room modes","enumerated":true,"enumerator":"4","html_id":"room-modes","key":"bfdWgmJ8pU"},{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Some you may have experienced a particular acoustic phenomenon called ","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"jOuFTDZAOt"},{"type":"emphasis","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"flutter echo","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"fGdyqmPuh6"}],"key":"c2eVwJMBiJ"},{"type":"text","value":". This is the rapid, repetitive echoes that occur between hard, parallel surfaces (such as bare walls or ceilings). When a sound wave bounces back and forth between these surfaces, it creates a series of closely spaced echoes that can sound like a “ping-pong” effect or a metallic ringing. Flutter echo is especially noticeable in empty rooms or corridors and can degrade speech intelligibility and musical clarity. Acoustic panels or diffusers are often used to break up parallel surfaces and eliminate flutter echo.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"TEOzp6Fbvd"}],"key":"ycwZ7cOEGR"},{"type":"paragraph","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"In Oslo, we have an acoustic installation at one of the entrances of the National Theatre train station based on a spectacular flutter echo.","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"LLQtgApUoy"}],"key":"fKYzhoBVif"},{"type":"image","url":"/sensingsoundandmusic/build/3b6b1a72c9c1f38f04e7445772621d9c.jpeg","alt":"Nationaltheatret-jensenius.jpg","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"LHBtQhcMbh","urlSource":"data:image/jpeg;base64,/9j/4AAQSk...42zz85/9k="}],"key":"rj0cP6TcsD"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Materials","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bnYWv5fNn8"}],"identifier":"materials","label":"Materials","html_id":"materials","implicit":true,"key":"DLXJNlSjFf"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Different construction materials play a crucial role in shaping the acoustic properties of a room:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HnNRvWePqL"}],"key":"wO6vkzpqQD"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Hard surfaces (glass, concrete, tile)","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"BfjMdoGHKq"}],"key":"Pur5BhTeaX"},{"type":"text","value":": Reflect sound waves efficiently, leading to increased reverberation and potential echoes. These surfaces can make a space sound “live” or “bright,” but may also cause unwanted reflections and clarity issues.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"lykpcU0cYc"}],"key":"xsQBbk1IT8"}],"key":"XxbPO763VJ"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Soft materials (carpet, curtains, upholstered furniture, acoustic panels)","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"NlCCC3Ybcc"}],"key":"dk3pNGeKwk"},{"type":"text","value":": Absorb sound energy, especially at mid and high frequencies, reducing reverberation and minimizing echoes. These materials help create a “dry” or “warm” acoustic environment, improving speech intelligibility and musical detail.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"yDlNa510KM"}],"key":"FyoK2kLjUE"}],"key":"GqADankQ4O"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Porous materials (foam, mineral wool, fiberglass)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TjX5K9Grlb"}],"key":"f7zDUJzLH8"},{"type":"text","value":": Highly effective at absorbing sound, particularly at higher frequencies. Used in acoustic panels and bass traps to control reflections and room modes.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"l4DtyIwqWd"}],"key":"BWeHtEOjiJ"}],"key":"Vh0xHQJbPd"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Dense materials (brick, stone, thick wood)","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"AV7W9BjFAI"}],"key":"RXm5Nj7pK7"},{"type":"text","value":": Reflect low-frequency sound waves and can help contain sound within a space, but may also contribute to standing waves and bass buildup.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"V9Al6anPgF"}],"key":"Rumgl6kX0Y"}],"key":"fxwXTQNT0s"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Diffusive surfaces (bookshelves, irregular walls, specialized diffusers)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"mDdhPwKXfC"}],"key":"b4cOrOtc0f"},{"type":"text","value":": Scatter sound waves in multiple directions, breaking up strong reflections and preventing flutter echoes. Diffusion improves clarity and creates a more balanced listening environment.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"quqLhFglQM"}],"key":"djTUtuRvxh"}],"key":"MRqhUQBQYy"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Windows and doors","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"AWoC8ZkJf4"}],"key":"zppB0NSWn7"},{"type":"text","value":": Can transmit sound between rooms, affecting isolation and privacy. Double glazing and solid-core doors help reduce sound transmission.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"VAhvCd8qIP"}],"key":"AZiubbMJc3"}],"key":"FeDfW1vqkt"}],"key":"fxbjkLYFve"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"The combination of these materials determine the overall acoustic character of a room.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"nXVBmXWuMA"}],"key":"KNAKhLZFkx"},{"type":"heading","depth":3,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Acoustic Treatment","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"qMY0l8EiZJ"}],"identifier":"acoustic-treatment","label":"Acoustic Treatment","html_id":"acoustic-treatment","implicit":true,"key":"Sftd3n99SX"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"The shape, size, and construction of a room are difficult to change after it has","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"i3CDxypRy3"}],"key":"t7Ta6FRTRJ"},{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"The above Effective acoustic treatment involves a combination of absorption, diffusion, and strategic placement of materials to optimize sound quality in a room:","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"NmdL1ORKyl"}],"key":"LJaVPp50vX"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":20,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"Absorptive Panels","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"hm4OMyEjUS"}],"key":"hiEcpCaN2w"},{"type":"text","value":": Typically made from foam, fiberglass, or mineral wool, these panels are mounted on walls or ceilings to absorb mid and high frequencies. They help reduce reflections, reverberation, and flutter echoes, making speech and music clearer.","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"tJNmynrYnv"}],"key":"Bbxo1iJYUw"}],"key":"l2w6GWACEQ"},{"type":"listItem","spread":true,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Bass Traps","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"Bjl79NZi9W"}],"key":"ANI4avUXbb"},{"type":"text","value":": Specialized absorbers placed in corners or along walls to target low-frequency energy. Bass traps help control room modes and prevent bass buildup, which can cause uneven sound and “boomy” bass.","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"RE59bigazn"}],"key":"bCspV3pPHt"}],"key":"ew6rn9HQre"},{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Diffusers","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"AdLJhyIWwS"}],"key":"qL73ech5Ka"},{"type":"text","value":": Unlike absorbers, diffusers scatter sound waves in multiple directions. They are often made from wood or plastic and have irregular surfaces or patterns. Diffusers break up strong reflections and standing waves, preserving a sense of spaciousness and natural ambience.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"ARqmsixWJI"}],"key":"hcSmRSludE"}],"key":"cAImWxiO9u"},{"type":"listItem","spread":true,"position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"Ceiling Clouds","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"bwRPgyZonM"}],"key":"IcGGDeuJhg"},{"type":"text","value":": Suspended panels above listening or performance areas absorb sound from above, reducing ceiling reflections and improving overall clarity.","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"xpmfxk2Pbp"}],"key":"LgsjxJVDCc"}],"key":"B4s66rpPvl"},{"type":"listItem","spread":true,"position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"Furniture Arrangement","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"TTftBaBCv6"}],"key":"pg1wtiYMbq"},{"type":"text","value":": Placing bookshelves, couches, and other furnishings strategically can help break up sound reflections and add both absorption and diffusion. Soft furniture absorbs sound, while irregular surfaces diffuse it.","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"LGsc05DjCR"}],"key":"kWreOTB4ve"}],"key":"TndN0h2cNs"},{"type":"listItem","spread":true,"position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Door and Window Seals","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"KprkthxdXX"}],"key":"ZgEkb8Un5v"},{"type":"text","value":": Adding seals or heavy curtains to doors and windows improves sound isolation, preventing unwanted noise from entering or leaving the room.","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"vvNydiddXA"}],"key":"dKg7fdDwlP"}],"key":"DwGHTEebge"},{"type":"listItem","spread":true,"position":{"start":{"line":26,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"Acoustic Curtains and Rugs","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"bGEVHwq84L"}],"key":"UN1sN3U2t2"},{"type":"text","value":": Thick curtains and rugs add absorption, especially in spaces with many hard surfaces, helping to tame excessive reverberation.","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"Eidqaauenq"}],"key":"sRscfMvqbG"}],"key":"Ampl8REZjn"}],"key":"D6kZ2M6zwb"},{"type":"paragraph","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"A balanced approach using both absorption and diffusion creates a room that is neither too “dead” nor too “live,” supporting accurate sound reproduction and comfortable listening.","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"pFdFgN8Q0m"}],"key":"wkipzJX1Tl"},{"type":"exercise","children":[{"type":"paragraph","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"Think about the acoustics of the room you are in. What are the key defining properties of the room? How can you improve it?","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"dnVH8iKk1S"}],"key":"nqeBvBwaPz"}],"label":"Improving room acoustics","identifier":"improving room acoustics","enumerated":true,"enumerator":"5","html_id":"improving-room-acoustics","key":"hizlurNwLO"}],"key":"o1zbvRXJlV"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Reverberation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WG1w2nnFVQ"}],"identifier":"reverberation","label":"Reverberation","html_id":"reverberation","implicit":true,"key":"CMBaTOIiMs"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Reverberation","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Reverberation","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"zsHMmJg3gs"}],"urlSource":"https://en.wikipedia.org/wiki/Reverberation","data":{"page":"Reverberation","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"IA5tkmElxX"}],"key":"xDuk9MJ5iB"},{"type":"text","value":" is one of the most defining acoustic properties of a room. It can be defined as the persistence of sound in a space after the original sound source has stopped, caused by reflections from surfaces such as walls, ceilings, and floors.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tghNUmwpsb"}],"key":"YUHJhyLdqF"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Acousticians often calculate reverberation time based on the concept ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VE5OspEbpT"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"T60","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nPaiePngmk"}],"key":"bnQvnS6fRk"},{"type":"text","value":", which is defined as the time it takes for sound to decay by 60 dB after the source stops. The optimal reverberation time depends on the room’s purpose and the type of music or activity. Spaces designed for speech, such as lecture halls, benefit from shorter reverberation times, while concert halls for symphonic music often require longer reverberation for a fuller sound.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"UOMLHKIbT6"}],"key":"d3KzgRCDh1"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Short T60 (0.5–1 s)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"owOQkGU2c6"}],"key":"byqb8El4vR"},{"type":"text","value":": Ideal for speech and clarity, minimizing echoes and enhancing intelligibility.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"xWyfjX5W9i"}],"key":"PJ0JWAC7tZ"}],"key":"gVHcnkywhY"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Moderate T60 (1.5–2 s)","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"nR5gTqOI9U"}],"key":"vCPOJbtcQB"},{"type":"text","value":": Suitable for chamber music, balancing clarity and warmth.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"yPQOsEPzGy"}],"key":"LRvfjBlhNM"}],"key":"UR2av4yh7P"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Long T60 (2–3 s)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ZI0O1MOmaG"}],"key":"CNsw9dlWaO"},{"type":"text","value":": Preferred for orchestral and choral music, creating a rich and immersive sound.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"FGXiqoK7i0"}],"key":"mGNTUgyPfc"}],"key":"kYdWWhrihg"}],"key":"G72RuVz2VJ"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Understanding and controlling reverberation is essential for creating spaces with desirable acoustic properties, whether for recording studios, concert halls, or home listening rooms. Proper acoustic design ensures clarity, warmth, and an enjoyable listening experience.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ZKhEXP16By"}],"key":"BZMD6hgrV0"}],"key":"fxFOGjny2x"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Simulate a simple exponential decay to illustrate T60 reverberation time\ninitial_amplitude = 1.0\nt = np.linspace(0, 3, 1000)  # 3 seconds duration\n\n# T60 is the time for amplitude to decay by 60 dB (factor of 1/1000)\nT60 = 2.0  # seconds (example value)\ndecay_curve = initial_amplitude * np.exp(-t * np.log(1000) / T60)\n\nplt.figure(figsize=(12, 4))\nplt.plot(t, decay_curve, label='Reverberation Decay')\nplt.axhline(initial_amplitude / 1000, color='red', linestyle='--', label='-60 dB Level')\nplt.title('Simulated Reverberation Decay (T60)')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.legend()\nplt.grid()\nplt.show()","visibility":"hide","key":"unwjFLqc33"},{"type":"output","id":"f5QqUueG2BTyn2KwUlfWQ","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"5ce7e94e55507f22f16555ebc448eea3","path":"/sensingsoundandmusic/build/5ce7e94e55507f22f16555ebc448eea3.png"},"text/plain":{"content":"\u003cFigure size 1200x400 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"RgBNPgNNY8"}],"visibility":"show","key":"F1fORdidGm"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Instrument acoustics","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qSoqrT3VCI"}],"identifier":"instrument-acoustics","label":"Instrument acoustics","html_id":"instrument-acoustics","implicit":true,"key":"wxMQ3a3yJW"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Room acoustics is a big field of study and there are numerous jobs for people working with both constructing and modifying rooms in buildings. There are much fewer people focusing on instrument acoustics. While the scale is smaller, most of the same principles apply to instruments, investigating how musical instruments generate, shape, and radiate sound.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"p7c2UytdNu"}],"key":"tsjy9PWzRj"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Principles of instrument acoustics","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"cFaT3tY7bZ"}],"identifier":"principles-of-instrument-acoustics","label":"Principles of instrument acoustics","html_id":"principles-of-instrument-acoustics","implicit":true,"key":"tcByO8oi9Y"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The main physical principles of instrument acoustics include the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ddGmdDcP5I"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"vibration source","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"xCdnQZ6wMZ"}],"key":"C3tkxacKo1"},{"type":"text","value":" and the instrument’s ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"m5SQdWFjMZ"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"resonance","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"UhEDA9kyGM"}],"key":"kO8RHgyQVS"},{"type":"text","value":" The initial sound is produced by vibrating elements such as strings (guitar, violin), air columns (flute, trumpet), membranes (drum), or solid bodies (xylophone). Most instruments have resonating bodies (soundboards, tubes, shells) that amplify and color the sound. The shape, size, and material of these bodies determine the instrument’s timbre and loudness.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ExYGWv56ry"}],"key":"ppWNAnnNbx"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"The vibration source heavily influences the ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"EUVp0Re06t"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"frequency range","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"bguCF4JC7N"}],"key":"VQ8qz223FE"},{"type":"text","value":" of the instrument. Each instrument has a characteristic range of frequencies it can produce, determined by its physical dimensions and construction.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"D8vQqbM0b9"}],"key":"us5M6QCjWI"},{"type":"image","url":"/sensingsoundandmusic/build/ed1ed0d73a498645bbe0ac5d074b8ceb.jpeg","alt":"Fundamentals of Instrument Acoustics","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"YlblbRjt93","urlSource":"http://www.sebastianmerchel.de/Projects/Tactile%20Touchscreen/Pictures/fundamentels_instruments_big.jpg"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Figure: Fundamentals of Instrument Acoustics (","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"jrrUezhtFr"},{"type":"link","url":"http://www.sebastianmerchel.de/","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Credit: Sebastian Merchel","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"zOBzHtZC9U"}],"urlSource":"http://www.sebastianmerchel.de/","key":"O0rJf1AXEI"},{"type":"text","value":").","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"mUjwabwG4F"}],"key":"Yh0Ev5skUp"}],"key":"sry6kVfaQ5"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"The resonance in the instrument is important for its ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"yrid33IlkC"},{"type":"emphasis","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"timbre","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"XA9fKqnXbm"}],"key":"jlvvyVpNZE"},{"type":"text","value":" based on its partials and overtones. Instruments rarely produce pure tones; instead, they generate complex waves with multiple harmonics. The relative strength of these harmonics defines the instrument’s unique sound.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"JZzMsLRGdq"}],"key":"z8eKbNIMoC"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"An instrument’s ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"U5f08P6m0A"},{"type":"emphasis","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"radiation pattern","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"tphjn5RKe1"}],"key":"STX5IdXm5S"},{"type":"text","value":" is based on the way sound is projected into the surrounding space depends on the instrument’s geometry and playing technique.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"Z4n8BSOd4C"}],"key":"Gsd4LZYNRR"},{"type":"grid","columns":[1,1,2,3],"children":[{"type":"card","children":[{"type":"header","children":[{"type":"paragraph","children":[{"type":"text","value":"String instruments","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"ku8PVqHOn9"}],"key":"aE5j8ROhYe"}],"key":"JcVw3oL5aq"},{"type":"paragraph","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"When a string is plucked or bowed, it vibrates at its fundamental frequency and produces harmonics. The body of the instrument (such as a guitar or violin) amplifies these vibrations and shapes the sound. The material and construction of the body affect the instrument’s tone and projection.","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"GaG4VZuZ7g"}],"key":"bI49exyoYM"}],"key":"RaSTBvG9ZH"},{"type":"card","children":[{"type":"header","children":[{"type":"paragraph","children":[{"type":"text","value":"Wind instruments","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"hvSaHU3zxH"}],"key":"gPAn18XJoq"}],"key":"FU3E3FWNMM"},{"type":"paragraph","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Wind instruments produce sound by vibrating air columns. The length, shape, and material of the tube determine the pitch and timbre. Opening and closing holes changes the effective length of the air column, allowing different notes to be played.","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"uXaNxQEYnp"}],"key":"iCwt5xgSVN"}],"key":"Ol3UeB3ypk"},{"type":"card","children":[{"type":"header","children":[{"type":"paragraph","children":[{"type":"text","value":"Percussion instruments","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"xraXeuQygy"}],"key":"Z9ppSs7p4s"}],"key":"lfxSOHj4oG"},{"type":"paragraph","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Percussion instruments generate sound through striking, shaking, or scraping. The vibration of membranes (drums) or solid bodies (bells, xylophones) creates complex waveforms. The size, tension, and material of the vibrating surface influence the pitch and timbre.","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"QmL2rQ4c8G"}],"key":"P8UoXMQhwV"}],"key":"L8tiKIZMRV"}],"key":"lhG45aEmqd"},{"type":"heading","depth":3,"position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"Organology","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"epI4zo137Q"}],"identifier":"organology","label":"Organology","html_id":"organology","implicit":true,"key":"KxXrwNnVg1"},{"type":"paragraph","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"In addition to acousticians, there is an academic field focused on the study of musical instruments: ","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"V3n42RxnyA"},{"type":"emphasis","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Organology","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"organology","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"AmaL5Hs4Er"}],"urlSource":"https://en.wikipedia.org/wiki/Organology","data":{"page":"Organology","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"nj6jP3mL97"}],"key":"bTlZx5vae7"},{"type":"text","value":". This was developed by (ethno)musicologists and researchers working in instrument museums in the late 19th and early 20th century, based on the need to organize large collections of instruments.","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"uKgcanpGh0"}],"key":"wfcPQabuIM"},{"type":"paragraph","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"The most famous organological system is the ","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"MZc3iiuaKU"},{"type":"link","url":"https://en.wikipedia.org/wiki/Hornbostel%E2%80%93Sachs","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"Hornbostel–Sachs System","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"UHgnErmRvu"}],"urlSource":"https://en.wikipedia.org/wiki/Hornbostel%E2%80%93Sachs","data":{"page":"Hornbostel%E2%80%93Sachs","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"FZr9YjfcMm"},{"type":"text","value":", which classifies instruments based on how they produce sound. The main categories are:","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"qsINVmFO6y"}],"key":"teh9sjelJG"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":46,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"Idiophones","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"uZQy6kVGPN"}],"key":"XvYP2VmoSF"},{"type":"text","value":": Instruments that produce sound primarily by the vibration of their own material, without strings, membranes, or external air columns. Examples include xylophones, cymbals, and bells.","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"JdlZp3b5Xk"}],"key":"XzTeWTPGOa"}],"key":"MjTEGMtRM1"},{"type":"listItem","spread":true,"position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"Membranophones","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"oPSRTUO5Im"}],"key":"ROjFUnY6vS"},{"type":"text","value":": Instruments that produce sound by vibrating a stretched membrane. Drums are the most common example, where the membrane is struck, rubbed, or otherwise excited.","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"KvWJijk4RW"}],"key":"x3VUuajfmz"}],"key":"Hm8AKMQNSA"},{"type":"listItem","spread":true,"position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Chordophones","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"CZVcyX2owA"}],"key":"n23uefewHk"},{"type":"text","value":": Instruments that produce sound by vibrating strings stretched between fixed points. This group includes violins, guitars, harps, and pianos.","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"G8xpiqAdXb"}],"key":"GHsZ6IYMHW"}],"key":"x6YsfNSuU3"},{"type":"listItem","spread":true,"position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Aerophones","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"YkJUx6zFvo"}],"key":"kcE4lh8Ooj"},{"type":"text","value":": Instruments that produce sound by vibrating columns of air. Examples are flutes, trumpets, saxophones, and pipe organs.","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"r1ajoi43DJ"}],"key":"TOLpmsYUDb"}],"key":"thxsqJ1uIW"},{"type":"listItem","spread":true,"position":{"start":{"line":50,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"children":[{"type":"text","value":"Electrophones","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"fUsUvF84xg"}],"key":"tdy8Q5xB4S"},{"type":"text","value":": Instruments that produce sound primarily through electrical means. This includes synthesizers, electric guitars (when amplified), and theremins.","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"cep7XvW8HD"}],"key":"hURLpHi2XB"}],"key":"PbYpMeVSMk"}],"key":"VfgacfeVOk"},{"type":"paragraph","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"Each category can be further subdivided based on how the sound is initiated (struck, plucked, bowed, blown, etc.), the construction of the instrument, and its acoustic properties. Although not entirely similar,  Disney made an interesting animation film called ","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"G4U4ps7jXn"},{"type":"emphasis","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"Toot Whistle Plunk and Boom","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"drjApWNynM"}],"key":"fFCuTJnQOU"},{"type":"text","value":" in 1953 that shows differences between instruments:","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"zMKK2gEkWI"}],"key":"jl77CSGCKy"},{"type":"iframe","src":"https://www.youtube.com/embed/8iVf0pPHvjc?si=Q7N2xX4m8J1x2ZEL","width":"100%","key":"XWntQ5kqbs"}],"key":"k1cP4llxp4"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Electro-Acoustics","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FCSlLfolM4"}],"identifier":"electro-acoustics","label":"Electro-Acoustics","html_id":"electro-acoustics","implicit":true,"key":"rEVTsAaLTT"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Electro-Acoustics\" refers to the field of study and technology that deals with the conversion between electrical signals and sound waves. It encompasses the design, analysis, and application of devices that perform this conversion, such as microphones, loudspeakers, headphones, and hearing aids. This field combines principles from acoustics (the science of sound) and electronics to create systems that enable sound recording, reproduction, and transmission.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"JTeaqNDv2C"}],"key":"hEhg3tjmKa"}],"key":"yTSxKTPCUD"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Microphones","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vrUGEf008l"}],"identifier":"microphones","label":"Microphones","html_id":"microphones","implicit":true,"key":"WeCO0Pa0vB"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Microphones are devices that convert sound waves into electrical signals. They are categorized by their design and working principles. The three main types are:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"lY3ZH2Wy4B"}],"key":"oMphIRFPIc"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Microphone#Dynamic","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Dynamic microphones","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"DXItvUk0Ri"}],"urlSource":"https://en.wikipedia.org/wiki/Microphone#Dynamic","data":{"page":"Microphone#Dynamic","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"K57hWbNQsP"}],"key":"if7BpSZVnj"},{"type":"text","value":" use a diaphragm attached to a coil of wire, which is placed within a magnetic field. When sound waves hit the diaphragm, it moves the coil, generating an electrical signal through electromagnetic induction. These microphones are known for their durability and ability to handle high sound pressure levels, making them ideal for live performances and situations where robustness is required.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"FwdXIOdtAM"}],"key":"VJ1TOb8u7l"}],"key":"pSXAYh1Nrc"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Microphone#Condenser","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Condenser microphones","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"F3ihkD1QWp"}],"urlSource":"https://en.wikipedia.org/wiki/Microphone#Condenser","data":{"page":"Microphone#Condenser","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"YVDTxzDPGt"}],"key":"ciIGR7Zmhm"},{"type":"text","value":" operate using a diaphragm positioned close to a charged backplate, together forming a capacitor. Sound waves cause the diaphragm to move, changing the distance between the diaphragm and backplate, which alters the capacitance and produces an electrical signal. This design makes condenser microphones highly sensitive and capable of capturing subtle details, making them well-suited for studio recordings and applications requiring high fidelity.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"NZkjDcvu03"}],"key":"TWqinNPeCS"}],"key":"wAhOzqjvnT"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Contact_microphone","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Contact microphones","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"T1E5W87Uaw"}],"urlSource":"https://en.wikipedia.org/wiki/Contact_microphone","data":{"page":"Contact_microphone","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"hWfNTC1UgS"}],"key":"HVdULH19EF"},{"type":"text","value":" detect vibrations directly from solid surfaces rather than from the air. They often use piezoelectric materials to convert these vibrations into electrical signals. This type of microphone is commonly used for amplifying acoustic instruments such as violins or guitars, as it can pick up the vibrations from the instrument’s body, providing a unique perspective on the sound.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"XT4Q1cpS0f"}],"key":"wS8WWu9gUB"}],"key":"nQu2HuxxE4"}],"key":"auKyB1THKk"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"In her exploreation of microphones as instruments, Cathy van Eck calls microphones for “softhearers” as a parallel to loudspeakers.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"YRQZLWxfd2"}],"key":"x73QnpT4Wq"}],"key":"Av7ClpkT9G"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Loudspeakers","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tBcTj3domi"}],"identifier":"loudspeakers","label":"Loudspeakers","html_id":"loudspeakers","implicit":true,"key":"QbRGCLQI0E"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Loudspeakers (or perhaps only speakers) are devices that convert electrical signals into sound waves. They come in various types based on their application and design:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"APA9mEL6dj"}],"key":"qqULqIvgAZ"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Standard Speakers","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"xhpuET9czy"}],"key":"bneFEc0qWX"},{"type":"text","value":" are used in audio systems for general sound reproduction. They employ a diaphragm (cone) driven by an electromagnet to produce sound and are designed to cover a wide range of frequencies, making them suitable for most listening environments.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"sGHyJ7xLuz"}],"key":"SH50pHFjD9"}],"key":"BOE6SHqfwi"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Headphones","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"WYyAz2IJTs"}],"key":"XNoSmXknky"},{"type":"text","value":" are miniature speakers worn on, around, or in the ears. All headphones feature passive noise cancelling by design (since they cover the ears), but there are also different types of active noise cancelling.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"OKgvbMDD22"}],"key":"EsAQ72JH65"}],"key":"QkWVi2og7B"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Actuators","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"mfZDeqd6uC"}],"key":"rKgu5wUmlX"},{"type":"text","value":" are devices that create vibrations, typically in solid objects. The vibrations are typically not audible by itself, it is the resonances in the objects excited by the actuator that produces the sound. They are used in haptic feedback systems or to turn surfaces, such as tables or windows, into speakers. They are also used in ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"DGMyBgkU94"},{"type":"link","url":"https://en.wikipedia.org/wiki/Bone_conduction","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"bone-conducting headsets","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"SAl4nA1AEI"}],"urlSource":"https://en.wikipedia.org/wiki/Bone_conduction","data":{"page":"Bone_conduction","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"Hh4lbsUsm3"},{"type":"text","value":".","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"fuHMmVYRGb"}],"key":"oPBBIZTRJ4"}],"key":"JAC0MwGWnN"}],"key":"RY1PMIkzX5"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"QQ6oYPJ04j"}],"key":"fiPg4gbmrX"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Did you know that ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"E2n04RpVa6"},{"type":"link","url":"https://en.wikipedia.org/wiki/Active_noise_control","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"active noise cancelling","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"kks8s63AgW"}],"urlSource":"https://en.wikipedia.org/wiki/Active_noise_control","data":{"page":"Active_noise_control","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"luwc3OHXYa"},{"type":"text","value":" is based on inverting the phase of the sound signal?","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"qk5NdoAt6K"}],"key":"sf3PqsD8ed"},{"type":"image","url":"/sensingsoundandmusic/build/3bcbe4c974c9ecb83317cb191118e8af.svg","alt":"Noise cancelling","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"Umg5MnFy7E","urlSource":"https://upload.wikimedia.org/wikipedia/commons/7/7d/Active_Noise_Reduction.svg"}],"key":"ak1Fjd3Ge2"}],"key":"N0biEj2D9T"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Signal processing","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xIjZNmbgJB"}],"identifier":"signal-processing","label":"Signal processing","html_id":"signal-processing","implicit":true,"key":"TZVlliMs1k"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Signal processing is the field concerned with analyzing, modifying, and synthesizing signals such as sound, images, and scientific measurements. In acoustics and audio engineering, signal processing is essential for improving sound quality, extracting information, and adapting audio for specific applications.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Ane4kS4iy8"}],"key":"KJBI6ityMx"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Signal processing can be done in both the analog and digital domain. Key aspects of signal processing in audio include:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"f9emuxdC08"}],"key":"NR0HxeKEP9"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Amplification","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"YLUyYaUsnT"}],"key":"s1B9VpTCdF"},{"type":"text","value":": Increasing the strength of electrical signals so they can drive loudspeakers or be recorded at usable levels.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"GIVYW8kE2n"}],"key":"TkY2RuStHA"}],"key":"Q5Zycvl8p3"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Filtering","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"RZx38KyQQG"}],"key":"weumDd1y5j"},{"type":"text","value":": Removing unwanted frequencies (such as noise or hum) or enhancing desired frequency ranges. Filters can be low-pass, high-pass, band-pass, or notch filters, each serving different purposes.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"tU7dC84Y2T"}],"key":"h37D0pM6yG"}],"key":"ZynXMgTelM"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Equalization (EQ)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"SDJu6z7Pgn"}],"key":"ASYTiGTmlL"},{"type":"text","value":": Adjusting the balance between frequency components to shape the tonal quality of audio signals.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"jG0OaCRcW5"}],"key":"grKdeVtRbM"}],"key":"fincGJ8Pbo"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Dynamic Range Compression","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"UnbYE0ZoA0"}],"key":"RksM9vZYgD"},{"type":"text","value":": Reducing the difference between the loudest and quietest parts of a signal to make audio more consistent and prevent distortion.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"wO0otAwyDd"}],"key":"rxCl3xl8GK"}],"key":"OL51xIzHnr"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Noise Reduction","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"wOuCkWAO6W"}],"key":"OrWimmvClH"},{"type":"text","value":": Techniques such as gating, spectral subtraction, or adaptive filtering to minimize background noise.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ekRL0Vlclg"}],"key":"gJJiLGAw4S"}],"key":"mLSisMbYJw"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Effects Processing","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"WZBj7sHvMh"}],"key":"PLrjHHccHn"},{"type":"text","value":": Adding reverberation, delay, chorus, distortion, or other effects to enhance or creatively alter the sound.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"jPDMZdOnDL"}],"key":"vXYjoWSuxn"}],"key":"B4p4pAcWvb"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Modulation","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"k2xw4rAMZf"}],"key":"meXFJiExeq"},{"type":"text","value":": Changing aspects of the signal such as amplitude, frequency, or phase for transmission or synthesis.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"fvUesUGxE9"}],"key":"Rft5aLDtqf"}],"key":"s4Qfjqd9gJ"}],"key":"IczqLSoXlT"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Signal processing is used in microphones, mixing consoles, audio interfaces, hearing aids, mobile devices, and music production software. It enables clear communication, high-fidelity music reproduction, and creative sound design. In the following, we will briefly look into digital sound.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"lr3qWeyor3"}],"key":"bMyRIBWMoR"}],"key":"Tjr5iBzZl3"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Digital audio","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XuhvTK5m4v"}],"identifier":"digital-audio","label":"Digital audio","html_id":"digital-audio","implicit":true,"key":"dZEVY6t6oP"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Digital audio is a huge field, so here we will only be able to scratch the surface.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"SKcZoVma1V"}],"key":"BcVqTX7Yo3"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Sound vs audio","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"HLgyfGslXQ"}],"identifier":"sound-vs-audio","label":"Sound vs audio","html_id":"sound-vs-audio","implicit":true,"key":"dco4KM6VKk"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"It is important to understand the difference between ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"sgbH4NvW7m"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"sound","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"plEXN2kCvU"}],"key":"QaKshwkLQb"},{"type":"text","value":" and ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"AeNTQqxNzu"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"audio","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"brtLXH5Etf"}],"key":"c3KFcgdNyo"},{"type":"text","value":". Sound refers to vibrations traveling through materials, while audio is the technology or electrical representation used to capture, store, and reproduce those vibrations. Audio can exist in both analog and digital forms, such as LPs, cassettes, or digital files, and serves as the intermediary between devices like microphones and speakers. The distinction is similar to that between light (a physical phenomenon) and video (its recorded representation).","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"VL0XGmwoES"}],"key":"djEPEPsBj2"},{"type":"heading","depth":3,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Digitization","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"tcpnLwsih5"}],"identifier":"digitization","label":"Digitization","html_id":"digitization","implicit":true,"key":"IybXFsZR65"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Digitization","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"V5HuAucR0a"}],"key":"ZlNV3ub0RJ"},{"type":"text","value":" is the process of converting physical sound to digital audio signals using an ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"taFHCkIV4t"},{"type":"link","url":"https://en.wikipedia.org/wiki/Analog-to-digital_converter","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Analog-to-Digital Converter","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"QEt48i2hcZ"}],"urlSource":"https://en.wikipedia.org/wiki/Analog-to-digital_converter","data":{"page":"Analog-to-digital_converter","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"TTWYkJxurb"},{"type":"text","value":" (ADC). This involves two main steps: ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Xf6KwOCRhp"},{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"sampling","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"RKdbtqPmOg"}],"key":"HK58xWKYgb"},{"type":"text","value":" and ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"jSVvzrvtvH"},{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"quantization","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ySj8Fk8g8S"}],"key":"ufifilnZc8"},{"type":"text","value":".","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"zMZHKScchd"}],"key":"i4MVfBw2gm"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"First, the continuous sound wave is measured at regular intervals (samples per second), known as the ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"nxzDzHA97v"},{"type":"emphasis","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"sampling rate","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"WozEnb9gXJ"}],"key":"SGl5Q73yuf"},{"type":"text","value":" (SR). Next, each sampled value is rounded to the nearest value that can be represented by a fixed number of bits (the ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"P90zTSCUx5"},{"type":"emphasis","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"bit depth","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"XENVcSeczE"}],"key":"JoTflGpdmt"},{"type":"text","value":"). Higher bit depths allow for more precise representation of amplitude, resulting in higher audio quality and lower quantization noise. The result is a stream of numbers that can be stored, processed, and transmitted by computers and digital devices.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"fAkDItKygw"}],"key":"u7Nj2aywJa"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Below is a visualization of how a continuous sound wave (such as a sine wave or white noise) is sampled and quantized. The blue curve represents the original continuous wave. The red dots show the sampled points at a specific sampling rate. Quantization further rounds these sampled values to discrete levels, determined by the bit depth.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"dEiRBrb5Yr"}],"key":"PT9vsPvjBj"}],"key":"p70yGu06I3"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define parameters for the sine wave\nfrequency = 1  # Frequency in Hz\namplitude = 1  # Amplitude of the sine wave\nsampling_rates = [5, 10, 20, 50]  # Different sampling rates in Hz\n\n# Generate the continuous sine wave\ncontinuous_wave = amplitude * np.sin(2 * np.pi * frequency * x)\n\n# Create the figure\nplt.figure(figsize=(12, 2))\n\n# Plot the continuous sine wave\nplt.plot(x, continuous_wave, label='Continuous Sine Wave', color='blue', alpha=0.7)\n\n# Plot sampled points for each sampling rate\nfor i, rate in enumerate(sampling_rates):\n    sampled_x = np.linspace(0, 2 * np.pi, rate, endpoint=False)\n    sampled_wave = amplitude * np.sin(2 * np.pi * frequency * sampled_x)\n    plt.scatter(sampled_x, sampled_wave, label=f'Sampled Points (Rate = {rate} Hz)', zorder=5)\n\nplt.title('Effect of Different Sampling Rates on a Sine Tone')\nplt.xlabel('x')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\nplt.show()","visibility":"hide","key":"yWjUbcWfwj"},{"type":"output","id":"7FKXlks_BsWyOnsZWSnsP","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"6394021662f952dbbcb87b55067e4c16","path":"/sensingsoundandmusic/build/6394021662f952dbbcb87b55067e4c16.png"},"text/plain":{"content":"\u003cFigure size 1200x200 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"kFeRyL7B0V"}],"visibility":"show","key":"SYF4YkbVEl"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Sampling rate","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qVEdGwXGlX"}],"identifier":"sampling-rate","label":"Sampling rate","html_id":"sampling-rate","implicit":true,"key":"p5wk3VVIdJ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The sampling rate is the number of samples per second taken from a continuous signal to create a discrete signal. According to the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WjkZqhY3SO"},{"type":"link","url":"https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Nyquist–Shannon sampling theorem","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"W70iDj41ZZ"}],"urlSource":"https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem","data":{"page":"Nyquist%E2%80%93Shannon_sampling_theorem","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"ivT5GXYvfu"},{"type":"text","value":", the sampling rate must be at least twice the highest frequency present in the signal to accurately reconstruct it. This minimum rate is known as the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"YJrwJJg3UI"},{"type":"link","url":"https://en.wikipedia.org/wiki/Nyquist_frequency","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Nyquist Frequency","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TH6cqyaWgL"}],"urlSource":"https://en.wikipedia.org/wiki/Nyquist_frequency","data":{"page":"Nyquist_frequency","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"nv22YXfoBF"},{"type":"text","value":". When the CD was introduced, it was decided that it should have a sampling rate of 44,100 Hz, which can capture frequencies up to 22,050 Hz. As we shall see next week, this is sufficient to cover all humanly audible sounds.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"iAIDgfaojw"}],"key":"swiIdG45eE"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Nowadays, it is often common to have much higher sampling rates, such as 96 kHz and 192 kHz. This is far beyond human hearing, but there are several benefits in audio processing:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ucx5add4Xa"}],"key":"GuOw5jAqmx"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Extended Frequency Response","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"R8NUnvBmKy"}],"key":"HC00j2SZLO"},{"type":"text","value":": While humans cannot hear frequencies above ~20 kHz, higher sampling rates allow for accurate recording and reproduction of ultrasonic content, which can affect the audible range through nonlinear processing or analog equipment.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ULvWFRc0NT"}],"key":"cgozUdPlJJ"}],"key":"fXtKxjwDSY"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Reduced Aliasing","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"mV9g8sxZkH"}],"key":"yrWnwtMVRZ"},{"type":"text","value":": Aliasing is distortion caused when high-frequency signals are misrepresented as lower frequencies. Higher sampling rates push the aliasing artifacts further above the audible range, making them easier to filter out.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"EN5h4tiayg"}],"key":"Z9Nx9AWv60"}],"key":"kgFPU0KAGY"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Improved Phase Accuracy","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"yjkXJzp6Q6"}],"key":"Ow0M6vMdsf"},{"type":"text","value":": Digital filters and processing algorithms can operate with greater precision at higher sampling rates, resulting in more accurate phase response and less pre-ringing or artifacts.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Vmuo7jhGGD"}],"key":"r6YrxuXXsp"}],"key":"PgwlxY5cej"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Better Headroom for Processing","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"W0qoeSEKPA"}],"key":"QdcmRcrYrD"},{"type":"text","value":": Audio editing, mixing, and effects (such as pitch shifting or time stretching) can be performed with fewer artifacts and greater fidelity at higher sampling rates.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"MVA8Rws5MZ"}],"key":"Xjavke2Lnj"}],"key":"rJHMi18Ow4"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Archival and Mastering Quality","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"qFhbAIOuW8"}],"key":"ioUw0jWyHq"},{"type":"text","value":": Recording at higher rates preserves more information for future remastering or conversion to other formats, ensuring the highest possible quality.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"SeW9UmJ41R"}],"key":"Ygrr7g68r3"}],"key":"VwuGAG7WMy"}],"key":"G0m015JEO6"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"However, higher sampling rates also result in larger file sizes and increased CPU usage, so they are typically used in professional recording, mixing, and mastering environments rather than for consumer playback.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"hfzYUb65zM"}],"key":"h1N7A12whC"}],"key":"QHGJgnEvTo"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Bit depth","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"D2Fv97AjE3"}],"identifier":"bit-depth","label":"Bit depth","html_id":"bit-depth","implicit":true,"key":"wnVnv6uQQJ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WDi5SSVyzR"},{"type":"link","url":"https://en.wikipedia.org/wiki/Audio_bit_depth","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"audio bit depth","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gSNBBLXwM1"}],"urlSource":"https://en.wikipedia.org/wiki/Audio_bit_depth","data":{"page":"Audio_bit_depth","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"MlDSkEMJ1k"},{"type":"text","value":" is the amount of data used to represent each individual sample in a digital audio signal. Bit depth determines the “resolution” or precision of the amplitude values that can be stored. Higher bit depths allow for more accurate representation of the original sound, resulting in lower quantization noise and a greater dynamic range.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FTk97Po42U"}],"key":"YlMHiSkjDK"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Low bit depth (e.g., 8-bit)","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"wD2mvvLavv"}],"key":"cjAPYtyKIM"},{"type":"text","value":": Only a small number of amplitude levels are available, which can introduce audible distortion and noise, especially in quiet passages.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"vdsuR15rVL"}],"key":"Jqf7ToIZqr"}],"key":"EYdlVxHL0K"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Medium bit depth (e.g., 16-bit)","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"ut0Yh589WZ"}],"key":"lhSuNLAkP7"},{"type":"text","value":": CD-quality audio uses 16 bits per sample, allowing for 65,536 possible amplitude values.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"IF9FPmNLEK"}],"key":"fgB3kflkmb"}],"key":"NcMUancst4"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"High bit depth (e.g., 24-bit)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ydiUxmAwR6"}],"key":"CPiL9x0fGG"},{"type":"text","value":": Professional audio recordings nowadays often use 24 bits per sample, providing over 16 million possible values and a wider dynamic range. Many more amplitude levels are available, resulting in smoother, more natural sound and the ability to capture subtle details.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"HVGHEITTLx"}],"key":"vqYRNqSSUj"}],"key":"deVrvEOpEH"}],"key":"FbYOamGuOl"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Quite recently, there are 32-bit recorders available, offering an extremely high dynamic range, far beyond what human hearing or traditional analog equipment can capture. With 32-bit float, you can record both very quiet and extremely loud sounds without worrying about clipping (distortion from signals being too loud) or noise floor issues (signals being too quiet). This means you can adjust levels after recording without losing audio quality, making it nearly impossible to ruin a recording due to incorrect gain settings. While most playback systems and final mixes use 24-bit or 16-bit audio, 32-bit float is a powerful tool for capturing and processing audio with maximum flexibility and safety during production.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"El1Z56Bq0m"}],"key":"UskfsJTcY6"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"The effect of bit depth can be visualized by quantizing a waveform at different bit depths. Lower bit depths produce a “stepped” appearance and more distortion, while higher bit depths closely follow the original waveform.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"DSL7WwaEXU"}],"key":"rkOgH4olKE"}],"key":"PvmbAI7bsv"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define parameters for the sine wave\nfrequency = 1  # Frequency in Hz\namplitude = 1  # Amplitude of the sine wave\nsampling_rate = 50  # Sampling rate in Hz (samples per second)\n\n# Generate the continuous sine wave\ncontinuous_wave = amplitude * np.sin(2 * np.pi * frequency * x)\n\n# Generate the sampled points\nsampled_x = np.linspace(0, 2 * np.pi, sampling_rate, endpoint=False)\nsampled_wave = amplitude * np.sin(2 * np.pi * frequency * sampled_x)\n\n# Quantize the sampled wave at different bit depths\nbit_depths = [2, 4, 8]  # Bit depths to demonstrate\nquantized_waves = [np.round(sampled_wave * (2**(b-1) - 1)) / (2**(b-1) - 1) for b in bit_depths]\n\n# Plot the continuous wave, sampled points, and quantized waves\nplt.figure(figsize=(12, 2))\n\n# Plot the continuous sine wave\nplt.plot(x, continuous_wave, label='Continuous Sine Wave', color='blue', alpha=0.7)\n\n# Plot the sampled points\nplt.scatter(sampled_x, sampled_wave, color='red', label='Sampled Points', zorder=5)\n\n# Plot quantized waves\nfor i, b in enumerate(bit_depths):\n    plt.step(sampled_x, quantized_waves[i], where='mid', label=f'Quantized ({b}-bit)', alpha=0.8)\n\nplt.title('Effect of Bit Depth on Sine Wave Quantization')\nplt.xlabel('x')\nplt.ylabel('Amplitude')\nplt.axhline(0, color='black', linewidth=0.5, linestyle='--')\nplt.legend()\nplt.grid()\nplt.show()","visibility":"hide","key":"w5rCf9C731"},{"type":"output","id":"xx0AluK_F-FlL9GhN4KsX","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"bf3a5b9fed5be82718e50630400e5ebf","path":"/sensingsoundandmusic/build/bf3a5b9fed5be82718e50630400e5ebf.png"},"text/plain":{"content":"\u003cFigure size 1200x200 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"SDljoO3lr4"}],"visibility":"show","key":"DUtruTBaWn"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Audio Compression and File Formats","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"M4Q9qwkgkv"}],"identifier":"audio-compression-and-file-formats","label":"Audio Compression and File Formats","html_id":"audio-compression-and-file-formats","implicit":true,"key":"NcBxpV0waJ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The final topic in today’s class is audio file formats and compression, essential for storing, sharing, and streaming digital sound.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PmBkTXU3Cx"}],"key":"cDufHiHzgO"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Audio ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Wxn338sZJ6"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"containers","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"woWfs99Dkw"}],"key":"Iuk4rx1ZWL"},{"type":"text","value":" are file formats that store digital audio data along with metadata (such as track info, album art, and artist details). Common containers include ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"iYocZzdUpd"},{"type":"link","url":"https://en.wikipedia.org/wiki/WAV","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"WAV","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ayqajXWiCg"}],"urlSource":"https://en.wikipedia.org/wiki/WAV","data":{"page":"WAV","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"MMDzCFIInN"},{"type":"text","value":" (Windows) and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VmyAM6p76s"},{"type":"link","url":"https://en.wikipedia.org/wiki/Audio_Interchange_File_Format","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"AIFF","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"gHOZEwqHQU"}],"urlSource":"https://en.wikipedia.org/wiki/Audio_Interchange_File_Format","data":{"page":"Audio_Interchange_File_Format","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"drrxD3d8RK"},{"type":"text","value":" (Apple), which both offer uncompressed, high-quality audio.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"eJzuPjAiJs"}],"key":"Druk1MaBrR"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Several container types, e.g. ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"hToKLyKU1r"},{"type":"link","url":"https://en.wikipedia.org/wiki/Matroska","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"MKV","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ISB2O9O44E"}],"urlSource":"https://en.wikipedia.org/wiki/Matroska","data":{"page":"Matroska","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"hFzHpjIBNf"},{"type":"text","value":", can contain raw (uncompressed) and/or compressed audio data alongside video and metadata. Others, like ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Ttuf9r3RSc"},{"type":"link","url":"https://en.wikipedia.org/wiki/MPEG-4_Part_14","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"MP4","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"OfDlT5jAnN"}],"urlSource":"https://en.wikipedia.org/wiki/MPEG-4_Part_14","data":{"page":"MPEG-4_Part_14","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"hVlsJPqZL2"},{"type":"text","value":", store compressed audio, often in combination with video.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"G7VaRQqMzb"}],"key":"amlhsBtuTo"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"It is important to note that the container used for storing the file is (often) independent from the audio ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"qDWYobx9qH"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"compression","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"E3aLMduhsl"}],"key":"VytRYz8Hds"},{"type":"text","value":" used. Note that audio file compression is not the same as the dynamics compression often used to improve the balance in recordings. Audio file compression is based on reducing the file size of digital audio, making it easier to store and transmit. There are two main types:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"NXsrphYGZu"}],"key":"eGvTaiAlxV"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":11,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Lossless compression","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"doWzNPbexR"}],"key":"zw7uIScmZy"},{"type":"text","value":": Preserves all original audio data, allowing perfect reconstruction, such as ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"YxX4TzDqBG"},{"type":"link","url":"https://en.wikipedia.org/wiki/FLAC","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"FLAC","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ueETBT83oe"}],"urlSource":"https://en.wikipedia.org/wiki/FLAC","data":{"page":"FLAC","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"HEm0C7vhUE"},{"type":"text","value":" and ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Qe3XImIIbP"},{"type":"link","url":"https://en.wikipedia.org/wiki/Apple_Lossless","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"ALAC","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"wMHxvzgDw9"}],"urlSource":"https://en.wikipedia.org/wiki/Apple_Lossless","data":{"page":"Apple_Lossless","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"vr7ULlOLah"},{"type":"text","value":".","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"NB8CrUM9rL"}],"key":"VoRoZOjSEh"}],"key":"ACBBMMmUBe"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Lossy compression","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"X4iGd0ELnl"}],"key":"r2cMJqimwf"},{"type":"text","value":": Removes some audio data, typically those less perceptible to human hearing, to achieve smaller file sizes, such as ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"YBLNCpVbu4"},{"type":"link","url":"https://en.wikipedia.org/wiki/MP3","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"MP3","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"wiAbgj57ds"}],"urlSource":"https://en.wikipedia.org/wiki/MP3","data":{"page":"MP3","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"LKGoIIqTtj"},{"type":"text","value":" and ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"PFm1chgUYN"},{"type":"link","url":"https://en.wikipedia.org/wiki/Advanced_Audio_Coding","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"AAC","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"fvGDtjfAhs"}],"urlSource":"https://en.wikipedia.org/wiki/Advanced_Audio_Coding","data":{"page":"Advanced_Audio_Coding","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"cOFyWckuyy"},{"type":"text","value":". Here is a quick overview of what to use:","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"V07aDYphU8"}],"key":"cG4vkOE5XY"}],"key":"nGdSpVBllj"}],"key":"LCl20YeFVi"},{"type":"table","position":{"start":{"line":14,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"tableRow","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"tableCell","header":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Format","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"WOy415MyR8"}],"key":"CilBY0qRUz"},{"type":"tableCell","header":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Compression Type","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"X9JDohkoxd"}],"key":"mLzK5XQ0qd"},{"type":"tableCell","header":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Typical Use","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"kjgNdZC3WS"}],"key":"dTLr0wKFq9"},{"type":"tableCell","header":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Quality","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"YxjuG51L8y"}],"key":"iDHS6mJPxq"}],"key":"VqHpbyBf20"},{"type":"tableRow","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"WAV, AIFF","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"m7w1GAZJNb"}],"key":"a6sEhCLgVm"},{"type":"tableCell","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"None","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"FNi2G0JA91"}],"key":"XcmzCR02zi"},{"type":"tableCell","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Recording, editing","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"Hc6zLuwcby"}],"key":"OGcifJadmz"},{"type":"tableCell","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Excellent","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"NV3apUq6oE"}],"key":"SLrFIZlpp8"}],"key":"Idir0OAr9l"},{"type":"tableRow","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"FLAC","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"uCDAwwzjUW"}],"key":"P8Xj1QRw2l"},{"type":"tableCell","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Lossless","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"n9b8vabrh1"}],"key":"jhxqkVm0xe"},{"type":"tableCell","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Archiving, hi-fi","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"pT0vFuLuv3"}],"key":"EcFngMSk5U"},{"type":"tableCell","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Excellent","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"nPUgbk1dIE"}],"key":"cUFRqwSIgo"}],"key":"QiGnUoFyUk"},{"type":"tableRow","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"tableCell","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"AAC","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"WPrutmIwrU"}],"key":"TubzvplLyw"},{"type":"tableCell","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Lossy","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"Bjw2F3u4Ns"}],"key":"bQZGpMyMai"},{"type":"tableCell","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Streaming","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"UJwAsB1WdD"}],"key":"tDHj8U1Ymk"},{"type":"tableCell","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Good","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"e7ECAXjirL"}],"key":"r0HJ4krdXs"}],"key":"yXXKJMowH2"}],"key":"RSlgrgUbvZ"},{"type":"paragraph","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"While MP3 files can provide good quality, AAC compression generally produces smaller file size and are therefore preferred. For those concerned about using open formats, such as the ","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"nUSMg1Onmk"},{"type":"link","url":"https://en.wikipedia.org/wiki/Ogg","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"Ogg container","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"rqQ0jgraw2"}],"urlSource":"https://en.wikipedia.org/wiki/Ogg","data":{"page":"Ogg","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"nruHmRO9gz"},{"type":"text","value":" and related compression formats.","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"H0gLHrdsmP"}],"key":"ZcjbAlYa4F"},{"type":"exercise","children":[{"type":"paragraph","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"Try to store an uncompressed audio file in a highly compressed format (MP3 or AAC). Listen to how it degrades.","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"oLaqaWGTjm"}],"key":"OQpgqWbawq"}],"label":"Audio compression","identifier":"audio compression","enumerated":true,"enumerator":"6","html_id":"audio-compression","key":"hRAUn50Sfj"}],"key":"BtYzoqSsNj"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Questions","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"anJwpEAYeM"}],"identifier":"questions","label":"Questions","html_id":"questions","implicit":true,"key":"wLvvCRUcCF"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"What is the difference between longitudinal and transverse waves, and how do these wave types relate to the propagation of sound in different media?","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tZAeqMe9PI"}],"key":"VpqYQzqfoM"}],"key":"CtRy3Dyn4X"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Explain the concepts of frequency, amplitude, and phase in sound waves. How do changes in each property affect the perception of sound?","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"qarRUv8X9k"}],"key":"EAfLDCvaLn"}],"key":"F4Yhb3lEl1"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Describe the role of room acoustics in shaping sound quality. What are standing waves, room modes, and flutter echo, and how can acoustic treatment improve a room’s acoustics?","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"JvbSo99aey"}],"key":"pI7U1NZsjq"}],"key":"ZBmJoPw0yM"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Compare and contrast the main categories of musical instruments in the Hornbostel–Sachs system. How does each category produce sound, and what are some examples?","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"rmvRmCtvng"}],"key":"mbrnafFx3B"}],"key":"ALaEyJN6oj"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"What is the process of digitizing sound, and how do sampling rate and bit depth influence the quality of digital audio?","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ghDDBfLNqV"}],"key":"p4fyWHndQv"}],"key":"Q1x3RHNvaf"}],"key":"exawBtoVOj"}],"key":"kJuOp2qVBk"}],"key":"bdzQVGjH2o"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Week 2: Listening","url":"/week2","group":"Sensing Sound and Music"},"next":{"title":"Week 4: Psychoacoustics","url":"/week4","group":"Sensing Sound and Music"}}},"domain":"http://localhost:3000"},"project":{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"exports":[],"title":"Sensing Sound and Music","description":"An interdisciplinary exploration of how humans perceive, experience, and create sound and music through psychological and technological perspectives.","authors":[{"id":"MUS2640","name":"MUS2640"},{"id":"University of Oslo","name":"University of Oslo"}],"github":"https://github.com/fourMs/sensingsoundandmusic","keywords":["sensing","sound","music","psychology","technology"],"id":"11cc8b5a-b0a2-4516-8397-a7dbad782f82","toc":[{"file":"intro.md"},{"file":"week1.md"},{"file":"week2.md"},{"file":"week3.ipynb"},{"file":"week4.ipynb"},{"file":"week5.md"},{"file":"week6.ipynb"},{"file":"week7.md"},{"file":"week8.md"},{"file":"week9.md"},{"file":"week10.md"},{"file":"week11.md"}],"bibliography":[],"index":"index","pages":[{"slug":"week1","title":"Week 1: Tuning in","description":"This page introduces the foundational concepts of music psychology and technology, exploring how humans perceive, experience, and create sound and music through both psychological and technological perspectives.","date":"","thumbnail":"/sensingsoundandmusic/build/c20d5f224f701120b83307814eab6564.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week2","title":"Week 2: Listening","description":"This chapter explores the art and science of listening, focusing on how sounds and soundscapes are described, understood, and analyzed across disciplines. It introduces influential theories and thinkers, practical listening exercises, and tools for engaging with the sonic environment.","date":"","thumbnail":"/sensingsoundandmusic/build/impulsive-sustained--c0c48158496bcc681fba65df66fa6f2f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week3","title":"Week 3: Acoustics","description":"This document provides an introduction to the fundamentals of acoustics, covering the physics of sound, the behavior of sound in rooms and instruments, and the basics of digital audio. It includes explanations, visualizations, and practical exercises to help you understand how sound is produced, transmitted, and perceived in various contexts.","date":"","thumbnail":"/sensingsoundandmusic/build/695b2b8faecb94212205e4e80f715504.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week4","title":"Week 4: Psychoacoustics","description":"This notebook introduces the fundamentals of psychoacoustics—the science of how humans perceive and interpret sound. It covers the anatomy of the ear, principles of loudness and pitch perception, auditory illusions, masking effects, and the application of psychoacoustic concepts in audio technology and music analysis.","date":"","thumbnail":"/sensingsoundandmusic/build/c03cf3c207d0b46d253830651ea7ba28.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week5","title":"Week 5: Time and Rhythm","description":"This chapter explores the foundations of musical time and rhythm, covering concepts such as onset timing, perceptual centers, meter, microrhythm, groove, and entrainment. It examines how rhythm is structured, perceived, and performed, highlighting the roles of technology and analysis tools in understanding the nuances of timing and groove in various musical styles.","date":"","thumbnail":"/sensingsoundandmusic/build/week5_image6-42ef9fdd71a421c1baf682d65217062b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week6","title":"Week 6: Harmony and melody","description":"This notebook explores the concepts of harmony, melody, and musical structure through both theoretical explanations and practical visualizations. It covers fundamental audio representations, symbolic music formats, and provides code examples for analyzing and visualizing musical elements using Python.","date":"","thumbnail":"/sensingsoundandmusic/build/week6_image2-4fa03b8bde3b7bda89ece8a2ac6da510.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week7","title":"Week 7: Body Motion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week8","title":"Week 8: The Brain","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/0698af3bcaf829b93eb28d09596d0541.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week9","title":"Week 9: Vision","description":"","date":"","thumbnail":"/sensingsoundandmusic/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week10","title":"Week 10: Physiology","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"week11","title":"Week 11: Machine Listening","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/sensingsoundandmusic/build/manifest-B2B2E6A5.js";
import * as route0 from "/sensingsoundandmusic/build/root-IB5726YR.js";
import * as route1 from "/sensingsoundandmusic/build/routes/$-LXLHKVOR.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/sensingsoundandmusic/build/entry.client-UNPC4GT3.js");</script></body></html>